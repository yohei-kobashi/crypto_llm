
args = Namespace(input_folder='/groups/gcf51099/crypto_llm/models/1.latin_wikipedia_poly_000000_1234_True/checkpoint/tinyllama-1.1B/global_step1400', output_folder='/groups/gcf51099/crypto_llm/models/hf/1.latin_wikipedia_poly_000000_1234_True', target_tp=1, target_pp=1, activation_function='gelu', for_release=False)
Converting the sentencepiece tokenizer to the huggingface tokenizer...
Traceback (most recent call last):
  File "/home/acf16449gb/crypto_llm/train/Megatron-DeepSpeed/tools/convert_checkpoint/deepspeed_llama2_to_transformers.py", line 104, in <module>
    main()
  File "/home/acf16449gb/crypto_llm/train/Megatron-DeepSpeed/tools/convert_checkpoint/deepspeed_llama2_to_transformers.py", line 40, in main
    output_tokenizer = convert_tokenizer(args.input_tokenizer_file)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Namespace' object has no attribute 'input_tokenizer_file'
