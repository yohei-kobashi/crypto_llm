
args = Namespace(input_folder='/groups/gcf51099/crypto_llm/models/1.latin_wikipedia_poly_000000_1234_True/checkpoint/tinyllama-1.1B/global_step1400', output_folder='/groups/gcf51099/crypto_llm/models/hf/1.latin_wikipedia_poly_000000_1234_True', target_tp=1, target_pp=1, activation_function='gelu', for_release=False)
Converting DeepSpeed checkpoint in /groups/gcf51099/crypto_llm/models/1.latin_wikipedia_poly_000000_1234_True/checkpoint/tinyllama-1.1B/global_step1400 to HF Transformers checkpoint in /groups/gcf51099/crypto_llm/models/hf/1.latin_wikipedia_poly_000000_1234_True
[2024-09-10 10:33:01,449] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Converting to HF Checkpoint
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Original shape: torch.Size([3072, 2048])
Saved shape: (8, 3, 128, 2048)
Saving config to "/groups/gcf51099/crypto_llm/models/hf/1.latin_wikipedia_poly_000000_1234_True/config.json"
Saving checkpoint to "/groups/gcf51099/crypto_llm/models/hf/1.latin_wikipedia_poly_000000_1234_True/pytorch_model.bin"
Now add tokenizer files and upload to the hub
