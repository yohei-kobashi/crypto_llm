
ssh_config_file = /home/acf16449gb/.ssh/config

SSH configuration has been updated.
Host g0146
    HostName g0146
    Port 2222
    StrictHostKeyChecking no

Host g0148
    HostName g0148
    Port 2222
    StrictHostKeyChecking no

Host g0149
    HostName g0149
    Port 2222
    StrictHostKeyChecking no

Host g0150
    HostName g0150
    Port 2222
    StrictHostKeyChecking no

Host g0151
    HostName g0151
    Port 2222
    StrictHostKeyChecking no

Host g0152
    HostName g0152
    Port 2222
    StrictHostKeyChecking no

Host g0153
    HostName g0153
    Port 2222
    StrictHostKeyChecking no

Host g0154
    HostName g0154
    Port 2222
    StrictHostKeyChecking no



ucllm_nedo_dev_train_dir = /home/acf16449gb/ucllm_nedo_prod/train
megatron_deepspeed_dir = /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed

input_tokenizer_file = /groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_no_encryption_000000_1234_True.model
output_model_dir = /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True
save_interval = 500
wandb_entity = yohei-kobashi
wandb_project = encrypted_data_LLM
wandb_tag = other_gpu

Number of GPUs per node: 4
Both /groups/gcf51099/crypto_llm/data/wikipedia_latin_no_encryption_000000_1234_True_text_document.bin and /groups/gcf51099/crypto_llm/data/wikipedia_latin_no_encryption_000000_1234_True_text_document.idx already exist.

hostfile = ./abci_node-8_gpu-32-v100/hostfile_jobid-42753456
g0146 slots=4
g0148 slots=4
g0149 slots=4
g0150 slots=4
g0151 slots=4
g0152 slots=4
g0153 slots=4
g0154 slots=4

[2024-07-31 13:46:00,564] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-31 13:46:06,164] [INFO] [runner.py:463:main] Using IP address of 10.1.5.10 for node g0146
[2024-07-31 13:46:06,166] [INFO] [multinode_runner.py:72:get_cmd] Running on the following workers: g0146,g0148,g0149,g0150,g0151,g0152,g0153,g0154
[2024-07-31 13:46:06,166] [INFO] [runner.py:570:main] cmd = pdsh -S -f 1024 -w g0146,g0148,g0149,g0150,g0151,g0152,g0153,g0154 export PYTHONPATH=/home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model;  cd /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model; /home/acf16449gb/crypto_llm/train/.venv_train/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJnMDE0NiI6IFswLCAxLCAyLCAzXSwgImcwMTQ4IjogWzAsIDEsIDIsIDNdLCAiZzAxNDkiOiBbMCwgMSwgMiwgM10sICJnMDE1MCI6IFswLCAxLCAyLCAzXSwgImcwMTUxIjogWzAsIDEsIDIsIDNdLCAiZzAxNTIiOiBbMCwgMSwgMiwgM10sICJnMDE1MyI6IFswLCAxLCAyLCAzXSwgImcwMTU0IjogWzAsIDEsIDIsIDNdfQ== --node_rank=%n --master_addr=10.1.5.10 --master_port=29500 /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/pretrain_gpt.py --override-opt_param-scheduler --optimizer 'adam' --adam-beta1 '0.9' --adam-beta2 '0.95' --tensor-model-parallel-size '1' --init-method-std '0.013' --lr-decay-tokens '300000000000' --lr-warmup-tokens '3000000000' --micro-batch-size '1' --exit-duration-in-mins '30000000' --global-batch-size '384' --num-layers '12' --hidden-size '2048' --ffn-hidden-size '2816' --num-attention-heads '16' --num-key-value-heads '2' --no-query-key-layer-scaling --attention-dropout '0' --hidden-dropout '0' --use-rotary-position-embeddings --untie-embeddings-and-output-weights --swiglu --normalization 'rmsnorm' --disable-bias-linear --seq-length '2048' --max-position-embeddings '2048' --train-tokens '600000000000' --train-samples '292968750' --lr '2.0e-4' --min-lr '1.0e-5' --lr-decay-style 'cosine' --split '949,50,1' --log-interval '10' --eval-interval '1000' --eval-iters '100' --save-interval '500' --weight-decay '0.1' --clip-grad '1.0' --hysteresis '2' --num-workers '0' --seed '1234' --load '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase' --save '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase' --no-async-tensor-model-parallel-allreduce --tensorboard-queue-size '1' --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --tensorboard-dir '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/tensorboard/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase_0.latin_wikipedia_no_encryption_000000_1234_True-0' --log-optimizer-states-to-tensorboard --tokenizer-type 'SentencePieceTokenizer' --tokenizer-model '/groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_no_encryption_000000_1234_True.model' --data-path '/groups/gcf51099/crypto_llm/data/wikipedia_latin_no_encryption_000000_1234_True_text_document' --data-impl 'mmap' --deepspeed --deepspeed_config '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/deepspeed_config/ds_config_gbs384_mbs1_log10_zero0.json' --zero-stage '0' --pipeline-model-parallel-size '1' --use_wandb --wandb_entity 'yohei-kobashi' --wandb_project 'encrypted_data_LLM' --wandb_group 'pretrain_gpt_0.6B_0.latin_wikipedia_no_encryption_000000_1234_True-0' --wandb_tag 'other_gpu'
g0146: [2024-07-31 13:46:09,500] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0146: [2024-07-31 13:46:11,626] [INFO] [launch.py:138:main] 0 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0146: [2024-07-31 13:46:11,626] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0146: [2024-07-31 13:46:11,626] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=0
g0146: [2024-07-31 13:46:11,626] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0146: [2024-07-31 13:46:11,626] [INFO] [launch.py:163:main] dist_world_size=32
g0146: [2024-07-31 13:46:11,626] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0146: [2024-07-31 13:46:14,732] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0146: [2024-07-31 13:46:14,736] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0146: [2024-07-31 13:46:14,736] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0146: [2024-07-31 13:46:14,737] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0154: [2024-07-31 13:46:17,502] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0150: [2024-07-31 13:46:17,559] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0153: [2024-07-31 13:46:17,833] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0151: [2024-07-31 13:46:17,949] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0152: [2024-07-31 13:46:17,994] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0148: [2024-07-31 13:46:18,029] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0149: [2024-07-31 13:46:18,053] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0146: ----------------------------------------------------------------------------------------------------
g0146: DeepSpeed C++/CUDA extension op report
g0146: 
g0146: DeepSpeed C++/CUDA extension op report--------------------------------------------------
g0146: 
g0146: --------------------------------------------------NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0146:       runtime if needed. Op compatibility means that your system
g0146:       meet the required dependencies to JIT install the op.
g0146: 
g0146: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0146:       runtime if needed. Op compatibility means that your system
g0146:       meet the required dependencies to JIT install the op.--------------------------------------------------
g0146: 
g0146: --------------------------------------------------JIT compiled ops requires ninja
g0146: 
g0146: JIT compiled ops requires ninja
g0146: --------------------------------------------------
g0146: DeepSpeed C++/CUDA extension op report
g0146: --------------------------------------------------
g0146: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0146:       runtime if needed. Op compatibility means that your system
g0146:       meet the required dependencies to JIT install the op.
g0146: --------------------------------------------------
g0146: JIT compiled ops requires ninja
g0146: --------------------------------------------------
g0146: DeepSpeed C++/CUDA extension op report
g0146: --------------------------------------------------
g0146: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0146:       runtime if needed. Op compatibility means that your system
g0146:       meet the required dependencies to JIT install the op.
g0146: --------------------------------------------------
g0146: JIT compiled ops requires ninja
g0146: ninja ninja..................ninja   [92m[OKAY][0mninja....................................
g0146:    [92m[OKAY][0m--------------------------------------------------[92m[OKAY][0m..................
g0146: 
g0146: 
g0146:  op name[92m[OKAY][0m---------------------------------------------------------------------------------------------------- 
g0146: 
g0146: ................
g0146:  --------------------------------------------------op nameop nameinstalled
g0146:    ..................................op name    installedinstalledcompatible ................ 
g0146: .. .. --------------------------------------------------installed compatible
g0146:  compatible
g0146: ..
g0146: -------------------------------------------------- --------------------------------------------------
g0146: compatible
g0146: 
g0146: --------------------------------------------------
g0146: async_io ...............async_io [92m[YES][0m  .....................  [92m[YES][0m[92m[OKAY][0m 
g0146: ...... [92m[OKAY][0m
g0146: fused_adam ............. [92m[YES][0m ......fused_adam  [92m[OKAY][0m.............
g0146:  [92m[YES][0m ......cpu_adam  [92m[OKAY][0m...............
g0146:  [92m[YES][0m ......cpu_adam  [92m[OKAY][0m...............
g0146:  [92m[YES][0m ......cpu_adagrad  [92m[OKAY][0m............
g0146:  [92m[YES][0m cpu_adagrad......  ............[92m[OKAY][0m 
g0146: [92m[YES][0m ......cpu_lion  [92m[OKAY][0m...............
g0146:  [92m[YES][0m ......cpu_lion  [92m[OKAY][0m...............
g0146:  [92m[YES][0m ...... [92m[OKAY][0m
g0146: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0146: evoformer_attn .........async_io [93m[NO][0m  ......................[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH  [92m[YES][0masync_io
g0146: [93m[NO][0m 
g0146: ......  evoformer_attn...............[92m[OKAY][0m  fused_lamb
g0146: [92m[YES][0m ......... ...................   [92m[YES][0m[93m[NO][0m[92m[OKAY][0m  
g0146: ...... .......[92m[OKAY][0mfused_adam 
g0146:  [93m[NO][0m.............
g0146:  fused_adam[92m[YES][0m  ...................fused_lamb   [92m[OKAY][0m[92m[YES][0m
g0146:  .............fused_lion......   .............[92m[OKAY][0m[92m[YES][0mcpu_adam 
g0146:  [92m[YES][0m ...............  ............cpu_adam[92m[YES][0m    .....................[92m[OKAY][0m[92m[OKAY][0m  
g0146: [92m[YES][0m[92m[OKAY][0m
g0146:  
g0146: ...... [92m[OKAY][0mcpu_adagrad
g0146:  ............ cpu_adagrad[92m[YES][0m  ..................  fused_lion[92m[YES][0m[92m[OKAY][0m 
g0146:  ................... cpu_lion[92m[OKAY][0m  
g0146: [92m[YES][0m...............  cpu_lion[92m[YES][0m......  .....................   [92m[OKAY][0m[92m[YES][0m[92m[OKAY][0m
g0146:  
g0146: ...... [92m[OKAY][0m
g0146: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0146: 
g0146: evoformer_attnevoformer_attn  ..................  [93m[NO][0m[93m[NO][0m  ..............  [93m[NO][0m[93m[NO][0m
g0146: 
g0146: fused_lambfused_lamb  ..........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0146: 
g0146: fused_lion fused_lion.............  .............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0146: [92m[OKAY][0m
g0146: inference_core_opsinference_core_ops .....  .....[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0146: [92m[OKAY][0m
g0146: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0146: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0146: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0146: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0146: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0146: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0146: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0146: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0146: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0146: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0146: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0146: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0146: 
g0146: sparse_attnsparse_attn  ........................  [93m[NO][0m[93m[NO][0m  ..............  [93m[NO][0m[93m[NO][0m
g0146: 
g0146: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0146: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0146: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0146: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0146: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0146: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0146: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0146: --------------------------------------------------
g0146: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0146: --------------------------------------------------
g0146: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0146: --------------------------------------------------
g0146: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0146: --------------------------------------------------
g0146: DeepSpeed general environment info:
g0146: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0146: torch version .................... 2.0.1+cu118
g0146: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0146: deepspeed info ................... 0.12.4, unknown, unknown
g0146: torch cuda version ............... 11.8
g0146: torch hip version ................ None
g0146: nvcc version ..................... 11.8
g0146: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0146: shared memory (/dev/shm) size .... 188.13 GB
g0146: DeepSpeed general environment info:
g0146: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0146: torch version .................... 2.0.1+cu118
g0146: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0146: deepspeed info ................... 0.12.4, unknown, unknown
g0146: torch cuda version ............... 11.8
g0146: torch hip version ................ None
g0146: nvcc version ..................... 11.8
g0146: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0146: shared memory (/dev/shm) size .... 188.13 GB
g0146: DeepSpeed general environment info:
g0146: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0146: torch version .................... 2.0.1+cu118
g0146: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0146: deepspeed info ................... 0.12.4, unknown, unknown
g0146: torch cuda version ............... 11.8
g0146: torch hip version ................ None
g0146: nvcc version ..................... 11.8
g0146: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0146: shared memory (/dev/shm) size .... 188.13 GB
g0146: DeepSpeed general environment info:
g0146: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0146: torch version .................... 2.0.1+cu118
g0146: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0146: deepspeed info ................... 0.12.4, unknown, unknown
g0146: torch cuda version ............... 11.8
g0146: torch hip version ................ None
g0146: nvcc version ..................... 11.8
g0146: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0146: shared memory (/dev/shm) size .... 188.13 GB
g0146: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0146: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0146: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0146: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0146: using world size: 32, data-parallel-size: 32, sequence-parallel size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
g0146: WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:SentencePieceTokenizer
g0146: using torch.float32 for parameters ...
g0146: ------------------------ arguments ------------------------
g0146:   accumulate_allreduce_grads_in_fp32 .............. False
g0146:   adam_beta1 ...................................... 0.9
g0146:   adam_beta2 ...................................... 0.95
g0146:   adam_eps ........................................ 1e-08
g0146:   add_bias_linear ................................. False
g0146:   add_position_embedding .......................... False
g0146:   adlr_autoresume ................................. False
g0146:   adlr_autoresume_interval ........................ 1000
g0146:   aml_data_download_path .......................... None
g0146:   apply_layernorm_1p .............................. False
g0146:   apply_query_key_layer_scaling ................... False
g0146:   apply_residual_connection_post_layernorm ........ False
g0146:   async_tensor_model_parallel_allreduce ........... False
g0146:   attention_dropout ............................... 0.0
g0146:   attention_softmax_in_fp32 ....................... False
g0146:   barrier_with_L1_time ............................ True
g0146:   bert_binary_head ................................ True
g0146:   bert_embedder_type .............................. megatron
g0146:   bert_load ....................................... None
g0146:   bf16 ............................................ False
g0146:   bias_dropout_fusion ............................. True
g0146:   bias_gelu_fusion ................................ False
g0146:   biencoder_projection_dim ........................ 0
g0146:   biencoder_shared_query_context_model ............ False
g0146:   block_data_path ................................. None
g0146:   checkpoint_activations .......................... False
g0146:   checkpoint_in_cpu ............................... False
g0146:   checkpoint_num_layers ........................... 1
g0146:   classes_fraction ................................ 1.0
g0146:   clip_grad ....................................... 1.0
g0146:   compression_training ............................ False
g0146:   consumed_train_samples .......................... 0
g0146:   consumed_train_tokens ........................... 0
g0146:   consumed_valid_samples .......................... 0
g0146:   contigious_checkpointing ........................ False
g0146:   cpu_optimizer ................................... False
g0146:   cpu_torch_adam .................................. False
g0146:   create_moe_param_group .......................... False
g0146:   curriculum_learning_legacy ...................... False
g0146:   data_cache_path ................................. None
g0146:   data_efficiency_curriculum_learning ............. False
g0146:   data_impl ....................................... mmap
g0146:   data_parallel_random_init ....................... False
g0146:   data_parallel_size .............................. 32
g0146:   data_path ....................................... ['/groups/gcf51099/crypto_llm/data/wikipedia_latin_no_encryption_000000_1234_True_text_document']
g0146:   data_per_class_fraction ......................... 1.0
g0146:   data_sharding ................................... True
g0146:   dataloader_type ................................. single
g0146:   DDP_impl ........................................ local
g0146:   decoder_num_layers .............................. None
g0146:   decoder_seq_length .............................. None
g0146:   deepscale ....................................... False
g0146:   deepscale_config ................................ None
g0146:   deepspeed ....................................... True
g0146:   deepspeed_activation_checkpointing .............. False
g0146:   deepspeed_config ................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/deepspeed_config/ds_config_gbs384_mbs1_log10_zero0.json
g0146:   deepspeed_mpi ................................... False
g0146:   dino_bottleneck_size ............................ 256
g0146:   dino_freeze_last_layer .......................... 1
g0146:   dino_head_hidden_size ........................... 2048
g0146:   dino_local_crops_number ......................... 10
g0146:   dino_local_img_size ............................. 96
g0146:   dino_norm_last_layer ............................ False
g0146:   dino_teacher_temp ............................... 0.07
g0146:   dino_warmup_teacher_temp ........................ 0.04
g0146:   dino_warmup_teacher_temp_epochs ................. 30
g0146:   distribute_checkpointed_activations ............. False
g0146:   distribute_saved_activations .................... False
g0146:   distributed_backend ............................. nccl
g0146:   distributed_timeout_minutes ..................... 10
g0146:   ds_fused_adam ................................... False
g0146:   ds_inference .................................... False
g0146:   ds_pipeline_enabled ............................. True
g0146:   ds_sequence_parallel_size ....................... 1
g0146:   embedding_path .................................. None
g0146:   embedding_weights_in_fp32 ....................... False
g0146:   empty_unused_memory_level ....................... 0
g0146:   enable_expert_tensor_parallelism ................ False
g0146:   encoder_num_layers .............................. 12
g0146:   encoder_seq_length .............................. 2048
g0146:   end_weight_decay ................................ 0.1
g0146:   eod_mask_loss ................................... False
g0146:   eval_interval ................................... 1000
g0146:   eval_iters ...................................... 100
g0146:   evidence_data_path .............................. None
g0146:   exit_duration_in_mins ........................... 30000000
g0146:   exit_interval ................................... None
g0146:   exit_on_missing_checkpoint ...................... False
g0146:   exit_signal_handler ............................. False
g0146:   expert_interval ................................. 2
g0146:   ffn_hidden_size ................................. 2816
g0146:   finetune ........................................ False
g0146:   force_ds_sequence_parallel ...................... False
g0146:   fp16 ............................................ False
g0146:   fp16_lm_cross_entropy ........................... False
g0146:   fp32_residual_connection ........................ False
g0146:   fp8_amax_compute_algo ........................... most_recent
g0146:   fp8_amax_history_len ............................ 1
g0146:   fp8_e4m3 ........................................ False
g0146:   fp8_hybrid ...................................... False
g0146:   fp8_interval .................................... 1
g0146:   fp8_margin ...................................... 0
g0146:   fp8_wgrad ....................................... True
g0146:   global_batch_size ............................... 384
g0146:   gradient_accumulation_fusion .................... True
g0146:   head_lr_mult .................................... 1.0
g0146:   hidden_dropout .................................. 0.0
g0146:   hidden_size ..................................... 2048
g0146:   hidden_size_teacher ............................. None
g0146:   hysteresis ...................................... 2
g0146:   ict_head_size ................................... None
g0146:   ict_load ........................................ None
g0146:   img_h ........................................... 224
g0146:   img_w ........................................... 224
g0146:   indexer_batch_size .............................. 128
g0146:   indexer_log_interval ............................ 1000
g0146:   inference ....................................... False
g0146:   inference_batch_times_seqlen_threshold .......... 512
g0146:   init_method_std ................................. 0.013
g0146:   init_method_xavier_uniform ...................... False
g0146:   initial_loss_scale .............................. 4294967296
g0146:   iter_per_epoch .................................. 1250
g0146:   kd .............................................. False
g0146:   kd_alpha_ce ..................................... 1
g0146:   kd_beta_ce ...................................... 1
g0146:   kd_temp ......................................... 1.0
g0146:   kv_channels ..................................... 128
g0146:   layernorm_epsilon ............................... 1e-05
g0146:   lazy_mpu_init ................................... None
g0146:   load ............................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase
g0146:   load_teacher .................................... None
g0146:   local_rank ...................................... 0
g0146:   log_batch_size_to_tensorboard ................... True
g0146:   log_interval .................................... 10
g0146:   log_learning_rate_to_tensorboard ................ True
g0146:   log_loss_scale_to_tensorboard ................... True
g0146:   log_memory_to_tensorboard ....................... False
g0146:   log_num_zeros_in_grad ........................... False
g0146:   log_optimizer_states_to_tensorboard ............. True
g0146:   log_params_norm ................................. False
g0146:   log_timers_to_tensorboard ....................... True
g0146:   log_validation_ppl_to_tensorboard ............... True
g0146:   log_world_size_to_tensorboard ................... False
g0146:   loss_scale ...................................... None
g0146:   loss_scale_window ............................... 1000
g0146:   lr .............................................. 0.0002
g0146:   lr_decay_iters .................................. None
g0146:   lr_decay_samples ................................ None
g0146:   lr_decay_style .................................. cosine
g0146:   lr_decay_tokens ................................. 300000000000
g0146:   lr_warmup_fraction .............................. None
g0146:   lr_warmup_iters ................................. 0
g0146:   lr_warmup_samples ............................... 0
g0146:   lr_warmup_tokens ................................ 3000000000
g0146:   make_vocab_size_divisible_by .................... 128
g0146:   mask_factor ..................................... 1.0
g0146:   mask_prob ....................................... 0.15
g0146:   mask_type ....................................... random
g0146:   masked_softmax_fusion ........................... True
g0146:   max_position_embeddings ......................... 2048
g0146:   max_tokens_to_oom ............................... 12000
g0146:   mem_efficient_ln ................................ True
g0146:   memory_centric_tiled_linear ..................... False
g0146:   merge_file ...................................... None
g0146:   micro_batch_size ................................ 1
g0146:   min_loss_scale .................................. 1.0
g0146:   min_lr .......................................... 1e-05
g0146:   mlp_type ........................................ standard
g0146:   mmap_warmup ..................................... False
g0146:   moe_eval_capacity_factor ........................ 1.0
g0146:   moe_expert_parallel_size ........................ 1
g0146:   moe_loss_coeff .................................. 0.1
g0146:   moe_min_capacity ................................ 4
g0146:   moe_token_dropping .............................. True
g0146:   moe_train_capacity_factor ....................... 1.0
g0146:   mos ............................................. False
g0146:   no_load_lr_state ................................ False
g0146:   no_load_optim ................................... None
g0146:   no_load_rng ..................................... None
g0146:   no_persist_layer_norm ........................... False
g0146:   no_pipeline_parallel ............................ False
g0146:   no_save_optim ................................... None
g0146:   no_save_rng ..................................... None
g0146:   normalization ................................... rmsnorm
g0146:   num_attention_heads ............................. 16
g0146:   num_attention_heads_teacher ..................... None
g0146:   num_channels .................................... 3
g0146:   num_classes ..................................... 1000
g0146:   num_experts ..................................... [1]
g0146:   num_experts_switch .............................. None
g0146:   num_experts_teacher ............................. [1]
g0146:   num_key_value_heads ............................. 2
g0146:   num_layers ...................................... 12
g0146:   num_layers_per_virtual_pipeline_stage ........... None
g0146:   num_layers_teacher .............................. None
g0146:   num_workers ..................................... 0
g0146:   onnx_safe ....................................... None
g0146:   openai_gelu ..................................... False
g0146:   optimizer ....................................... adam
g0146:   output_bert_embeddings .......................... False
g0146:   overlap_p2p_comm ................................ False
g0146:   override_opt_param_scheduler .................... True
g0146:   params_dtype .................................... torch.float32
g0146:   partition_activations ........................... False
g0146:   patch_dim ....................................... 16
g0146:   perform_initialization .......................... True
g0146:   pipeline_model_parallel_size .................... 1
g0146:   pipeline_model_parallel_split_rank .............. None
g0146:   profile_backward ................................ False
g0146:   query_in_block_prob ............................. 0.1
g0146:   rampup_batch_size ............................... None
g0146:   random_ltd ...................................... False
g0146:   rank ............................................ 0
g0146:   recompute_granularity ........................... None
g0146:   recompute_method ................................ None
g0146:   recompute_num_layers ............................ 1
g0146:   remote_device ................................... none
g0146:   repeated_dataloader ............................. False
g0146:   reset_attention_mask ............................ False
g0146:   reset_iteration ................................. False
g0146:   reset_position_ids .............................. False
g0146:   retriever_report_topk_accuracies ................ []
g0146:   retriever_score_scaling ......................... False
g0146:   retriever_seq_length ............................ 256
g0146:   retro_add_retriever ............................. False
g0146:   retro_cyclic_train_iters ........................ None
g0146:   retro_encoder_attention_dropout ................. 0.1
g0146:   retro_encoder_hidden_dropout .................... 0.1
g0146:   retro_encoder_layers ............................ 2
g0146:   retro_num_neighbors ............................. 2
g0146:   retro_num_retrieved_chunks ...................... 2
g0146:   retro_return_doc_ids ............................ False
g0146:   retro_workdir ................................... None
g0146:   return_data_index ............................... False
g0146:   rotary_percent .................................. 1.0
g0146:   sample_rate ..................................... 1.0
g0146:   save ............................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase
g0146:   save_interval ................................... 500
g0146:   scatter_gather_tensors_in_pipeline .............. True
g0146:   scattered_embeddings ............................ False
g0146:   seed ............................................ 1234
g0146:   seq_length ...................................... 2048
g0146:   sequence_parallel ............................... False
g0146:   sgd_momentum .................................... 0.9
g0146:   short_seq_prob .................................. 0.1
g0146:   skip_train ...................................... False
g0146:   split ........................................... 949,50,1
g0146:   split_transformers .............................. False
g0146:   squared_relu .................................... False
g0146:   standalone_embedding_stage ...................... False
g0146:   start_weight_decay .............................. 0.1
g0146:   swiglu .......................................... True
g0146:   swin_backbone_type .............................. tiny
g0146:   synchronize_each_layer .......................... False
g0146:   tensor_model_parallel_size ...................... 1
g0146:   tensorboard_dir ................................. /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/tensorboard/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase_0.latin_wikipedia_no_encryption_000000_1234_True-0
g0146:   tensorboard_log_interval ........................ 1
g0146:   tensorboard_queue_size .......................... 1
g0146:   test_data_path .................................. None
g0146:   tf32 ............................................ False
g0146:   tile_factor ..................................... 1
g0146:   timing_log_level ................................ 0
g0146:   timing_log_option ............................... minmax
g0146:   titles_data_path ................................ None
g0146:   tokenizer_model ................................. /groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_no_encryption_000000_1234_True.model
g0146:   tokenizer_type .................................. SentencePieceTokenizer
g0146:   topk ............................................ 1
g0146:   train_data_exact_num_epochs ..................... None
g0146:   train_data_path ................................. None
g0146:   train_desc_path ................................. None
g0146:   train_doc_idx_path .............................. None
g0146:   train_idx_path .................................. None
g0146:   train_iters ..................................... None
g0146:   train_sample_idx_path ........................... None
g0146:   train_samples ................................... 292968750
g0146:   train_shuffle_idx_path .......................... None
g0146:   train_tokens .................................... 600000000000
g0146:   transformer_impl ................................ local
g0146:   transformer_pipeline_model_parallel_size ........ 1
g0146:   universal_checkpoint ............................ False
g0146:   untie_embeddings_and_output_weights ............. True
g0146:   use_checkpoint_args ............................. False
g0146:   use_checkpoint_opt_param_scheduler .............. False
g0146:   use_contiguous_buffers_in_local_ddp ............. True
g0146:   use_cpu_initialization .......................... None
g0146:   use_dataset_only ................................ False
g0146:   use_distributed_optimizer ....................... False
g0146:   use_flash_attn .................................. False
g0146:   use_flash_attn_triton ........................... False
g0146:   use_flash_attn_v1 ............................... False
g0146:   use_flash_attn_v2 ............................... False
g0146:   use_one_sent_docs ............................... False
g0146:   use_pin_memory .................................. False
g0146:   use_ring_exchange_p2p ........................... False
g0146:   use_rotary_position_embeddings .................. True
g0146:   use_tutel ....................................... False
g0146:   use_wandb ....................................... True
g0146:   valid_data_path ................................. None
g0146:   variable_seq_lengths ............................ False
g0146:   virtual_pipeline_model_parallel_size ............ None
g0146:   vision_backbone_type ............................ vit
g0146:   vision_pretraining .............................. False
g0146:   vision_pretraining_type ......................... classify
g0146:   vocab_extra_ids ................................. 0
g0146:   vocab_file ...................................... None
g0146:   vocab_size ...................................... None
g0146:   wandb_entity .................................... yohei-kobashi
g0146:   wandb_group ..................................... pretrain_gpt_0.6B_0.latin_wikipedia_no_encryption_000000_1234_True-0
g0146:   wandb_project ................................... encrypted_data_LLM
g0146:   wandb_tag ....................................... other_gpu
g0146:   weight_decay .................................... 0.1
g0146:   weight_decay_incr_style ......................... constant
g0146:   world_size ...................................... 32
g0146:   zero_allgather_bucket_size ...................... 0.0
g0146:   zero_contigious_gradients ....................... False
g0146:   zero_reduce_bucket_size ......................... 0.0
g0146:   zero_reduce_scatter ............................. False
g0146:   zero_stage ...................................... 0
g0146: -------------------- end of arguments ---------------------
g0146: setting number of micro-batches to constant 12
g0146: > building SentencePieceTokenizer tokenizer ...
g0146: [2024-07-31 13:46:19,486] [INFO] [comm.py:637:init_distributed] cdb=None
g0146: [2024-07-31 13:46:19,487] [INFO] [comm.py:637:init_distributed] cdb=None
g0146: [2024-07-31 13:46:19,487] [INFO] [comm.py:637:init_distributed] cdb=None
g0146:  > padded vocab (size: 32003) with 125 dummy tokens (new size: 32128)
g0146: > initializing torch distributed ...
g0146: [2024-07-31 13:46:19,488] [INFO] [comm.py:637:init_distributed] cdb=None
g0146: [2024-07-31 13:46:19,488] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
g0146: [W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0150: [2024-07-31 13:46:21,592] [INFO] [launch.py:138:main] 3 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0150: [2024-07-31 13:46:21,592] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0150: [2024-07-31 13:46:21,592] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=3
g0150: [2024-07-31 13:46:21,593] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0150: [2024-07-31 13:46:21,593] [INFO] [launch.py:163:main] dist_world_size=32
g0150: [2024-07-31 13:46:21,593] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0154: [2024-07-31 13:46:21,824] [INFO] [launch.py:138:main] 7 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0154: [2024-07-31 13:46:21,825] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0154: [2024-07-31 13:46:21,825] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=7
g0154: [2024-07-31 13:46:21,825] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0154: [2024-07-31 13:46:21,825] [INFO] [launch.py:163:main] dist_world_size=32
g0154: [2024-07-31 13:46:21,825] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0148: [2024-07-31 13:46:21,965] [INFO] [launch.py:138:main] 1 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0148: [2024-07-31 13:46:21,965] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0148: [2024-07-31 13:46:21,965] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=1
g0148: [2024-07-31 13:46:21,965] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0148: [2024-07-31 13:46:21,965] [INFO] [launch.py:163:main] dist_world_size=32
g0148: [2024-07-31 13:46:21,966] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0153: [2024-07-31 13:46:22,007] [INFO] [launch.py:138:main] 6 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0153: [2024-07-31 13:46:22,007] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0153: [2024-07-31 13:46:22,007] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=6
g0153: [2024-07-31 13:46:22,007] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0153: [2024-07-31 13:46:22,007] [INFO] [launch.py:163:main] dist_world_size=32
g0153: [2024-07-31 13:46:22,007] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0151: [2024-07-31 13:46:22,090] [INFO] [launch.py:138:main] 4 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0151: [2024-07-31 13:46:22,090] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0151: [2024-07-31 13:46:22,090] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=4
g0151: [2024-07-31 13:46:22,090] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0151: [2024-07-31 13:46:22,090] [INFO] [launch.py:163:main] dist_world_size=32
g0151: [2024-07-31 13:46:22,090] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0152: [2024-07-31 13:46:22,275] [INFO] [launch.py:138:main] 5 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0152: [2024-07-31 13:46:22,276] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0152: [2024-07-31 13:46:22,276] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=5
g0152: [2024-07-31 13:46:22,276] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0152: [2024-07-31 13:46:22,276] [INFO] [launch.py:163:main] dist_world_size=32
g0152: [2024-07-31 13:46:22,276] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0149: [2024-07-31 13:46:22,292] [INFO] [launch.py:138:main] 2 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0149: [2024-07-31 13:46:22,292] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0146': [0, 1, 2, 3], 'g0148': [0, 1, 2, 3], 'g0149': [0, 1, 2, 3], 'g0150': [0, 1, 2, 3], 'g0151': [0, 1, 2, 3], 'g0152': [0, 1, 2, 3], 'g0153': [0, 1, 2, 3], 'g0154': [0, 1, 2, 3]}
g0149: [2024-07-31 13:46:22,292] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=2
g0149: [2024-07-31 13:46:22,292] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0146': [0, 1, 2, 3], 'g0148': [4, 5, 6, 7], 'g0149': [8, 9, 10, 11], 'g0150': [12, 13, 14, 15], 'g0151': [16, 17, 18, 19], 'g0152': [20, 21, 22, 23], 'g0153': [24, 25, 26, 27], 'g0154': [28, 29, 30, 31]})
g0149: [2024-07-31 13:46:22,292] [INFO] [launch.py:163:main] dist_world_size=32
g0149: [2024-07-31 13:46:22,292] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0150: [2024-07-31 13:46:24,686] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0150: [2024-07-31 13:46:24,686] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0150: [2024-07-31 13:46:24,725] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0150: [2024-07-31 13:46:24,832] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0154: [2024-07-31 13:46:24,958] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0154: [2024-07-31 13:46:24,958] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0154: [2024-07-31 13:46:25,013] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0154: [2024-07-31 13:46:25,054] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0148: [2024-07-31 13:46:25,082] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0148: [2024-07-31 13:46:25,087] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0148: [2024-07-31 13:46:25,132] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0153: [2024-07-31 13:46:25,136] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0153: [2024-07-31 13:46:25,136] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0151: [2024-07-31 13:46:25,139] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0151: [2024-07-31 13:46:25,139] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0153: [2024-07-31 13:46:25,175] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0153: [2024-07-31 13:46:25,196] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0151: [2024-07-31 13:46:25,274] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0148: [2024-07-31 13:46:25,310] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0151: [2024-07-31 13:46:25,332] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0149: [2024-07-31 13:46:25,395] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0149: [2024-07-31 13:46:25,398] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0152: [2024-07-31 13:46:25,399] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0152: [2024-07-31 13:46:25,400] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0152: [2024-07-31 13:46:25,410] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0149: [2024-07-31 13:46:25,470] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0152: [2024-07-31 13:46:25,635] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0149: [2024-07-31 13:46:25,644] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0150: --------------------------------------------------
g0150: DeepSpeed C++/CUDA extension op report
g0150: --------------------------------------------------
g0150: --------------------------------------------------NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0150:       runtime if needed. Op compatibility means that your system
g0150:       meet the required dependencies to JIT install the op.
g0150: 
g0150: --------------------------------------------------
g0150: DeepSpeed C++/CUDA extension op reportJIT compiled ops requires ninja
g0150: 
g0150: --------------------------------------------------
g0150: --------------------------------------------------NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0150:       runtime if needed. Op compatibility means that your system
g0150:       meet the required dependencies to JIT install the op.
g0150: 
g0150: --------------------------------------------------
g0150: DeepSpeed C++/CUDA extension op reportJIT compiled ops requires ninja
g0150: 
g0150: --------------------------------------------------
g0150: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0150:       runtime if needed. Op compatibility means that your system
g0150:       meet the required dependencies to JIT install the op.
g0150: --------------------------------------------------
g0150: JIT compiled ops requires ninja
g0150: --------------------------------------------------
g0150: DeepSpeed C++/CUDA extension op report
g0150: --------------------------------------------------
g0150: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0150:       runtime if needed. Op compatibility means that your system
g0150:       meet the required dependencies to JIT install the op.
g0150: --------------------------------------------------
g0150: JIT compiled ops requires ninja
g0150: ninjaninjaninjaninja   .................. .................................... ..................  [92m[OKAY][0m [92m[OKAY][0m[92m[OKAY][0m
g0150: [92m[OKAY][0m
g0150: 
g0150: 
g0150: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0150: 
g0150: --------------------------------------------------
g0150: 
g0150: op nameop nameop name  op name ................................ ................  ................ installedinstalled installed  installed .... ..  .. compatiblecompatible compatible
g0150: 
g0150: compatible
g0150: ----------------------------------------------------------------------------------------------------
g0150: --------------------------------------------------
g0150: 
g0150: 
g0150: --------------------------------------------------
g0150: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0150: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0150: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0150: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0150: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0150: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0150: fused_lamb ............. [92m[YES][0m async_io......  [92m[OKAY][0m
g0150: ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: fused_lion ............. [92m[YES][0m fused_adam......  .............[92m[OKAY][0m 
g0150: [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0150: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0150: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: inference_core_opsinference_core_ops  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0150: 
g0150: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0150: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0150: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0150: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0150: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0150: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0150: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0150: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0150: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0150: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0150: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0150: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0150: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0150: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0150: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0150: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0150: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0150: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0150: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0150: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0150: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0150: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0150: --------------------------------------------------
g0150: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0150: --------------------------------------------------
g0150: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0150: --------------------------------------------------
g0150: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0150: --------------------------------------------------
g0150: DeepSpeed general environment info:
g0150: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0150: torch version .................... 2.0.1+cu118
g0150: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0150: deepspeed info ................... 0.12.4, unknown, unknown
g0150: torch cuda version ............... 11.8
g0150: torch hip version ................ None
g0150: nvcc version ..................... 11.8
g0150: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0150: shared memory (/dev/shm) size .... 188.13 GB
g0150: DeepSpeed general environment info:
g0150: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0150: torch version .................... 2.0.1+cu118
g0150: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0150: deepspeed info ................... 0.12.4, unknown, unknown
g0150: torch cuda version ............... 11.8
g0150: torch hip version ................ None
g0150: nvcc version ..................... 11.8
g0150: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0150: shared memory (/dev/shm) size .... 188.13 GB
g0150: DeepSpeed general environment info:
g0150: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0150: torch version .................... 2.0.1+cu118
g0150: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0150: deepspeed info ................... 0.12.4, unknown, unknown
g0150: torch cuda version ............... 11.8
g0150: torch hip version ................ None
g0150: nvcc version ..................... 11.8
g0150: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0150: shared memory (/dev/shm) size .... 188.13 GB
g0150: DeepSpeed general environment info:
g0150: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0150: torch version .................... 2.0.1+cu118
g0150: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0150: deepspeed info ................... 0.12.4, unknown, unknown
g0150: torch cuda version ............... 11.8
g0150: torch hip version ................ None
g0150: nvcc version ..................... 11.8
g0150: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0150: shared memory (/dev/shm) size .... 188.13 GB
g0150: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0150: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0150: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0150: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0154: --------------------------------------------------
g0154: DeepSpeed C++/CUDA extension op report
g0154: --------------------------------------------------
g0154: --------------------------------------------------NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0154:       runtime if needed. Op compatibility means that your system
g0154:       meet the required dependencies to JIT install the op.
g0154: 
g0154: --------------------------------------------------
g0154: DeepSpeed C++/CUDA extension op reportJIT compiled ops requires ninja
g0154: 
g0154: --------------------------------------------------
g0154: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0154:       runtime if needed. Op compatibility means that your system
g0154:       meet the required dependencies to JIT install the op.
g0154: --------------------------------------------------
g0154: JIT compiled ops requires ninja
g0154: --------------------------------------------------
g0154: DeepSpeed C++/CUDA extension op report
g0154: --------------------------------------------------
g0154: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0154:       runtime if needed. Op compatibility means that your system
g0154:       meet the required dependencies to JIT install the op.
g0154: --------------------------------------------------
g0154: JIT compiled ops requires ninja
g0154: --------------------------------------------------
g0154: DeepSpeed C++/CUDA extension op report
g0154: --------------------------------------------------
g0154: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0154:       runtime if needed. Op compatibility means that your system
g0154:       meet the required dependencies to JIT install the op.
g0154: --------------------------------------------------
g0154: JIT compiled ops requires ninja
g0154: ninja .................. [92m[OKAY][0m
g0154: --------------------------------------------------
g0154: op name ................ installed .. compatible
g0154: --------------------------------------------------
g0154: ninja .................. [92m[OKAY][0m
g0154: --------------------------------------------------ninja
g0154:  op name..................  ................[92m[OKAY][0m 
g0154: installed --------------------------------------------------..
g0154:  compatibleop name
g0154:  ................-------------------------------------------------- 
g0154: installed .. compatible
g0154: --------------------------------------------------
g0154: ninja .................. [92m[OKAY][0m
g0154: --------------------------------------------------
g0154: op name ................ installed .. compatible
g0154: --------------------------------------------------
g0154: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0154: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0154: cpu_adagrad ............ async_io[92m[YES][0m  .....................  [92m[OKAY][0m[92m[YES][0m
g0154:  ...... cpu_lion[92m[OKAY][0m 
g0154: ............... [92m[YES][0m async_io......  [92m[OKAY][0mfused_adam...............
g0154:   .............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0154: [92m[OKAY][0m
g0154: 
g0154: evoformer_attn .........cpu_adam  [93m[NO][0m...............  fused_adam.......[92m[YES][0m   .............[93m[NO][0m...... 
g0154:  [92m[YES][0m[92m[OKAY][0m 
g0154: ......fused_lambasync_io  cpu_adagrad[92m[OKAY][0m.............   
g0154: ........................... [92m[YES][0m [92m[YES][0mcpu_adam [92m[YES][0m ......  ...... ..................... [92m[OKAY][0m  
g0154: [92m[OKAY][0m[92m[YES][0m[92m[OKAY][0m
g0154:  
g0154: ......cpu_lion  [92m[OKAY][0m...............
g0154:  fused_lionfused_adam[92m[YES][0m cpu_adagrad  ............. ......................... ......  [92m[YES][0m [92m[YES][0m[92m[OKAY][0m[92m[YES][0m  
g0154:  ..................   [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m
g0154: 
g0154: 
g0154: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0154: cpu_lioncpu_adam evoformer_attn ............... ............... .........  [92m[YES][0m[92m[YES][0m [93m[NO][0m ...... ...... ....... [92m[OKAY][0m [92m[OKAY][0m
g0154: 
g0154: [93m[NO][0m
g0154: cpu_adagrad fused_lamb............  [92m[YES][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH............. 
g0154: ......  evoformer_attn[92m[YES][0m[92m[OKAY][0m  
g0154: ...............  [92m[OKAY][0mcpu_lion[93m[NO][0m
g0154:   ......................  [92m[YES][0m[93m[NO][0m 
g0154: ......fused_lion  fused_lamb[92m[OKAY][0m............. 
g0154: .............  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0154: 
g0154: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0154: evoformer_attn ......... fused_lion[93m[NO][0m  ....................  [92m[YES][0m[93m[NO][0m 
g0154: ...... [92m[OKAY][0m
g0154: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0154: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0154: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0154: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0151: --------------------------------------------------
g0151: DeepSpeed C++/CUDA extension op report
g0151: --------------------------------------------------
g0151: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0151:       runtime if needed. Op compatibility means that your system
g0151:       meet the required dependencies to JIT install the op.
g0151: --------------------------------------------------
g0151: JIT compiled ops requires ninja
g0151: --------------------------------------------------
g0151: DeepSpeed C++/CUDA extension op report
g0151: --------------------------------------------------
g0151: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0151:       runtime if needed. Op compatibility means that your system
g0151:       meet the required dependencies to JIT install the op.
g0151: --------------------------------------------------
g0151: JIT compiled ops requires ninja
g0151: --------------------------------------------------
g0151: DeepSpeed C++/CUDA extension op report
g0151: --------------------------------------------------
g0151: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0151:       runtime if needed. Op compatibility means that your system
g0151:       meet the required dependencies to JIT install the op.
g0151: --------------------------------------------------
g0151: JIT compiled ops requires ninja
g0151: --------------------------------------------------
g0151: DeepSpeed C++/CUDA extension op report
g0151: --------------------------------------------------
g0151: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0151:       runtime if needed. Op compatibility means that your system
g0151:       meet the required dependencies to JIT install the op.
g0151: --------------------------------------------------
g0151: JIT compiled ops requires ninja
g0154: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0154: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0154: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0154: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0154: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: --------------------------------------------------
g0148: DeepSpeed C++/CUDA extension op report
g0148: --------------------------------------------------
g0148: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0148:       runtime if needed. Op compatibility means that your system
g0148:       meet the required dependencies to JIT install the op.
g0148: --------------------------------------------------
g0148: JIT compiled ops requires ninja
g0148: --------------------------------------------------
g0148: DeepSpeed C++/CUDA extension op report
g0148: --------------------------------------------------
g0148: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0148:       runtime if needed. Op compatibility means that your system
g0148:       meet the required dependencies to JIT install the op.
g0148: --------------------------------------------------
g0148: JIT compiled ops requires ninja
g0148: --------------------------------------------------
g0148: DeepSpeed C++/CUDA extension op report
g0148: --------------------------------------------------
g0148: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0148:       runtime if needed. Op compatibility means that your system
g0148:       meet the required dependencies to JIT install the op.
g0148: --------------------------------------------------
g0148: JIT compiled ops requires ninja
g0148: --------------------------------------------------
g0148: DeepSpeed C++/CUDA extension op report
g0148: --------------------------------------------------
g0148: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0148:       runtime if needed. Op compatibility means that your system
g0148:       meet the required dependencies to JIT install the op.
g0148: --------------------------------------------------
g0148: JIT compiled ops requires ninja
g0154: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: ninjaninjaninja  .................. .................. .................. [92m[OKAY][0m [92m[OKAY][0m
g0151: [92m[OKAY][0m
g0151: 
g0151: ----------------------------------------------------------------------------------------------------
g0151: --------------------------------------------------
g0151: op name
g0151: op name  ................op name................   installed................installed   ..installed..   compatible..compatible
g0151:  
g0151: --------------------------------------------------compatible--------------------------------------------------
g0151: 
g0151: 
g0151: ninja--------------------------------------------------
g0151:  .................. [92m[OKAY][0m
g0151: --------------------------------------------------
g0151: op name ................ installed .. compatible
g0151: --------------------------------------------------
g0154: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0154: ragged_device_ops ...... [92m[YES][0mragged_device_ops  ...... ......[92m[OKAY][0m 
g0154: [92m[YES][0m ...... [92m[OKAY][0m
g0148: ninjaninjaninja  .................. .................. .................. ninja[92m[OKAY][0m [92m[OKAY][0m
g0148: [92m[OKAY][0m 
g0148: 
g0148: ..................---------------------------------------------------------------------------------------------------- 
g0148: --------------------------------------------------
g0148: [92m[OKAY][0m
g0148: op name
g0148: op name op name ................ --------------------------------------------------................ ................
g0148:  installed installedop name  installed .... ................  .. compatiblecompatible installed
g0148: 
g0148: compatible 
g0148: ----------------------------------------------------------------------------------------------------..
g0148: --------------------------------------------------
g0148:  
g0148: compatible
g0148: --------------------------------------------------
g0154: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0154: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0154: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0154: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0154: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: ragged_ops .............[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0 
g0154: [92m[YES][0m ...... [92m[OKAY][0m
g0154: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0154: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0154: sparse_attn ............ [93m[NO][0m .......[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible 
g0154: [93m[NO][0m
g0154: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0154: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0154: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0154: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0154: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0154: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0154: spatial_inferencespatial_inference  ............  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0154: 
g0154: transformertransformer  ........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0154: 
g0154: stochastic_transformerstochastic_transformer  ..  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0154: 
g0154: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0154: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0154: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0154: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0154: --------------------------------------------------
g0150: [2024-07-31 13:46:29,322] [INFO] [comm.py:637:init_distributed] cdb=None
g0150: [2024-07-31 13:46:29,322] [INFO] [comm.py:637:init_distributed] cdb=None
g0150: [2024-07-31 13:46:29,322] [INFO] [comm.py:637:init_distributed] cdb=None
g0154: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0154: --------------------------------------------------
g0154: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0154: --------------------------------------------------
g0154: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0154: --------------------------------------------------
g0154: DeepSpeed general environment info:
g0154: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0154: torch version .................... 2.0.1+cu118
g0154: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0154: deepspeed info ................... 0.12.4, unknown, unknown
g0154: torch cuda version ............... 11.8
g0154: torch hip version ................ None
g0154: nvcc version ..................... 11.8
g0154: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0154: shared memory (/dev/shm) size .... 188.13 GB
g0150: [2024-07-31 13:46:29,327] [INFO] [comm.py:637:init_distributed] cdb=None
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0154: DeepSpeed general environment info:
g0154: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0154: torch version .................... 2.0.1+cu118
g0154: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0154: deepspeed info ................... 0.12.4, unknown, unknown
g0154: torch cuda version ............... 11.8
g0154: torch hip version ................ None
g0154: nvcc version ..................... 11.8
g0154: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0154: shared memory (/dev/shm) size .... 188.13 GB
g0154: DeepSpeed general environment info:
g0154: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0154: torch version .................... 2.0.1+cu118
g0154: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0154: deepspeed info ................... 0.12.4, unknown, unknown
g0154: torch cuda version ............... 11.8
g0154: torch hip version ................ None
g0154: nvcc version ..................... 11.8
g0154: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0154: shared memory (/dev/shm) size .... 188.13 GB
g0154: DeepSpeed general environment info:
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0154: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0154: torch version .................... 2.0.1+cu118
g0154: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0154: deepspeed info ................... 0.12.4, unknown, unknown
g0154: torch cuda version ............... 11.8
g0154: torch hip version ................ None
g0154: nvcc version ..................... 11.8
g0154: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0154: shared memory (/dev/shm) size .... 188.13 GB
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0150: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0153: 
g0153: 
g0153: DeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op report
g0153: 
g0153: 
g0153: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0153: 
g0153: 
g0153: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0153:       runtime if needed. Op compatibility means that your system
g0153:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0153:       runtime if needed. Op compatibility means that your system
g0153:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0153:       runtime if needed. Op compatibility means that your system
g0153:       meet the required dependencies to JIT install the op.
g0153: 
g0153: 
g0153: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0153: 
g0153: 
g0153: JIT compiled ops requires ninjaJIT compiled ops requires ninjaJIT compiled ops requires ninja
g0153: 
g0153: 
g0153: --------------------------------------------------
g0153: DeepSpeed C++/CUDA extension op report
g0153: --------------------------------------------------
g0153: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0153:       runtime if needed. Op compatibility means that your system
g0153:       meet the required dependencies to JIT install the op.
g0153: --------------------------------------------------
g0153: JIT compiled ops requires ninja
g0153: ninjaninja  ninja....................................  [92m[OKAY][0m [92m[OKAY][0m
g0153: ..................
g0153:  --------------------------------------------------[92m[OKAY][0m--------------------------------------------------
g0153: 
g0153: 
g0153: op nameop name--------------------------------------------------  
g0153: ................................  op nameinstalledinstalled   ....................   installedcompatiblecompatible 
g0153: 
g0153: .. ----------------------------------------------------------------------------------------------------compatible
g0153: 
g0153: 
g0153: --------------------------------------------------
g0153: ninja .................. [92m[OKAY][0m
g0153: --------------------------------------------------
g0153: op name ................ installed .. compatible
g0153: --------------------------------------------------
g0154: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0154: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0154: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0154: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0148: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0148: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0148: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0148: evoformer_attn ......... [93m[NO][0masync_io .......  ...............[93m[NO][0m 
g0148: [92m[YES][0m ...... fused_lamb[92m[OKAY][0m 
g0148: ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: fused_lion .............cpu_adam  [92m[YES][0m...............  ......[92m[YES][0m  [92m[OKAY][0m......
g0148:  [92m[OKAY][0m
g0148: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0148: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0148: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: fused_lion .............async_io  [92m[YES][0m...............  ......[92m[YES][0m  [92m[OKAY][0m......
g0148:  [92m[OKAY][0m
g0148: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0148: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: cpu_lion ............... async_io[92m[YES][0m  .....................  [92m[OKAY][0m[92m[YES][0m
g0148:  ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0148: evoformer_attn .........fused_adam  [93m[NO][0m.............  .......[92m[YES][0m  [93m[NO][0m......
g0148:  [92m[OKAY][0m
g0148: fused_lamb ............. cpu_adam[92m[YES][0m  .....................  [92m[YES][0m[92m[OKAY][0m 
g0148: ...... [92m[OKAY][0m
g0148: cpu_adagrad ............ fused_lion[92m[YES][0m  ...................  [92m[YES][0m [92m[OKAY][0m......
g0148:  [92m[OKAY][0m
g0148: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0148: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0148: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0148: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0148: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0148: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0148: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0148: ragged_device_ops ...... [92m[YES][0m ragged_device_ops......  ......[92m[OKAY][0m 
g0148: [92m[YES][0m ...... [92m[OKAY][0m
g0148: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0148: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0148: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0148: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0148: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0148: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0148: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0148: sparse_attn ............ [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0[93m[NO][0m
g0148:  ....... [93m[NO][0m
g0148: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0148: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0148: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0148: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0148: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0148: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0148: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0148: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0148: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0148: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0148: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0148: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0148: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0153: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0153: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0153: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0153: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0153: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0153: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0153: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0153: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0153: async_io [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH...............
g0153:  [92m[YES][0mevoformer_attn  ...... .........[92m[OKAY][0m 
g0153: [93m[NO][0m ....... [93m[NO][0m
g0153: fused_adam fused_lamb.............  .............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0masync_io 
g0153: [92m[OKAY][0m 
g0153: ............... cpu_adam[92m[YES][0m  .....................  [92m[YES][0m[92m[OKAY][0m fused_lion
g0153: ......  .............[92m[OKAY][0m 
g0153: [92m[YES][0m ...... cpu_adagrad[92m[OKAY][0mfused_adam 
g0153:  .........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0153: 
g0153: cpu_lion cpu_adam...............  ...............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0153: [92m[OKAY][0m
g0153: cpu_adagrad ............ [92m[YES][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0153: ...... evoformer_attn[92m[OKAY][0m 
g0153: ......... [93m[NO][0mcpu_lion  ......................  [93m[NO][0m[92m[YES][0m
g0153:  ...... [92m[OKAY][0mfused_lamb
g0153:  ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0153: evoformer_attn ......... fused_lion[93m[NO][0m  ....................  [93m[NO][0m[92m[YES][0m
g0153:  ...... fused_lamb[92m[OKAY][0m 
g0153: ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0148: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0148: --------------------------------------------------
g0148: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0148: --------------------------------------------------
g0148: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0148: --------------------------------------------------
g0148: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0148: --------------------------------------------------
g0148: DeepSpeed general environment info:
g0148: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0148: torch version .................... 2.0.1+cu118
g0148: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0148: deepspeed info ................... 0.12.4, unknown, unknown
g0148: torch cuda version ............... 11.8
g0148: torch hip version ................ None
g0148: nvcc version ..................... 11.8
g0148: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0148: shared memory (/dev/shm) size .... 188.13 GB
g0148: DeepSpeed general environment info:
g0148: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0148: torch version .................... 2.0.1+cu118
g0148: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0148: deepspeed info ................... 0.12.4, unknown, unknown
g0148: torch cuda version ............... 11.8
g0148: torch hip version ................ None
g0148: nvcc version ..................... 11.8
g0148: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0148: shared memory (/dev/shm) size .... 188.13 GB
g0148: DeepSpeed general environment info:
g0148: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0148: torch version .................... 2.0.1+cu118
g0148: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0148: deepspeed info ................... 0.12.4, unknown, unknown
g0148: torch cuda version ............... 11.8
g0148: torch hip version ................ None
g0148: nvcc version ..................... 11.8
g0148: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0148: shared memory (/dev/shm) size .... 188.13 GB
g0148: DeepSpeed general environment info:
g0148: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0148: torch version .................... 2.0.1+cu118
g0148: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0148: deepspeed info ................... 0.12.4, unknown, unknown
g0148: torch cuda version ............... 11.8
g0148: torch hip version ................ None
g0148: nvcc version ..................... 11.8
g0148: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0148: shared memory (/dev/shm) size .... 188.13 GB
g0153: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0153: inference_core_opsinference_core_ops  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0153: 
g0153: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0154: [2024-07-31 13:46:29,448] [INFO] [comm.py:637:init_distributed] cdb=None
g0154: [2024-07-31 13:46:29,449] [INFO] [comm.py:637:init_distributed] cdb=None
g0154: [2024-07-31 13:46:29,450] [INFO] [comm.py:637:init_distributed] cdb=None
g0153: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0153: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0153: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0153: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0153: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0153: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0153: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0153: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0153: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0153: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0153: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0153: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0153: 
g0153: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0153: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0153: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0153: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0153: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0153: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0153: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0153: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0153: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0153: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0153: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0153: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0153: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0153: --------------------------------------------------
g0153: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0153: --------------------------------------------------
g0153: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0153: --------------------------------------------------
g0153: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0153: --------------------------------------------------
g0153: DeepSpeed general environment info:
g0153: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0153: torch version .................... 2.0.1+cu118
g0153: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0153: deepspeed info ................... 0.12.4, unknown, unknown
g0153: torch cuda version ............... 11.8
g0153: torch hip version ................ None
g0153: nvcc version ..................... 11.8
g0153: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0153: shared memory (/dev/shm) size .... 188.13 GB
g0153: DeepSpeed general environment info:
g0153: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0153: torch version .................... 2.0.1+cu118
g0153: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0153: deepspeed info ................... 0.12.4, unknown, unknown
g0153: torch cuda version ............... 11.8
g0153: torch hip version ................ None
g0153: nvcc version ..................... 11.8
g0153: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0153: shared memory (/dev/shm) size .... 188.13 GB
g0148: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0148: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0148: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0148: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0153: DeepSpeed general environment info:
g0153: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0153: torch version .................... 2.0.1+cu118
g0153: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0153: deepspeed info ................... 0.12.4, unknown, unknown
g0153: torch cuda version ............... 11.8
g0153: torch hip version ................ None
g0153: nvcc version ..................... 11.8
g0153: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0153: shared memory (/dev/shm) size .... 188.13 GB
g0153: DeepSpeed general environment info:
g0153: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0153: torch version .................... 2.0.1+cu118
g0153: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0153: deepspeed info ................... 0.12.4, unknown, unknown
g0153: torch cuda version ............... 11.8
g0153: torch hip version ................ None
g0153: nvcc version ..................... 11.8
g0153: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0153: shared memory (/dev/shm) size .... 188.13 GB
g0153: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0153: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0153: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0153: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0151: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0151: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0151: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0151: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0151: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0151: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0151: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0151: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0masync_io
g0151:  ............... cpu_adam[92m[YES][0m  .....................  [92m[YES][0m[92m[OKAY][0m 
g0151: async_io......  [92m[OKAY][0m...............
g0151:  [92m[YES][0m fused_adam......cpu_adagrad   .............[92m[OKAY][0m............ 
g0151:  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0mfused_adam
g0151: 
g0151:  ............. cpu_adam[92m[YES][0mcpu_lion   ....................................   [92m[YES][0m[92m[OKAY][0m[92m[YES][0m 
g0151:  ............  [92m[OKAY][0m[92m[OKAY][0mcpu_adam
g0151: 
g0151:  ............... cpu_adagrad[92m[YES][0m  ..................  [92m[YES][0m[92m[OKAY][0m 
g0151: ...... [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[OKAY][0mcpu_adagrad
g0151: 
g0151:  ............evoformer_attn  cpu_lion[92m[YES][0m.........   .....................[93m[NO][0m   [92m[YES][0m[92m[OKAY][0m....... 
g0151:  ...... [93m[NO][0m[92m[OKAY][0mcpu_lion
g0151: 
g0151:  ............... [92m[YES][0mfused_lamb  ...................  [92m[OKAY][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[YES][0m
g0151: 
g0151:  ...... evoformer_attn[92m[OKAY][0m 
g0151: ......... [93m[NO][0m .......[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0151: [93m[NO][0m
g0151: evoformer_attn fused_lion.........fused_lamb   .............[93m[NO][0m.............   [92m[YES][0m.......[92m[YES][0m   ......[93m[NO][0m...... 
g0151:  [92m[OKAY][0m[92m[OKAY][0m
g0151: 
g0151: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0mfused_lion
g0151:  ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: inference_core_opsinference_core_ops  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0151: 
g0151: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0151: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0151: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0151: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0151: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: cutlass_opscutlass_ops  ........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0151: 
g0151: quantizerquantizer  ............................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0151: 
g0148: [2024-07-31 13:46:29,555] [INFO] [comm.py:637:init_distributed] cdb=None
g0148: [2024-07-31 13:46:29,556] [INFO] [comm.py:637:init_distributed] cdb=None
g0148: [2024-07-31 13:46:29,556] [INFO] [comm.py:637:init_distributed] cdb=None
g0151: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0148: [2024-07-31 13:46:29,558] [INFO] [comm.py:637:init_distributed] cdb=None
g0151: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0151: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0151: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0151: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0151: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0151: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0151: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0151: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0151: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0151: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0151: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0151: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0148: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0151: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0151: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0151: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0151: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0151: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0151: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0151: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0151: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0151: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0149: --------------------------------------------------
g0151: --------------------------------------------------
g0149: DeepSpeed C++/CUDA extension op report
g0149: --------------------------------------------------
g0149: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0149:       runtime if needed. Op compatibility means that your system
g0149:       meet the required dependencies to JIT install the op.
g0149: --------------------------------------------------
g0149: JIT compiled ops requires ninja
g0149: --------------------------------------------------
g0149: DeepSpeed C++/CUDA extension op report
g0149: --------------------------------------------------
g0149: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0149:       runtime if needed. Op compatibility means that your system
g0149:       meet the required dependencies to JIT install the op.
g0149: --------------------------------------------------
g0149: JIT compiled ops requires ninja
g0149: --------------------------------------------------
g0149: DeepSpeed C++/CUDA extension op report
g0149: --------------------------------------------------
g0149: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0149:       runtime if needed. Op compatibility means that your system
g0149:       meet the required dependencies to JIT install the op.
g0149: --------------------------------------------------
g0149: JIT compiled ops requires ninja
g0149: --------------------------------------------------
g0149: DeepSpeed C++/CUDA extension op report
g0149: --------------------------------------------------
g0149: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0149:       runtime if needed. Op compatibility means that your system
g0149:       meet the required dependencies to JIT install the op.
g0149: --------------------------------------------------
g0149: JIT compiled ops requires ninja
g0151: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0151: --------------------------------------------------
g0151: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0151: --------------------------------------------------
g0151: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0151: --------------------------------------------------
g0151: DeepSpeed general environment info:
g0151: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0151: torch version .................... 2.0.1+cu118
g0151: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0151: deepspeed info ................... 0.12.4, unknown, unknown
g0151: torch cuda version ............... 11.8
g0151: torch hip version ................ None
g0151: nvcc version ..................... 11.8
g0151: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0151: shared memory (/dev/shm) size .... 188.13 GB
g0149: ninjaninjaninja   ......................................................  ninja [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m 
g0149: 
g0149: 
g0149: .................. ------------------------------------------------------------------------------------------------------------------------------------------------------[92m[OKAY][0m
g0149: 
g0149: 
g0149: 
g0149: op nameop nameop name --------------------------------------------------  ................
g0149: ................................   installedop nameinstalledinstalled    ......................    compatibleinstalledcompatiblecompatible
g0149:  
g0149: 
g0149: ..---------------------------------------------------------------------------------------------------- --------------------------------------------------
g0149: 
g0149: compatible
g0149: 
g0149: --------------------------------------------------
g0151: DeepSpeed general environment info:
g0151: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0151: torch version .................... 2.0.1+cu118
g0151: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0151: deepspeed info ................... 0.12.4, unknown, unknown
g0151: torch cuda version ............... 11.8
g0151: torch hip version ................ None
g0151: nvcc version ..................... 11.8
g0151: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0151: shared memory (/dev/shm) size .... 188.13 GB
g0151: DeepSpeed general environment info:
g0151: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0151: torch version .................... 2.0.1+cu118
g0151: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0151: deepspeed info ................... 0.12.4, unknown, unknown
g0151: torch cuda version ............... 11.8
g0151: torch hip version ................ None
g0151: nvcc version ..................... 11.8
g0151: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0151: shared memory (/dev/shm) size .... 188.13 GB
g0151: DeepSpeed general environment info:
g0151: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0151: torch version .................... 2.0.1+cu118
g0151: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0151: deepspeed info ................... 0.12.4, unknown, unknown
g0151: torch cuda version ............... 11.8
g0151: torch hip version ................ None
g0151: nvcc version ..................... 11.8
g0151: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0151: shared memory (/dev/shm) size .... 188.13 GB
g0153: [2024-07-31 13:46:29,590] [INFO] [comm.py:637:init_distributed] cdb=None
g0153: [2024-07-31 13:46:29,590] [INFO] [comm.py:637:init_distributed] cdb=None
g0153: [2024-07-31 13:46:29,592] [INFO] [comm.py:637:init_distributed] cdb=None
g0152: --------------------------------------------------
g0152: DeepSpeed C++/CUDA extension op report
g0152: --------------------------------------------------
g0152: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0152:       runtime if needed. Op compatibility means that your system
g0152:       meet the required dependencies to JIT install the op.
g0152: --------------------------------------------------
g0152: JIT compiled ops requires ninja
g0152: ----------------------------------------------------------------------------------------------------
g0152: 
g0152: DeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op report
g0152: 
g0152: ----------------------------------------------------------------------------------------------------
g0152: 
g0152: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0152:       runtime if needed. Op compatibility means that your system
g0152:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0152:       runtime if needed. Op compatibility means that your system
g0152:       meet the required dependencies to JIT install the op.
g0152: 
g0152: ----------------------------------------------------------------------------------------------------
g0152: 
g0152: JIT compiled ops requires ninjaJIT compiled ops requires ninja
g0152: 
g0152: --------------------------------------------------
g0152: DeepSpeed C++/CUDA extension op report
g0152: --------------------------------------------------
g0152: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0152:       runtime if needed. Op compatibility means that your system
g0152:       meet the required dependencies to JIT install the op.
g0152: --------------------------------------------------
g0152: JIT compiled ops requires ninja
g0153: [2024-07-31 13:46:29,592] [INFO] [comm.py:637:init_distributed] cdb=None
g0152: ninjaninjaninja   ninja......................................................    [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m..................
g0152: 
g0152:  
g0152: [92m[OKAY][0m----------------------------------------------------------------------------------------------------
g0152: --------------------------------------------------
g0152: 
g0152: 
g0152: --------------------------------------------------op nameop name
g0152: op name   ................................op name................    installedinstalled................installed    ......installed    compatiblecompatiblecompatible..
g0152: 
g0152: 
g0152:  --------------------------------------------------compatible----------------------------------------------------------------------------------------------------
g0152: 
g0152: 
g0152: 
g0152: --------------------------------------------------
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0153: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0151: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0151: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0151: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0152: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0152: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_lion ............... async_io[92m[YES][0m  .....................  [92m[OKAY][0m
g0152: [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0152: evoformer_attnfused_adam  ......................  [93m[NO][0m[92m[YES][0m  .............  [93m[NO][0m[92m[OKAY][0m
g0152: 
g0152: fused_lambcpu_adam  ............................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0152: 
g0152: cpu_adagrad ............ [92m[YES][0m ......fused_lion  [92m[OKAY][0m.............
g0152:  [92m[YES][0m cpu_lion......  [92m[OKAY][0m...............
g0152:  [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0152: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0152: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0152: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0152: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0152: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: async_iofused_lion  ............................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0152: 
g0152: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0152: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0152: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0152: inference_core_opsinference_core_ops  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0152: 
g0152: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0152: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0152: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0152: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0152: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0152: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0152: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0152: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0152: ragged_ops[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible 
g0152: ............. sparse_attn[92m[YES][0m  ..................  [93m[NO][0m[92m[OKAY][0m 
g0152: ....... [93m[NO][0m
g0152: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0152: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0152: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0152: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0152: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0152: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0152: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0152: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0152: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0152: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0152: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0152: --------------------------------------------------
g0152: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0152: --------------------------------------------------
g0152: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0152: --------------------------------------------------
g0152: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0152: --------------------------------------------------
g0152: DeepSpeed general environment info:
g0152: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0152: torch version .................... 2.0.1+cu118
g0152: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0152: deepspeed info ................... 0.12.4, unknown, unknown
g0152: torch cuda version ............... 11.8
g0152: torch hip version ................ None
g0152: nvcc version ..................... 11.8
g0152: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0152: shared memory (/dev/shm) size .... 188.13 GB
g0152: DeepSpeed general environment info:
g0152: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0152: torch version .................... 2.0.1+cu118
g0152: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0152: deepspeed info ................... 0.12.4, unknown, unknown
g0152: torch cuda version ............... 11.8
g0152: torch hip version ................ None
g0152: nvcc version ..................... 11.8
g0152: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0152: shared memory (/dev/shm) size .... 188.13 GB
g0152: DeepSpeed general environment info:
g0152: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0152: torch version .................... 2.0.1+cu118
g0152: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0152: deepspeed info ................... 0.12.4, unknown, unknown
g0152: torch cuda version ............... 11.8
g0152: torch hip version ................ None
g0152: nvcc version ..................... 11.8
g0152: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0152: shared memory (/dev/shm) size .... 188.13 GB
g0152: DeepSpeed general environment info:
g0152: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0152: torch version .................... 2.0.1+cu118
g0152: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0152: deepspeed info ................... 0.12.4, unknown, unknown
g0152: torch cuda version ............... 11.8
g0152: torch hip version ................ None
g0152: nvcc version ..................... 11.8
g0152: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0152: shared memory (/dev/shm) size .... 188.13 GB
g0151: [2024-07-31 13:46:29,727] [INFO] [comm.py:637:init_distributed] cdb=None
g0151: [2024-07-31 13:46:29,728] [INFO] [comm.py:637:init_distributed] cdb=None
g0151: [2024-07-31 13:46:29,728] [INFO] [comm.py:637:init_distributed] cdb=None
g0151: [2024-07-31 13:46:29,731] [INFO] [comm.py:637:init_distributed] cdb=None
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0151: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0152: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0152: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0152: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0149: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0149: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0149: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0149: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0149: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0149: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0149: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0149: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0149: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0149: evoformer_attn ......... [93m[NO][0m .......async_io [93m[NO][0m 
g0149: ............... [92m[YES][0mfused_lamb  ...................  [92m[OKAY][0m[92m[YES][0m
g0149:  ...... [92m[OKAY][0m
g0149: async_iofused_adam .............  ...............[92m[YES][0mfused_lion   [92m[YES][0m...................   ......[92m[OKAY][0m[92m[YES][0m 
g0149:  [92m[OKAY][0m......
g0149:  cpu_adam[92m[OKAY][0m 
g0149: ............... [92m[YES][0m ......fused_adam  [92m[OKAY][0m.............
g0149:  [92m[YES][0m cpu_adagrad......  ............[92m[OKAY][0m 
g0149: [92m[YES][0m ...... cpu_adam[92m[OKAY][0m
g0149:  ............... [92m[YES][0m cpu_lion......  ...............[92m[OKAY][0m 
g0149: [92m[YES][0m ...... cpu_adagrad[92m[OKAY][0m 
g0149: ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: cpu_lion ............... [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[YES][0m
g0149:  ...... evoformer_attn[92m[OKAY][0m 
g0149: ......... [93m[NO][0m ....... [93m[NO][0m
g0149: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0149: fused_lamb evoformer_attn.............  .........[92m[YES][0m  [93m[NO][0m......  .......[92m[OKAY][0m 
g0149: [93m[NO][0m
g0149: fused_lamb ............. [92m[YES][0mfused_lion  ...................  [92m[OKAY][0m[92m[YES][0m
g0149:  ...... [92m[OKAY][0m
g0149: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0149: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0149: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0149: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0149: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: ragged_device_ops ...... [92m[YES][0m ......ragged_device_ops  [92m[OKAY][0m......
g0149:  [92m[YES][0m ...... [92m[OKAY][0m
g0149: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0149: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0149: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0149: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0149: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0149: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0149: ragged_ops[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0149:  ............. sparse_attn[92m[YES][0m  ..................  [93m[NO][0m[92m[OKAY][0m .......
g0149:  [93m[NO][0m
g0149: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0149: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0149: sparse_attn ............ [93m[NO][0m ragged_ops.......  ............. [93m[NO][0m[92m[YES][0m
g0149:  ...... [92m[OKAY][0m
g0149: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0149: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0149: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0149: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0149: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0149: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0149: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0149: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0149: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0149: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: spatial_inferencestochastic_transformer  .......  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0149: 
g0149: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0149: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0149: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0149: --------------------------------------------------
g0149: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0149: --------------------------------------------------
g0149: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0149: --------------------------------------------------
g0149: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0149: --------------------------------------------------
g0149: DeepSpeed general environment info:
g0149: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0149: torch version .................... 2.0.1+cu118
g0149: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0149: deepspeed info ................... 0.12.4, unknown, unknown
g0149: torch cuda version ............... 11.8
g0149: torch hip version ................ None
g0149: nvcc version ..................... 11.8
g0149: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0149: shared memory (/dev/shm) size .... 188.05 GB
g0149: DeepSpeed general environment info:
g0149: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0149: torch version .................... 2.0.1+cu118
g0149: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0149: deepspeed info ................... 0.12.4, unknown, unknown
g0149: torch cuda version ............... 11.8
g0149: torch hip version ................ None
g0149: nvcc version ..................... 11.8
g0149: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0149: shared memory (/dev/shm) size .... 188.05 GB
g0149: DeepSpeed general environment info:
g0149: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0149: torch version .................... 2.0.1+cu118
g0149: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0149: deepspeed info ................... 0.12.4, unknown, unknown
g0149: torch cuda version ............... 11.8
g0149: torch hip version ................ None
g0149: nvcc version ..................... 11.8
g0149: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0149: shared memory (/dev/shm) size .... 188.05 GB
g0149: DeepSpeed general environment info:
g0149: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0149: torch version .................... 2.0.1+cu118
g0149: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0149: deepspeed info ................... 0.12.4, unknown, unknown
g0149: torch cuda version ............... 11.8
g0149: torch hip version ................ None
g0149: nvcc version ..................... 11.8
g0149: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0149: shared memory (/dev/shm) size .... 188.05 GB
g0152: [2024-07-31 13:46:29,839] [INFO] [comm.py:637:init_distributed] cdb=None
g0152: [2024-07-31 13:46:29,840] [INFO] [comm.py:637:init_distributed] cdb=None
g0152: [2024-07-31 13:46:29,840] [INFO] [comm.py:637:init_distributed] cdb=None
g0152: [2024-07-31 13:46:29,841] [INFO] [comm.py:637:init_distributed] cdb=None
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0152: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0149: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0149: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0149: **** Git info for Megatron: git_hash=eb60d45 git_branch=main ****
g0154: > setting tensorboard ...
g0154: [2024-07-31 13:46:29,887] [INFO] [comm.py:637:init_distributed] cdb=None
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0154: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [2024-07-31 13:46:30,331] [INFO] [comm.py:637:init_distributed] cdb=None
g0149: [2024-07-31 13:46:30,331] [INFO] [comm.py:637:init_distributed] cdb=None
g0149: [2024-07-31 13:46:30,331] [INFO] [comm.py:637:init_distributed] cdb=None
g0149: [2024-07-31 13:46:30,331] [INFO] [comm.py:637:init_distributed] cdb=None
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0149: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0146-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0146: > initialized tensor model parallel with size 1
g0146: > initialized pipeline model parallel with size 1
g0146: > setting random seeds to 1234 ...
g0146: > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
g0146: > compiling dataset index builder ...
g0146: make: Entering directory '/home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/data'
g0146: make: Nothing to be done for 'default'.
g0146: make: Leaving directory '/home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/data'
g0146: >>> done with dataset index builder. Compilation time: 0.082 seconds
g0146: WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
g0146: > compiling and loading fused kernels ...
g0146: Detected CUDA files, patching ldflags
g0146: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0146: Building extension module scaled_upper_triang_masked_softmax_cuda...
g0146: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0146: ninja: no work to do.
g0146: Loading extension module scaled_upper_triang_masked_softmax_cuda...
g0146: Detected CUDA files, patching ldflags
g0146: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0146: Building extension module scaled_masked_softmax_cuda...
g0146: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0146: ninja: no work to do.
g0146: Loading extension module scaled_masked_softmax_cuda...
g0146: Detected CUDA files, patching ldflags
g0146: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0146: Building extension module scaled_softmax_cuda...
g0146: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0146: ninja: no work to do.
g0146: Loading extension module scaled_softmax_cuda...
g0146: >>> done with compiling and loading fused kernels. Compilation time: 7.565 seconds
g0146: time to initialize megatron (seconds): 24.346
g0146: [after megatron is initialized] datetime: 2024-07-31 13:46:41 
g0151: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0149: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0153: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0146: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0152: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0148: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0150: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0154: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0151: wandb: Tracking run with wandb version 0.17.5
g0151: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-anu00g0u
g0151: wandb: Run `wandb offline` to turn off syncing.
g0151: wandb: Syncing run g0151.abci.local
g0151: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0151: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/anu00g0u
g0153: wandb: Tracking run with wandb version 0.17.5
g0153: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-5uzvcvu7
g0153: wandb: Run `wandb offline` to turn off syncing.
g0153: wandb: Syncing run g0153.abci.local
g0153: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0153: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/5uzvcvu7
g0152: wandb: Tracking run with wandb version 0.17.5
g0152: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-sk9dl25a
g0152: wandb: Run `wandb offline` to turn off syncing.
g0154: wandb: Tracking run with wandb version 0.17.5
g0154: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-1z9y9757
g0154: wandb: Run `wandb offline` to turn off syncing.
g0152: wandb: Syncing run g0152.abci.local
g0152: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0152: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/sk9dl25a
g0154: wandb: Syncing run g0154.abci.local
g0154: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0154: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/1z9y9757
g0149: wandb: Tracking run with wandb version 0.17.5
g0149: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-leonklr1
g0149: wandb: Run `wandb offline` to turn off syncing.
g0149: wandb: Syncing run g0149.abci.local
g0149: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0149: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/leonklr1
g0150: wandb: Tracking run with wandb version 0.17.5
g0150: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-ggxeocbv
g0150: wandb: Run `wandb offline` to turn off syncing.
g0150: wandb: Syncing run g0150.abci.local
g0150: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0150: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/ggxeocbv
g0148: wandb: Tracking run with wandb version 0.17.5
g0148: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-7ixcqtlt
g0148: wandb: Run `wandb offline` to turn off syncing.
g0148: wandb: Syncing run g0148.abci.local
g0148: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0148: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/7ixcqtlt
g0146: wandb: Tracking run with wandb version 0.17.5
g0146: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240731_134643-rmwrpfz7
g0146: wandb: Run `wandb offline` to turn off syncing.
g0146: wandb: Syncing run g0146.abci.local
g0146: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0146: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/rmwrpfz7
g0146: building GPT model ...
g0146: [2024-07-31 13:46:44,302] [INFO] [utils.py:795:see_memory_usage] Before Building Model
g0146: [2024-07-31 13:46:44,303] [INFO] [utils.py:796:see_memory_usage] MA 0.0 GB         Max_MA 0.37 GB         CA 0.0 GB         Max_CA 0 GB 
g0146: [2024-07-31 13:46:44,303] [INFO] [utils.py:803:see_memory_usage] CPU Virtual Memory:  used = 32.83 GB, percent = 8.7%
g0146: SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
g0146: Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=1, model=0): 1, ProcessCoord(pipe=0, data=2, model=0): 2, ProcessCoord(pipe=0, data=3, model=0): 3, ProcessCoord(pipe=0, data=4, model=0): 4, ProcessCoord(pipe=0, data=5, model=0): 5, ProcessCoord(pipe=0, data=6, model=0): 6, ProcessCoord(pipe=0, data=7, model=0): 7, ProcessCoord(pipe=0, data=8, model=0): 8, ProcessCoord(pipe=0, data=9, model=0): 9, ProcessCoord(pipe=0, data=10, model=0): 10, ProcessCoord(pipe=0, data=11, model=0): 11, ProcessCoord(pipe=0, data=12, model=0): 12, ProcessCoord(pipe=0, data=13, model=0): 13, ProcessCoord(pipe=0, data=14, model=0): 14, ProcessCoord(pipe=0, data=15, model=0): 15, ProcessCoord(pipe=0, data=16, model=0): 16, ProcessCoord(pipe=0, data=17, model=0): 17, ProcessCoord(pipe=0, data=18, model=0): 18, ProcessCoord(pipe=0, data=19, model=0): 19, ProcessCoord(pipe=0, data=20, model=0): 20, ProcessCoord(pipe=0, data=21, model=0): 21, ProcessCoord(pipe=0, data=22, model=0): 22, ProcessCoord(pipe=0, data=23, model=0): 23, ProcessCoord(pipe=0, data=24, model=0): 24, ProcessCoord(pipe=0, data=25, model=0): 25, ProcessCoord(pipe=0, data=26, model=0): 26, ProcessCoord(pipe=0, data=27, model=0): 27, ProcessCoord(pipe=0, data=28, model=0): 28, ProcessCoord(pipe=0, data=29, model=0): 29, ProcessCoord(pipe=0, data=30, model=0): 30, ProcessCoord(pipe=0, data=31, model=0): 31}
g0146: [2024-07-31 13:46:45,341] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer
g0146: stage=0 layers=16
g0146:      0: _to_float16
g0146:      1: EmbeddingPipe
g0146:      2: ParallelTransformerLayerPipe
g0146:      3: ParallelTransformerLayerPipe
g0146:      4: ParallelTransformerLayerPipe
g0146:      5: ParallelTransformerLayerPipe
g0146:      6: ParallelTransformerLayerPipe
g0146:      7: ParallelTransformerLayerPipe
g0146:      8: ParallelTransformerLayerPipe
g0146:      9: ParallelTransformerLayerPipe
g0146:     10: ParallelTransformerLayerPipe
g0146:     11: ParallelTransformerLayerPipe
g0146:     12: ParallelTransformerLayerPipe
g0146:     13: ParallelTransformerLayerPipe
g0146:     14: MixedFusedRMSNorm
g0146:     15: LMHeadPipe
g0146:   loss: CrossEntropy
g0146: [2024-07-31 13:46:45,869] [INFO] [utils.py:795:see_memory_usage] After Building Model
g0146: [2024-07-31 13:46:45,870] [INFO] [utils.py:796:see_memory_usage] MA 1.69 GB         Max_MA 1.72 GB         CA 1.72 GB         Max_CA 2 GB 
g0146: [2024-07-31 13:46:45,870] [INFO] [utils.py:803:see_memory_usage] CPU Virtual Memory:  used = 32.9 GB, percent = 8.7%
g0146:  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 452511744
g0146: setting training iterations to 762939
g0146: > learning rate decay style: cosine
g0146: DeepSpeed is enabled.
g0146: [2024-07-31 13:46:45,873] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4, git-hash=unknown, git-branch=unknown
g0154: [2024-07-31 13:46:46,539] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0154: [2024-07-31 13:46:46,540] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0154: [2024-07-31 13:46:46,540] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0154: [2024-07-31 13:46:46,540] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0151: [2024-07-31 13:46:46,572] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0151: [2024-07-31 13:46:46,572] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0151: [2024-07-31 13:46:46,572] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0151: [2024-07-31 13:46:46,573] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0150: [2024-07-31 13:46:46,588] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0150: [2024-07-31 13:46:46,588] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0150: [2024-07-31 13:46:46,589] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0150: [2024-07-31 13:46:46,589] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,593] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
g0152: [2024-07-31 13:46:46,593] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0152: [2024-07-31 13:46:46,594] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0153: [2024-07-31 13:46:46,594] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0153: [2024-07-31 13:46:46,594] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0153: [2024-07-31 13:46:46,594] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0153: [2024-07-31 13:46:46,594] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,594] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
g0146: [2024-07-31 13:46:46,594] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
g0152: [2024-07-31 13:46:46,594] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,596] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
g0146: [2024-07-31 13:46:46,596] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
g0152: [2024-07-31 13:46:46,595] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,649] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
g0148: [2024-07-31 13:46:46,649] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,649] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
g0146: [2024-07-31 13:46:46,649] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x7f2c6dd8d750>
g0148: [2024-07-31 13:46:46,649] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,650] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
g0146: [2024-07-31 13:46:46,650] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,650] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,650] [INFO] [config.py:979:print] DeepSpeedEngine configuration:
g0148: [2024-07-31 13:46:46,650] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,650] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,651] [INFO] [config.py:983:print]   activation_checkpointing_config  {
g0146:     "partition_activations": false, 
g0146:     "contiguous_memory_optimization": false, 
g0146:     "cpu_checkpointing": false, 
g0146:     "number_checkpoints": null, 
g0146:     "synchronize_checkpoint_boundary": false, 
g0146:     "profile": false
g0146: }
g0148: [2024-07-31 13:46:46,651] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,651] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
g0149: [2024-07-31 13:46:46,651] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0149: [2024-07-31 13:46:46,651] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0149: [2024-07-31 13:46:46,651] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,651] [INFO] [config.py:983:print]   amp_enabled .................. False
g0146: [2024-07-31 13:46:46,651] [INFO] [config.py:983:print]   amp_params ................... False
g0146: [2024-07-31 13:46:46,652] [INFO] [config.py:983:print]   autotuning_config ............ {
g0146:     "enabled": false, 
g0146:     "start_step": null, 
g0146:     "end_step": null, 
g0146:     "metric_path": null, 
g0146:     "arg_mappings": null, 
g0146:     "metric": "throughput", 
g0146:     "model_info": null, 
g0146:     "results_dir": "autotuning_results", 
g0146:     "exps_dir": "autotuning_exps", 
g0146:     "overwrite": true, 
g0146:     "fast": true, 
g0146:     "start_profile_step": 3, 
g0146:     "end_profile_step": 5, 
g0146:     "tuner_type": "gridsearch", 
g0146:     "tuner_early_stopping": 5, 
g0146:     "tuner_num_trials": 50, 
g0146:     "model_info_path": null, 
g0146:     "mp_size": 1, 
g0146:     "max_train_batch_size": null, 
g0146:     "min_train_batch_size": 1, 
g0146:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
g0146:     "min_train_micro_batch_size_per_gpu": 1, 
g0146:     "num_tuning_micro_batch_sizes": 3
g0146: }
g0149: [2024-07-31 13:46:46,651] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,652] [INFO] [config.py:983:print]   bfloat16_enabled ............. False
g0146: [2024-07-31 13:46:46,652] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False
g0146: [2024-07-31 13:46:46,652] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True
g0146: [2024-07-31 13:46:46,652] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False
g0146: [2024-07-31 13:46:46,652] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2be22d2bd0>
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   communication_data_type ...... None
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   dataloader_drop_last ......... False
g0146: [2024-07-31 13:46:46,653] [INFO] [config.py:983:print]   disable_allgather ............ False
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   dump_state ................... False
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 500, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100
g0146: [2024-07-31 13:46:46,654] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   elasticity_enabled ........... False
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   flops_profiler_config ........ {
g0146:     "enabled": false, 
g0146:     "recompute_fwd_factor": 0.0, 
g0146:     "profile_step": 1, 
g0146:     "module_depth": -1, 
g0146:     "top_modules": 1, 
g0146:     "detailed": true, 
g0146:     "output_file": null
g0146: }
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   fp16_auto_cast ............... False
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   fp16_enabled ................. True
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   global_rank .................. 0
g0146: [2024-07-31 13:46:46,655] [INFO] [config.py:983:print]   grad_accum_dtype ............. None
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 12
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   gradient_clipping ............ 1.0
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 2048
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   load_universal_checkpoint .... False
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   loss_scale ................... 0
g0146: [2024-07-31 13:46:46,656] [INFO] [config.py:983:print]   memory_breakdown ............. False
g0146: [2024-07-31 13:46:46,657] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False
g0146: [2024-07-31 13:46:46,657] [INFO] [config.py:983:print]   mics_shard_size .............. -1
g0146: [2024-07-31 13:46:46,657] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
g0146: [2024-07-31 13:46:46,657] [INFO] [config.py:983:print]   nebula_config ................ {
g0146:     "enabled": false, 
g0146:     "persistent_storage_path": null, 
g0146:     "persistent_time_interval": 100, 
g0146:     "num_of_version_in_retention": 2, 
g0146:     "enable_nebula_load": true, 
g0146:     "load_path": null
g0146: }
g0146: [2024-07-31 13:46:46,657] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False
g0146: [2024-07-31 13:46:46,657] [INFO] [config.py:983:print]   optimizer_name ............... None
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   optimizer_params ............. None
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   pld_enabled .................. False
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   pld_params ................... False
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   prescale_gradients ........... True
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   scheduler_name ............... None
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   scheduler_params ............. None
g0146: [2024-07-31 13:46:46,658] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   sparse_attention ............. None
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   steps_per_print .............. 10
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   train_batch_size ............. 384
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  1
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   use_node_local_storage ....... False
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   wall_clock_breakdown ......... False
g0146: [2024-07-31 13:46:46,659] [INFO] [config.py:983:print]   weight_quantization_config ... None
g0146: [2024-07-31 13:46:46,660] [INFO] [config.py:983:print]   world_size ................... 32
g0146: [2024-07-31 13:46:46,660] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False
g0146: [2024-07-31 13:46:46,660] [INFO] [config.py:983:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
g0146: [2024-07-31 13:46:46,660] [INFO] [config.py:983:print]   zero_enabled ................. False
g0146: [2024-07-31 13:46:46,660] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True
g0146: [2024-07-31 13:46:46,660] [INFO] [config.py:983:print]   zero_optimization_stage ...... 0
g0146: [2024-07-31 13:46:46,660] [INFO] [config.py:969:print_user_config]   json = {
g0146:     "train_batch_size": 384, 
g0146:     "train_micro_batch_size_per_gpu": 1, 
g0146:     "steps_per_print": 10, 
g0146:     "zero_optimization": {
g0146:         "stage": 0
g0146:     }, 
g0146:     "gradient_clipping": 1.0, 
g0146:     "prescale_gradients": true, 
g0146:     "fp16": {
g0146:         "enabled": true, 
g0146:         "loss_scale": 0, 
g0146:         "loss_scale_window": 500, 
g0146:         "hysteresis": 2, 
g0146:         "min_loss_scale": 1, 
g0146:         "initial_scale_power": 11
g0146:     }, 
g0146:     "wall_clock_breakdown": false
g0146: }
g0146: [2024-07-31 13:46:46,661] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=12 micro_batch_size=1
g0146: [2024-07-31 13:46:46,661] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0146: [2024-07-31 13:46:46,800] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=16 [0, 16) STAGE_PARAMS=452511744 (452.512M) TOTAL_PARAMS=452511744 (452.512M) UNIQUE_PARAMS=452511744 (452.512M)
g0146: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0146: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0146: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0146: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0153: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0149: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0153: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0149: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0149: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0153: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0150: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0150: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0152: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0146: WARNING: could not find the metadata file /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase 
g0152: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0152: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0154: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0152: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0154: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0149: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0154: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0150: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0150: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0154: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0148: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0148: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0148: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0148: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0153: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0151: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0151: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0146:     will not load any checkpoints and will start from random
g0151: [2024-07-31 13:46:46,823] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0151: [2024-07-31 13:46:46,824] [WARNING] [engine.py:2703:load_checkpoint] Unable to find latest file at /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_no_encryption_000000_1234_True/checkpoint/gpt_0.6B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs384_mbs1_g32_pp1_seed1234_rebase/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
g0154: (min, max) time across ranks (ms):
g0154:     load-checkpoint ................................: (2.35, 2.73)
g0146: [after model, optimizer, and learning rate scheduler are built] datetime: 2024-07-31 13:46:46 
g0146: > building train, validation, and test datasets ...
g0146:  > datasets target sizes (minimum size):
g0146:     train:      292968750
g0146:     validation: 29299200
g0146:     test:       38400
g0146: > building train, validation, and test datasets for GPT ...
g0146: Single data path provided for train, valid & test
g0146:  > building dataset index ...
g0146:     reading sizes...
g0146:     reading pointers...
g0146:     reading document index...
g0146:     creating numpy buffer of mmap...
g0146:     creating memory view of numpy buffer...
g0146:  > finished creating indexed dataset in 0.055974 seconds
g0146:     number of documents: 2237032
g0146:  > dataset split:
g0146:     train:
g0146:      document indices in [0, 2122943) total of 2122943 documents
g0146:     validation:
g0146:      document indices in [2122943, 2234795) total of 111852 documents
g0146:     test:
g0146:      document indices in [2234795, 2237032) total of 2237 documents
g0146:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/f837781dad64e489073cc07d7167f285_doc_idx.npy
g0146:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/f837781dad64e489073cc07d7167f285_sample_idx.npy
g0146:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/f837781dad64e489073cc07d7167f285_shuffle_idx.npy
g0146:     loaded indexed file in 0.509 seconds
g0146:     total number of samples: 294008032
g0146:     total number of epochs: 78
g0146:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/dd7cd1fa090e404050e33c6c37bbe848_doc_idx.npy
g0146:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/dd7cd1fa090e404050e33c6c37bbe848_sample_idx.npy
g0146:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/dd7cd1fa090e404050e33c6c37bbe848_shuffle_idx.npy
g0146:     loaded indexed file in 1.690 seconds
g0146:     total number of samples: 29404896
g0146:     total number of epochs: 149
g0146:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2c945c6ac7cc4b052947ea12d8aa402a_doc_idx.npy
g0146:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2c945c6ac7cc4b052947ea12d8aa402a_sample_idx.npy
g0146:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2c945c6ac7cc4b052947ea12d8aa402a_shuffle_idx.npy
g0146:     loaded indexed file in 0.524 seconds
g0146:     total number of samples: 38713
g0146:     total number of epochs: 15
g0146: > finished creating GPT datasets ...
g0146: [after dataloaders are built] datetime: 2024-07-31 13:46:52 
g0146: done with setup ...
g0146: training ...
g0154: (min, max) time across ranks (ms):
g0154:     model-and-optimizer-setup ......................: (2714.92, 2722.29)
g0154:     train/valid/test-data-iterators-setup ..........: (5518.45, 5657.46)
g0146: [before the start of training step] datetime: 2024-07-31 13:46:52 
g0146: [2024-07-31 13:49:39,034] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[4.718592e-07, 4.718592e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
g0146: steps: 10 loss: 10.3745 iter time (s): 16.580 samples/sec: 23.161
g0154:  iteration       10/  762939 | consumed samples:         3840 | consumed tokens:      7864320 | elapsed time per iteration (ms): 16647.1 | learning rate: 4.719E-07 | global batch size:   384 | lm loss: 1.049634E+01 | loss scale: 2048.0 | grad norm: 25.900 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 23.067 | tokens per gpu per second (tgs): 1476.293 | TFLOPs: 6.68 |
g0146: [Rank 0] (after 10 iterations) memory (MB) | allocated: 6452.05419921875 | max allocated: 10808.9453125 | reserved: 13768.0 | max reserved: 13768.0
g0146: [2024-07-31 13:51:59,014] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[9.961472e-07, 9.961472e-07], mom=[(0.9, 0.95), (0.9, 0.95)]
g0146: steps: 20 loss: 9.5765 iter time (s): 13.796 samples/sec: 27.835
g0154:  iteration       20/  762939 | consumed samples:         7680 | consumed tokens:     15728640 | elapsed time per iteration (ms): 13998.1 | learning rate: 9.961E-07 | global batch size:   384 | lm loss: 9.973405E+00 | loss scale: 2048.0 | grad norm: 20.572 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 27.432 | tokens per gpu per second (tgs): 1755.671 | TFLOPs: 7.94 |
g0146: [2024-07-31 13:55:24,517] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[1.5204352000000003e-06, 1.5204352000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
g0146: steps: 30 loss: 8.6726 iter time (s): 20.484 samples/sec: 18.747
g0154:  iteration       30/  762939 | consumed samples:        11520 | consumed tokens:     23592960 | elapsed time per iteration (ms): 20550.4 | learning rate: 1.520E-06 | global batch size:   384 | lm loss: 9.049734E+00 | loss scale: 2048.0 | grad norm: 10.049 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 18.686 | tokens per gpu per second (tgs): 1195.891 | TFLOPs: 5.41 |
g0146: [2024-07-31 13:57:10,827] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[2.0447232e-06, 2.0447232e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
g0146: steps: 40 loss: 8.1955 iter time (s): 10.564 samples/sec: 36.350
g0154:  iteration       40/  762939 | consumed samples:        15360 | consumed tokens:     31457280 | elapsed time per iteration (ms): 10630.8 | learning rate: 2.045E-06 | global batch size:   384 | lm loss: 8.375211E+00 | loss scale: 2048.0 | grad norm: 5.112 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 36.121 | tokens per gpu per second (tgs): 2311.767 | TFLOPs: 10.46 |
g0146: [2024-07-31 13:59:34,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[2.5690112000000003e-06, 2.5690112000000003e-06], mom=[(0.9, 0.95), (0.9, 0.95)]
g0146: steps: 50 loss: 7.9314 iter time (s): 14.266 samples/sec: 26.917
g0154:  iteration       50/  762939 | consumed samples:        19200 | consumed tokens:     39321600 | elapsed time per iteration (ms): 14332.7 | learning rate: 2.569E-06 | global batch size:   384 | lm loss: 8.045551E+00 | loss scale: 2048.0 | grad norm: 3.458 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 26.792 | tokens per gpu per second (tgs): 1714.679 | TFLOPs: 7.76 |
