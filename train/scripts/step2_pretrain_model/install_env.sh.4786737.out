* Loading modules
Currently Loaded Modulefiles:
 1) gcc/8.3.1(default)   2) cuda/11.8   3) cudnn/8.8.0  
* Creating conda environment
Channels:
 - defaults
Platform: linux-64
Collecting package metadata (repodata.json): ...working... done
Solving environment: ...working... done

## Package Plan ##

  environment location: /work/gb20/b20048/miniconda3/envs/deep

  added / updated specs:
    - python=3.9


The following packages will be downloaded:

    package                    |            build
    ---------------------------|-----------------
    _libgcc_mutex-0.1          |             main           3 KB
    _openmp_mutex-5.1          |            1_gnu          21 KB
    ca-certificates-2024.7.2   |       h06a4308_0         127 KB
    ld_impl_linux-64-2.38      |       h1181459_1         654 KB
    libffi-3.4.4               |       h6a678d5_1         141 KB
    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB
    libgomp-11.2.0             |       h1234567_1         474 KB
    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB
    ncurses-6.4                |       h6a678d5_0         914 KB
    openssl-3.0.14             |       h5eee18b_0         5.2 MB
    pip-24.2                   |   py39h06a4308_0         2.2 MB
    python-3.9.19              |       h955ad1f_1        25.1 MB
    readline-8.2               |       h5eee18b_0         357 KB
    setuptools-72.1.0          |   py39h06a4308_0         2.4 MB
    sqlite-3.45.3              |       h5eee18b_0         1.2 MB
    tk-8.6.14                  |       h39e8969_0         3.4 MB
    tzdata-2024a               |       h04d1e81_0         116 KB
    wheel-0.43.0               |   py39h06a4308_0         109 KB
    xz-5.4.6                   |       h5eee18b_1         643 KB
    zlib-1.2.13                |       h5eee18b_1         111 KB
    ------------------------------------------------------------
                                           Total:        53.1 MB

The following NEW packages will be INSTALLED:

  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main 
  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu 
  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.7.2-h06a4308_0 
  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 
  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 
  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 
  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 
  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 
  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 
  openssl            pkgs/main/linux-64::openssl-3.0.14-h5eee18b_0 
  pip                pkgs/main/linux-64::pip-24.2-py39h06a4308_0 
  python             pkgs/main/linux-64::python-3.9.19-h955ad1f_1 
  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 
  setuptools         pkgs/main/linux-64::setuptools-72.1.0-py39h06a4308_0 
  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 
  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 
  tzdata             pkgs/main/noarch::tzdata-2024a-h04d1e81_0 
  wheel              pkgs/main/linux-64::wheel-0.43.0-py39h06a4308_0 
  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 
  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 



Downloading and Extracting Packages: ...working... done
Preparing transaction: ...working... done
Verifying transaction: ...working... done
Executing transaction: ...working... done
#
# To activate this environment, use
#
#     $ conda activate deep
#
# To deactivate an active environment, use
#
#     $ conda deactivate

* Installing pytorch
Looking in indexes: https://download.pytorch.org/whl/cu118
Collecting torch==2.1.0
  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp39-cp39-linux_x86_64.whl (2325.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.3/2.3 GB 101.3 MB/s eta 0:00:00
Collecting torchvision==0.16.0
  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp39-cp39-linux_x86_64.whl (6.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.2/6.2 MB 111.0 MB/s eta 0:00:00
Collecting torchaudio==2.1.0
  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp39-cp39-linux_x86_64.whl (3.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.2/3.2 MB 3.9 MB/s eta 0:00:00
Collecting filelock (from torch==2.1.0)
  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)
Collecting typing-extensions (from torch==2.1.0)
  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)
Collecting sympy (from torch==2.1.0)
  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.7/5.7 MB 171.2 MB/s eta 0:00:00
Collecting networkx (from torch==2.1.0)
  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.6/1.6 MB 97.1 MB/s eta 0:00:00
Collecting jinja2 (from torch==2.1.0)
  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)
Collecting fsspec (from torch==2.1.0)
  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)
Collecting triton==2.1.0 (from torch==2.1.0)
  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 89.3/89.3 MB 254.7 MB/s eta 0:00:00
Collecting numpy (from torchvision==0.16.0)
  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18.2/18.2 MB 202.1 MB/s eta 0:00:00
Collecting requests (from torchvision==0.16.0)
  Downloading https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)
Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.0)
  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.5/4.5 MB 144.6 MB/s eta 0:00:00
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.0)
  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
Collecting charset-normalizer<3,>=2 (from requests->torchvision==0.16.0)
  Downloading https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)
Collecting idna<4,>=2.5 (from requests->torchvision==0.16.0)
  Downloading https://download.pytorch.org/whl/idna-3.4-py3-none-any.whl (61 kB)
Collecting urllib3<1.27,>=1.21.1 (from requests->torchvision==0.16.0)
  Downloading https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)
Collecting certifi>=2017.4.17 (from requests->torchvision==0.16.0)
  Downloading https://download.pytorch.org/whl/certifi-2022.12.7-py3-none-any.whl (155 kB)
Collecting mpmath>=0.19 (from sympy->torch==2.1.0)
  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 kB 23.9 MB/s eta 0:00:00
Installing collected packages: mpmath, urllib3, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, jinja2, torch, torchvision, torchaudio
Successfully installed MarkupSafe-2.1.5 certifi-2022.12.7 charset-normalizer-2.1.1 filelock-3.13.1 fsspec-2024.2.0 idna-3.4 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 pillow-10.2.0 requests-2.28.1 sympy-1.12 torch-2.1.0+cu118 torchaudio-2.1.0+cu118 torchvision-0.16.0+cu118 triton-2.1.0 typing-extensions-4.9.0 urllib3-1.26.13
Collecting ninja==1.11.1 (from -r requirements.txt (line 2))
  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)
Collecting packaging (from -r requirements.txt (line 3))
  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)
Collecting protobuf<3.21.0 (from -r requirements.txt (line 4))
  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (679 bytes)
Collecting pybind11 (from -r requirements.txt (line 5))
  Downloading pybind11-2.13.5-py3-none-any.whl.metadata (9.5 kB)
Collecting regex (from -r requirements.txt (line 6))
  Downloading regex-2024.7.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)
Collecting six (from -r requirements.txt (line 7))
  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)
Requirement already satisfied: wheel in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.43.0)
Collecting accelerate>=0.23.0 (from -r requirements.txt (line 11))
  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)
Collecting peft>=0.5.0 (from -r requirements.txt (line 12))
  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)
Collecting tokenizers>=0.14.0 (from -r requirements.txt (line 13))
  Downloading tokenizers-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Collecting transformers>=4.34.0 (from -r requirements.txt (line 14))
  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)
Collecting trl>=0.7.2 (from -r requirements.txt (line 15))
  Downloading trl-0.10.1-py3-none-any.whl.metadata (12 kB)
Collecting datasets (from -r requirements.txt (line 16))
  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)
Collecting tensorboard (from -r requirements.txt (line 19))
  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)
Collecting chardet (from -r requirements.txt (line 20))
  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)
Collecting wandb (from -r requirements.txt (line 21))
  Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)
Collecting bitsandbytes (from -r requirements.txt (line 24))
  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)
Collecting nltk (from -r requirements.txt (line 25))
  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)
Collecting sentencepiece (from -r requirements.txt (line 26))
  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Collecting einops (from -r requirements.txt (line 29))
  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: numpy in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from -r requirements.txt (line 30)) (1.26.3)
Collecting psutil (from accelerate>=0.23.0->-r requirements.txt (line 11))
  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)
Collecting pyyaml (from accelerate>=0.23.0->-r requirements.txt (line 11))
  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
Requirement already satisfied: torch>=1.10.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from accelerate>=0.23.0->-r requirements.txt (line 11)) (2.1.0+cu118)
Collecting huggingface-hub>=0.21.0 (from accelerate>=0.23.0->-r requirements.txt (line 11))
  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)
Collecting safetensors>=0.3.1 (from accelerate>=0.23.0->-r requirements.txt (line 11))
  Downloading safetensors-0.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)
Collecting tqdm (from peft>=0.5.0->-r requirements.txt (line 12))
  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)
Requirement already satisfied: filelock in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers>=4.34.0->-r requirements.txt (line 14)) (3.13.1)
Requirement already satisfied: requests in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers>=4.34.0->-r requirements.txt (line 14)) (2.28.1)
Collecting tokenizers>=0.14.0 (from -r requirements.txt (line 13))
  Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Collecting tyro>=0.5.11 (from trl>=0.7.2->-r requirements.txt (line 15))
  Downloading tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)
Collecting pyarrow>=15.0.0 (from datasets->-r requirements.txt (line 16))
  Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 16))
  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Collecting pandas (from datasets->-r requirements.txt (line 16))
  Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)
Collecting requests (from transformers>=4.34.0->-r requirements.txt (line 14))
  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting xxhash (from datasets->-r requirements.txt (line 16))
  Downloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess (from datasets->-r requirements.txt (line 16))
  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)
Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->-r requirements.txt (line 16)) (2024.2.0)
Collecting aiohttp (from datasets->-r requirements.txt (line 16))
  Downloading aiohttp-3.10.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)
Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 19))
  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)
Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 19))
  Downloading grpcio-1.66.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)
Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 19))
  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)
Requirement already satisfied: setuptools>=41.0.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 19)) (72.1.0)
Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 19))
  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)
Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 19))
  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)
Collecting click!=8.0.0,>=7.1 (from wandb->-r requirements.txt (line 21))
  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)
Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 21))
  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)
Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 21))
  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)
Collecting platformdirs (from wandb->-r requirements.txt (line 21))
  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)
Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 21))
  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)
Collecting setproctitle (from wandb->-r requirements.txt (line 21))
  Downloading setproctitle-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)
Requirement already satisfied: typing-extensions in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from wandb->-r requirements.txt (line 21)) (4.9.0)
Collecting joblib (from nltk->-r requirements.txt (line 25))
  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)
Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->-r requirements.txt (line 16))
  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 16))
  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)
Collecting attrs>=17.3.0 (from aiohttp->datasets->-r requirements.txt (line 16))
  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 16))
  Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 16))
  Downloading multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)
Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements.txt (line 16))
  Downloading yarl-1.9.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (39 kB)
Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->-r requirements.txt (line 16))
  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)
Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 21))
  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)
Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 19))
  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)
Requirement already satisfied: charset-normalizer<4,>=2 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers>=4.34.0->-r requirements.txt (line 14)) (2.1.1)
Requirement already satisfied: idna<4,>=2.5 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers>=4.34.0->-r requirements.txt (line 14)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers>=4.34.0->-r requirements.txt (line 14)) (1.26.13)
Requirement already satisfied: certifi>=2017.4.17 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers>=4.34.0->-r requirements.txt (line 14)) (2022.12.7)
Requirement already satisfied: sympy in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.23.0->-r requirements.txt (line 11)) (1.12)
Requirement already satisfied: networkx in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.23.0->-r requirements.txt (line 11)) (3.2.1)
Requirement already satisfied: jinja2 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.23.0->-r requirements.txt (line 11)) (3.1.3)
Requirement already satisfied: triton==2.1.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.23.0->-r requirements.txt (line 11)) (2.1.0)
Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl>=0.7.2->-r requirements.txt (line 15))
  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)
Collecting rich>=11.1.0 (from tyro>=0.5.11->trl>=0.7.2->-r requirements.txt (line 15))
  Downloading rich-13.8.0-py3-none-any.whl.metadata (18 kB)
Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.7.2->-r requirements.txt (line 15))
  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)
Collecting eval-type-backport>=0.1.3 (from tyro>=0.5.11->trl>=0.7.2->-r requirements.txt (line 15))
  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)
Requirement already satisfied: MarkupSafe>=2.1.1 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 19)) (2.1.5)
Collecting python-dateutil>=2.8.2 (from pandas->datasets->-r requirements.txt (line 16))
  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas->datasets->-r requirements.txt (line 16))
  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas->datasets->-r requirements.txt (line 16))
  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 21))
  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)
Collecting zipp>=0.5 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 19))
  Downloading zipp-3.20.1-py3-none-any.whl.metadata (3.7 kB)
Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.2->-r requirements.txt (line 15))
  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)
Collecting pygments<3.0.0,>=2.13.0 (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.2->-r requirements.txt (line 15))
  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)
Requirement already satisfied: mpmath>=0.19 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate>=0.23.0->-r requirements.txt (line 11)) (1.3.0)
Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.7.2->-r requirements.txt (line 15))
  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)
Downloading packaging-24.1-py3-none-any.whl (53 kB)
Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.0/1.0 MB 59.0 MB/s eta 0:00:00
Downloading pybind11-2.13.5-py3-none-any.whl (240 kB)
Downloading regex-2024.7.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 775.9/775.9 kB 51.2 MB/s eta 0:00:00
Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)
Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)
Downloading peft-0.12.0-py3-none-any.whl (296 kB)
Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.5/9.5 MB 210.6 MB/s eta 0:00:00
Downloading tokenizers-0.19.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.6/3.6 MB 154.4 MB/s eta 0:00:00
Downloading trl-0.10.1-py3-none-any.whl (280 kB)
Downloading datasets-2.21.0-py3-none-any.whl (527 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 527.3/527.3 kB 32.0 MB/s eta 0:00:00
Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.5/5.5 MB 215.7 MB/s eta 0:00:00
Downloading chardet-5.2.0-py3-none-any.whl (199 kB)
Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.4/9.4 MB 219.4 MB/s eta 0:00:00
Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 137.5/137.5 MB 212.9 MB/s eta 0:00:00
Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.5/1.5 MB 80.3 MB/s eta 0:00:00
Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.3/1.3 MB 58.1 MB/s eta 0:00:00
Downloading einops-0.8.0-py3-none-any.whl (43 kB)
Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)
Downloading click-8.1.7-py3-none-any.whl (97 kB)
Downloading dill-0.3.8-py3-none-any.whl (116 kB)
Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)
Downloading aiohttp-3.10.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 82.8 MB/s eta 0:00:00
Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)
Downloading grpcio-1.66.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.8/5.8 MB 243.4 MB/s eta 0:00:00
Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)
Downloading Markdown-3.7-py3-none-any.whl (106 kB)
Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)
Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (39.9 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 39.9/39.9 MB 254.4 MB/s eta 0:00:00
Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 737.4/737.4 kB 46.8 MB/s eta 0:00:00
Downloading requests-2.32.3-py3-none-any.whl (64 kB)
Downloading safetensors-0.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)
Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)
Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)
Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)
Downloading tyro-0.8.10-py3-none-any.whl (105 kB)
Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)
Downloading joblib-1.4.2-py3-none-any.whl (301 kB)
Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)
Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13.1/13.1 MB 273.9 MB/s eta 0:00:00
Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)
Downloading setproctitle-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)
Downloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)
Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)
Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)
Downloading attrs-24.2.0-py3-none-any.whl (63 kB)
Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)
Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)
Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)
Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)
Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)
Downloading multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (123 kB)
Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)
Downloading rich-13.8.0-py3-none-any.whl (241 kB)
Downloading shtab-1.7.1-py3-none-any.whl (14 kB)
Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)
Downloading yarl-1.9.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (474 kB)
Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)
Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 89.2 MB/s eta 0:00:00
Downloading smmap-5.0.1-py3-none-any.whl (24 kB)
Downloading zipp-3.20.1-py3-none-any.whl (9.0 kB)
Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)
Installing collected packages: sentencepiece, pytz, ninja, zipp, xxhash, werkzeug, tzdata, tqdm, tensorboard-data-server, smmap, six, shtab, setproctitle, sentry-sdk, safetensors, requests, regex, pyyaml, pygments, pybind11, pyarrow, psutil, protobuf, platformdirs, packaging, multidict, mdurl, joblib, grpcio, frozenlist, eval-type-backport, einops, docstring-parser, dill, click, chardet, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, python-dateutil, nltk, multiprocess, markdown-it-py, importlib-metadata, huggingface-hub, gitdb, docker-pycreds, aiosignal, tokenizers, rich, pandas, markdown, gitpython, bitsandbytes, aiohttp, accelerate, wandb, tyro, transformers, tensorboard, peft, datasets, trl
  Attempting uninstall: requests
    Found existing installation: requests 2.28.1
    Uninstalling requests-2.28.1:
      Successfully uninstalled requests-2.28.1
Successfully installed absl-py-2.1.0 accelerate-0.33.0 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 bitsandbytes-0.43.3 chardet-5.2.0 click-8.1.7 datasets-2.21.0 dill-0.3.8 docker-pycreds-0.4.0 docstring-parser-0.16 einops-0.8.0 eval-type-backport-0.2.0 frozenlist-1.4.1 gitdb-4.0.11 gitpython-3.1.43 grpcio-1.66.1 huggingface-hub-0.24.6 importlib-metadata-8.4.0 joblib-1.4.2 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.5 multiprocess-0.70.16 ninja-1.11.1 nltk-3.9.1 packaging-24.1 pandas-2.2.2 peft-0.12.0 platformdirs-4.2.2 protobuf-3.20.3 psutil-6.0.0 pyarrow-17.0.0 pybind11-2.13.5 pygments-2.18.0 python-dateutil-2.9.0.post0 pytz-2024.1 pyyaml-6.0.2 regex-2024.7.24 requests-2.32.3 rich-13.8.0 safetensors-0.4.4 sentencepiece-0.2.0 sentry-sdk-2.13.0 setproctitle-1.3.3 shtab-1.7.1 six-1.16.0 smmap-5.0.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.2 trl-0.10.1 tyro-0.8.10 tzdata-2024.1 wandb-0.17.8 werkzeug-3.0.4 xxhash-3.5.0 yarl-1.9.7 zipp-3.20.1
Collecting deepspeed-kernels
  Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl.metadata (680 bytes)
Collecting cmake>=3.24 (from deepspeed-kernels)
  Downloading cmake-3.30.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)
Requirement already satisfied: packaging in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from deepspeed-kernels) (24.1)
Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 44.5/44.5 MB 119.8 MB/s eta 0:00:00
Downloading cmake-3.30.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 26.9/26.9 MB 196.3 MB/s eta 0:00:00
Installing collected packages: cmake, deepspeed-kernels
Successfully installed cmake-3.30.2 deepspeed-kernels-0.0.1.dev1698255861
* Installing deepspeed with pre-build operators
Using pip 24.2 from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/pip (python 3.9)
Collecting deepspeed==0.12.4
  Downloading deepspeed-0.12.4.tar.gz (1.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 57.1 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Running command python setup.py egg_info
  fatal: not a git repository (or any parent up to mount point /)
  Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
  DS_BUILD_OPS=1
  [93m [WARNING] [0m async_io attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m async_io attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adam attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adam attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adagrad attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adagrad attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_lion attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_lion attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
  [93m [WARNING] [0m Filtered compute capabilities ['6.0', '6.1', '7.0']
  [93m [WARNING] [0m Filtered compute capabilities ['6.0', '6.1', '7.0']
  [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
  [93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
  Install Ops={'async_io': 1, 'fused_adam': 1, 'cpu_adam': 1, 'cpu_adagrad': 1, 'cpu_lion': 1, 'evoformer_attn': False, 'fused_lamb': 1, 'fused_lion': 1, 'inference_core_ops': 1, 'cutlass_ops': 1, 'quantizer': 1, 'ragged_device_ops': 1, 'ragged_ops': 1, 'random_ltd': 1, 'sparse_attn': False, 'spatial_inference': 1, 'transformer': 1, 'stochastic_transformer': 1, 'transformer_inference': 1}
  version=0.12.4, git_hash=unknown, git_branch=unknown
  install_requires=['hjson', 'ninja', 'numpy', 'packaging>=20.0', 'psutil', 'py-cpuinfo', 'pydantic', 'pynvml', 'torch', 'tqdm']
  compatible_ops={'async_io': True, 'fused_adam': True, 'cpu_adam': True, 'cpu_adagrad': True, 'cpu_lion': True, 'evoformer_attn': False, 'fused_lamb': True, 'fused_lion': True, 'inference_core_ops': True, 'cutlass_ops': True, 'quantizer': True, 'ragged_device_ops': True, 'ragged_ops': True, 'random_ltd': True, 'sparse_attn': False, 'spatial_inference': True, 'transformer': True, 'stochastic_transformer': True, 'transformer_inference': True, 'deepspeed_not_implemented': False}
  ext_modules=[<setuptools.extension.Extension('deepspeed.ops.aio.async_io_op') at 0x1455f2f66df0>, <setuptools.extension.Extension('deepspeed.ops.adam.fused_adam_op') at 0x14569e80e6d0>, <setuptools.extension.Extension('deepspeed.ops.adam.cpu_adam_op') at 0x14569e80e670>, <setuptools.extension.Extension('deepspeed.ops.adagrad.cpu_adagrad_op') at 0x14569e80e640>, <setuptools.extension.Extension('deepspeed.ops.lion.cpu_lion_op') at 0x1455f2fd2e50>, <setuptools.extension.Extension('deepspeed.ops.lamb.fused_lamb_op') at 0x1455f2fd28e0>, <setuptools.extension.Extension('deepspeed.ops.lion.fused_lion_op') at 0x1455f2fd25b0>, <setuptools.extension.Extension('deepspeed.inference.v2.kernelsinference_core_ops') at 0x1455f2fa1a00>, <setuptools.extension.Extension('deepspeed.inference.v2.kernels.cutlass_ops.cutlass_ops') at 0x1455f2fa1610>, <setuptools.extension.Extension('deepspeed.ops.quantizer.quantizer_op') at 0x1455f2fa46a0>, <setuptools.extension.Extension('deepspeed.inference.v2.kernels.ragged_ops.ragged_device_ops') at 0x1455f2fa41f0>, <setuptools.extension.Extension('deepspeed.inference.v2.ragged_ops') at 0x1455f2fd2a90>, <setuptools.extension.Extension('deepspeed.ops.random_ltd_op') at 0x1455f2f3e310>, <setuptools.extension.Extension('deepspeed.ops.spatial.spatial_inference_op') at 0x1455f2f3e280>, <setuptools.extension.Extension('deepspeed.ops.transformer.transformer_op') at 0x1455f2f3ed60>, <setuptools.extension.Extension('deepspeed.ops.transformer.stochastic_transformer_op') at 0x1455f2f3e850>, <setuptools.extension.Extension('deepspeed.ops.transformer.inference.transformer_inference_op') at 0x1455f2f3ee20>]
  running egg_info
  creating /tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info
  writing /tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/PKG-INFO
  writing dependency_links to /tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/dependency_links.txt
  writing entry points to /tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/entry_points.txt
  writing requirements to /tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/requires.txt
  writing top-level names to /tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/top_level.txt
  writing manifest file '/tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/SOURCES.txt'
  reading manifest file '/tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/SOURCES.txt'
  reading manifest template 'MANIFEST.in'
  warning: no files found matching 'deepspeed/inference/v2/kernels/ragged_ops/libs/*.so'
  warning: no files found matching 'deepspeed/inference/v2/kernels/cutlass_ops/libs/*.so'
  warning: no files found matching '*.hip' under directory 'deepspeed'
  warning: no files found matching '*.cc' under directory 'deepspeed'
  warning: no files found matching '*.tr' under directory 'csrc'
  warning: no files found matching '*.cc' under directory 'csrc'
  warning: no files found matching '*.py' under directory 'benchmarks'
  writing manifest file '/tmp/pip-pip-egg-info-789ebg29/deepspeed.egg-info/SOURCES.txt'
  deepspeed build time = 0.20860767364501953 secs
  Preparing metadata (setup.py): finished with status 'done'
Collecting hjson (from deepspeed==0.12.4)
  Obtaining dependency information for hjson from https://files.pythonhosted.org/packages/1f/7f/13cd798d180af4bf4c0ceddeefba2b864a63c71645abc0308b768d67bb81/hjson-3.1.0-py3-none-any.whl.metadata
  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)
Requirement already satisfied: ninja in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from deepspeed==0.12.4) (1.11.1)
Requirement already satisfied: numpy in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from deepspeed==0.12.4) (1.26.3)
Requirement already satisfied: packaging>=20.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from deepspeed==0.12.4) (24.1)
Requirement already satisfied: psutil in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from deepspeed==0.12.4) (6.0.0)
Collecting py-cpuinfo (from deepspeed==0.12.4)
  Obtaining dependency information for py-cpuinfo from https://files.pythonhosted.org/packages/e0/a9/023730ba63db1e494a271cb018dcd361bd2c917ba7004c3e49d5daf795a2/py_cpuinfo-9.0.0-py3-none-any.whl.metadata
  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)
Collecting pydantic (from deepspeed==0.12.4)
  Obtaining dependency information for pydantic from https://files.pythonhosted.org/packages/1f/fa/b7f815b8c9ad021c07f88875b601222ef5e70619391ade4a49234d12d278/pydantic-2.8.2-py3-none-any.whl.metadata
  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)
Collecting pynvml (from deepspeed==0.12.4)
  Obtaining dependency information for pynvml from https://files.pythonhosted.org/packages/54/5b/16e50abf152be7f18120f11dfff495014a9eaff7b764626e1656f04ad262/pynvml-11.5.3-py3-none-any.whl.metadata
  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)
Requirement already satisfied: torch in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from deepspeed==0.12.4) (2.1.0+cu118)
Requirement already satisfied: tqdm in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from deepspeed==0.12.4) (4.66.5)
Collecting annotated-types>=0.4.0 (from pydantic->deepspeed==0.12.4)
  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata
  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
Collecting pydantic-core==2.20.1 (from pydantic->deepspeed==0.12.4)
  Obtaining dependency information for pydantic-core==2.20.1 from https://files.pythonhosted.org/packages/9b/f1/a006955715be98093d092aa025f604c7c00721e83fe04bf467c49f31a685/pydantic_core-2.20.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata
  Downloading pydantic_core-2.20.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)
Requirement already satisfied: typing-extensions>=4.6.1 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from pydantic->deepspeed==0.12.4) (4.9.0)
Requirement already satisfied: filelock in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->deepspeed==0.12.4) (3.13.1)
Requirement already satisfied: sympy in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->deepspeed==0.12.4) (1.12)
Requirement already satisfied: networkx in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->deepspeed==0.12.4) (3.2.1)
Requirement already satisfied: jinja2 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->deepspeed==0.12.4) (3.1.3)
Requirement already satisfied: fsspec in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->deepspeed==0.12.4) (2024.2.0)
Requirement already satisfied: triton==2.1.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->deepspeed==0.12.4) (2.1.0)
Requirement already satisfied: MarkupSafe>=2.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from jinja2->torch->deepspeed==0.12.4) (2.1.5)
Requirement already satisfied: mpmath>=0.19 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from sympy->torch->deepspeed==0.12.4) (1.3.0)
Downloading hjson-3.1.0-py3-none-any.whl (54 kB)
Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)
Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)
Downloading pydantic_core-2.20.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 70.9 MB/s eta 0:00:00
Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)
Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)
Building wheels for collected packages: deepspeed
  Building wheel for deepspeed (setup.py): started
  Running command python setup.py bdist_wheel
  DS_BUILD_OPS=1
  [93m [WARNING] [0m async_io attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m async_io attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adam attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adam attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adagrad attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_adagrad attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_lion attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m cpu_lion attempted to use `py-cpuinfo` but failed (exception type: <class 'UnboundLocalError'>, local variable 'get_cpu_info' referenced before assignment), falling back to `lscpu` to get this information.
  [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
  [93m [WARNING] [0m Filtered compute capabilities ['6.0', '6.1', '7.0']
  [93m [WARNING] [0m Filtered compute capabilities ['6.0', '6.1', '7.0']
  [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
  [93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
  Install Ops={'async_io': 1, 'fused_adam': 1, 'cpu_adam': 1, 'cpu_adagrad': 1, 'cpu_lion': 1, 'evoformer_attn': False, 'fused_lamb': 1, 'fused_lion': 1, 'inference_core_ops': 1, 'cutlass_ops': 1, 'quantizer': 1, 'ragged_device_ops': 1, 'ragged_ops': 1, 'random_ltd': 1, 'sparse_attn': False, 'spatial_inference': 1, 'transformer': 1, 'stochastic_transformer': 1, 'transformer_inference': 1}
  fatal: not a git repository (or any parent up to mount point /)
  Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
  version=0.12.4, git_hash=unknown, git_branch=unknown
  install_requires=['hjson', 'ninja', 'numpy', 'packaging>=20.0', 'psutil', 'py-cpuinfo', 'pydantic', 'pynvml', 'torch', 'tqdm']
  compatible_ops={'async_io': True, 'fused_adam': True, 'cpu_adam': True, 'cpu_adagrad': True, 'cpu_lion': True, 'evoformer_attn': False, 'fused_lamb': True, 'fused_lion': True, 'inference_core_ops': True, 'cutlass_ops': True, 'quantizer': True, 'ragged_device_ops': True, 'ragged_ops': True, 'random_ltd': True, 'sparse_attn': False, 'spatial_inference': True, 'transformer': True, 'stochastic_transformer': True, 'transformer_inference': True, 'deepspeed_not_implemented': False}
  ext_modules=[<setuptools.extension.Extension('deepspeed.ops.aio.async_io_op') at 0x1463b31e8970>, <setuptools.extension.Extension('deepspeed.ops.adam.fused_adam_op') at 0x14645eab7670>, <setuptools.extension.Extension('deepspeed.ops.adam.cpu_adam_op') at 0x14645eab76d0>, <setuptools.extension.Extension('deepspeed.ops.adagrad.cpu_adagrad_op') at 0x14645eab7610>, <setuptools.extension.Extension('deepspeed.ops.lion.cpu_lion_op') at 0x1463b3299190>, <setuptools.extension.Extension('deepspeed.ops.lamb.fused_lamb_op') at 0x1463b32991f0>, <setuptools.extension.Extension('deepspeed.ops.lion.fused_lion_op') at 0x1463b32999a0>, <setuptools.extension.Extension('deepspeed.inference.v2.kernelsinference_core_ops') at 0x1463ac1bc610>, <setuptools.extension.Extension('deepspeed.inference.v2.kernels.cutlass_ops.cutlass_ops') at 0x1463ac1bc550>, <setuptools.extension.Extension('deepspeed.ops.quantizer.quantizer_op') at 0x1463ac1bc670>, <setuptools.extension.Extension('deepspeed.inference.v2.kernels.ragged_ops.ragged_device_ops') at 0x1463ac1bc520>, <setuptools.extension.Extension('deepspeed.inference.v2.ragged_ops') at 0x1463a7f22610>, <setuptools.extension.Extension('deepspeed.ops.random_ltd_op') at 0x1463a7f22ac0>, <setuptools.extension.Extension('deepspeed.ops.spatial.spatial_inference_op') at 0x1463a7f22a00>, <setuptools.extension.Extension('deepspeed.ops.transformer.transformer_op') at 0x1463a7f22940>, <setuptools.extension.Extension('deepspeed.ops.transformer.stochastic_transformer_op') at 0x1463a7f257f0>, <setuptools.extension.Extension('deepspeed.ops.transformer.inference.transformer_inference_op') at 0x1463a7f256d0>]
  running bdist_wheel
  running build
  running build_py
  creating build
  creating build/lib.linux-x86_64-cpython-39
  creating build/lib.linux-x86_64-cpython-39/deepspeed
  copying deepspeed/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed
  copying deepspeed/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed
  copying deepspeed/env_report.py -> build/lib.linux-x86_64-cpython-39/deepspeed
  copying deepspeed/git_version_info.py -> build/lib.linux-x86_64-cpython-39/deepspeed
  copying deepspeed/git_version_info_installed.py -> build/lib.linux-x86_64-cpython-39/deepspeed
  copying deepspeed/pydantic_v1.py -> build/lib.linux-x86_64-cpython-39/deepspeed
  creating build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  copying deepspeed/accelerator/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  copying deepspeed/accelerator/abstract_accelerator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  copying deepspeed/accelerator/cpu_accelerator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  copying deepspeed/accelerator/cuda_accelerator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  copying deepspeed/accelerator/mps_accelerator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  copying deepspeed/accelerator/npu_accelerator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  copying deepspeed/accelerator/real_accelerator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/accelerator
  creating build/lib.linux-x86_64-cpython-39/deepspeed/autotuning
  copying deepspeed/autotuning/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning
  copying deepspeed/autotuning/autotuner.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning
  copying deepspeed/autotuning/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning
  copying deepspeed/autotuning/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning
  copying deepspeed/autotuning/scheduler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning
  copying deepspeed/autotuning/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning
  creating build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/deepspeed_checkpoint.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/ds_to_universal.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/reshape_3d_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/reshape_meg_2d.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/reshape_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/universal_checkpoint.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  copying deepspeed/checkpoint/zero_checkpoint.py -> build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint
  creating build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/backend.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/ccl.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/comm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/reduce_op.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/torch.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  copying deepspeed/comm/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/comm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/basic_layer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/compress.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/helper.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/scheduler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  copying deepspeed/compression/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/compression
  creating build/lib.linux-x86_64-cpython-39/deepspeed/elasticity
  copying deepspeed/elasticity/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/elasticity
  copying deepspeed/elasticity/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/elasticity
  copying deepspeed/elasticity/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/elasticity
  copying deepspeed/elasticity/elastic_agent.py -> build/lib.linux-x86_64-cpython-39/deepspeed/elasticity
  copying deepspeed/elasticity/elasticity.py -> build/lib.linux-x86_64-cpython-39/deepspeed/elasticity
  copying deepspeed/elasticity/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/elasticity
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference
  copying deepspeed/inference/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference
  copying deepspeed/inference/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference
  copying deepspeed/inference/engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference
  creating build/lib.linux-x86_64-cpython-39/deepspeed/launcher
  copying deepspeed/launcher/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/launcher
  copying deepspeed/launcher/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/launcher
  copying deepspeed/launcher/launch.py -> build/lib.linux-x86_64-cpython-39/deepspeed/launcher
  copying deepspeed/launcher/multinode_runner.py -> build/lib.linux-x86_64-cpython-39/deepspeed/launcher
  copying deepspeed/launcher/runner.py -> build/lib.linux-x86_64-cpython-39/deepspeed/launcher
  creating build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations
  copying deepspeed/model_implementations/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations
  creating build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/auto_tp.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/auto_tp_model_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/fusedqkv_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/inject.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/layers.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/load_checkpoint.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/module_quantize.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/policy.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/replace_module.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/replace_policy.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/tp_shard.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  copying deepspeed/module_inject/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject
  creating build/lib.linux-x86_64-cpython-39/deepspeed/moe
  copying deepspeed/moe/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/moe
  copying deepspeed/moe/experts.py -> build/lib.linux-x86_64-cpython-39/deepspeed/moe
  copying deepspeed/moe/layer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/moe
  copying deepspeed/moe/mappings.py -> build/lib.linux-x86_64-cpython-39/deepspeed/moe
  copying deepspeed/moe/sharded_moe.py -> build/lib.linux-x86_64-cpython-39/deepspeed/moe
  copying deepspeed/moe/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/moe
  creating build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  copying deepspeed/monitor/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  copying deepspeed/monitor/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  copying deepspeed/monitor/csv_monitor.py -> build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  copying deepspeed/monitor/monitor.py -> build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  copying deepspeed/monitor/tensorboard.py -> build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  copying deepspeed/monitor/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  copying deepspeed/monitor/wandb.py -> build/lib.linux-x86_64-cpython-39/deepspeed/monitor
  creating build/lib.linux-x86_64-cpython-39/deepspeed/nebula
  copying deepspeed/nebula/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/nebula
  copying deepspeed/nebula/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/nebula
  copying deepspeed/nebula/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/nebula
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops
  copying deepspeed/ops/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops
  creating build/lib.linux-x86_64-cpython-39/deepspeed/pipe
  copying deepspeed/pipe/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/pipe
  creating build/lib.linux-x86_64-cpython-39/deepspeed/profiling
  copying deepspeed/profiling/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/profiling
  copying deepspeed/profiling/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/profiling
  copying deepspeed/profiling/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/profiling
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/bf16_optimizer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/config_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/dataloader.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/eigenvalue.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/hybrid_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/lr_schedules.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/progressive_layer_drop.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/quantize.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/sparse_tensor.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/state_dict_factory.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  copying deepspeed/runtime/weight_quantizer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime
  creating build/lib.linux-x86_64-cpython-39/deepspeed/sequence
  copying deepspeed/sequence/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/sequence
  copying deepspeed/sequence/layer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/sequence
  creating build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/comms_logging.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/debug.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/exceptions.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/groups.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/init_on_device.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/logging.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/mixed_precision_linkage.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/numa.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/nvtx.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/tensor_fragment.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/timer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/types.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  copying deepspeed/utils/zero_to_fp32.py -> build/lib.linux-x86_64-cpython-39/deepspeed/utils
  creating build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner
  copying deepspeed/autotuning/tuner/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner
  copying deepspeed/autotuning/tuner/base_tuner.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner
  copying deepspeed/autotuning/tuner/cost_model.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner
  copying deepspeed/autotuning/tuner/index_based_tuner.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner
  copying deepspeed/autotuning/tuner/model_based_tuner.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner
  copying deepspeed/autotuning/tuner/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization
  copying deepspeed/inference/quantization/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization
  copying deepspeed/inference/quantization/layers.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization
  copying deepspeed/inference/quantization/quantization.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization
  copying deepspeed/inference/quantization/quantization_context.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization
  copying deepspeed/inference/quantization/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/allocator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/config_v2.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/engine_factory.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/engine_v2.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/inference_parameter.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/inference_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/logging.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  copying deepspeed/inference/v2/scheduling_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint
  copying deepspeed/inference/v2/checkpoint/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint
  copying deepspeed/inference/v2/checkpoint/base_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint
  copying deepspeed/inference/v2/checkpoint/huggingface_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint
  copying deepspeed/inference/v2/checkpoint/in_memory_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels
  copying deepspeed/inference/v2/kernels/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels
  copying deepspeed/inference/v2/kernels/ds_kernel.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  copying deepspeed/inference/v2/model_implementations/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  copying deepspeed/inference/v2/model_implementations/flat_model_helpers.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  copying deepspeed/inference/v2/model_implementations/inference_model_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  copying deepspeed/inference/v2/model_implementations/inference_policy_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  copying deepspeed/inference/v2/model_implementations/inference_transformer_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  copying deepspeed/inference/v2/model_implementations/layer_container_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  copying deepspeed/inference/v2/model_implementations/parameter_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules
  copying deepspeed/inference/v2/modules/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules
  copying deepspeed/inference/v2/modules/ds_module.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules
  copying deepspeed/inference/v2/modules/heuristics.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules
  copying deepspeed/inference/v2/modules/module_registry.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  copying deepspeed/inference/v2/ragged/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  copying deepspeed/inference/v2/ragged/blocked_allocator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  copying deepspeed/inference/v2/ragged/kv_cache.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  copying deepspeed/inference/v2/ragged/manager_configs.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  copying deepspeed/inference/v2/ragged/ragged_manager.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  copying deepspeed/inference/v2/ragged/ragged_wrapper.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  copying deepspeed/inference/v2/ragged/sequence_descriptor.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops
  copying deepspeed/inference/v2/kernels/core_ops/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops
  copying deepspeed/inference/v2/kernels/cutlass_ops/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops
  copying deepspeed/inference/v2/kernels/ragged_ops/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying deepspeed/inference/v2/kernels/core_ops/bias_activations/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying deepspeed/inference/v2/kernels/core_ops/blas_kernels/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas_linear.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_fp_ln_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_ln.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_post_ln.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_pre_ln.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_pre_norm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying deepspeed/inference/v2/kernels/core_ops/gated_activations/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/mixed_moe_gemm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying deepspeed/inference/v2/kernels/ragged_ops/atom_builder/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying deepspeed/inference/v2/kernels/ragged_ops/embed/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying deepspeed/inference/v2/kernels/ragged_ops/embed/embed.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_trained_kv_rotary.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/linear_blocked_kv_copy.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/logits_gather/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_gather/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/attn_output_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/embedding_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/invfreq_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/mlp_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/moe_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/norm_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/qkv_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  copying deepspeed/inference/v2/model_implementations/common_parameters/unembed_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2
  copying deepspeed/inference/v2/model_implementations/llama_v2/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2
  copying deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_containers.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2
  copying deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_model.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2
  copying deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_policy.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral
  copying deepspeed/inference/v2/model_implementations/mistral/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral
  copying deepspeed/inference/v2/model_implementations/mistral/container.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral
  copying deepspeed/inference/v2/model_implementations/mistral/model.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral
  copying deepspeed/inference/v2/model_implementations/mistral/policy.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt
  copying deepspeed/inference/v2/model_implementations/opt/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt
  copying deepspeed/inference/v2/model_implementations/opt/container.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt
  copying deepspeed/inference/v2/model_implementations/opt/model.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt
  copying deepspeed/inference/v2/model_implementations/opt/policy.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/attn.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/attn_out.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/embedding.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/mlp.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/qkv.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/types.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/unembed.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  copying deepspeed/inference/v2/model_implementations/sharding/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  copying deepspeed/inference/v2/modules/configs/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  copying deepspeed/inference/v2/modules/configs/attention_configs.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  copying deepspeed/inference/v2/modules/configs/embedding_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  copying deepspeed/inference/v2/modules/configs/linear_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  copying deepspeed/inference/v2/modules/configs/moe_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  copying deepspeed/inference/v2/modules/configs/norm_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  copying deepspeed/inference/v2/modules/configs/unembed_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations
  copying deepspeed/inference/v2/modules/implementations/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/attention_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/embedding_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/linear_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/moe_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/post_norm_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/pre_norm_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  copying deepspeed/inference/v2/modules/interfaces/unembed_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/attention
  copying deepspeed/inference/v2/modules/implementations/attention/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/attention
  copying deepspeed/inference/v2/modules/implementations/attention/dense_blocked_attention.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/attention
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/embedding
  copying deepspeed/inference/v2/modules/implementations/embedding/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/embedding
  copying deepspeed/inference/v2/modules/implementations/embedding/ragged_embedding.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/embedding
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/linear
  copying deepspeed/inference/v2/modules/implementations/linear/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/linear
  copying deepspeed/inference/v2/modules/implementations/linear/blas_fp_linear.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/linear
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/moe
  copying deepspeed/inference/v2/modules/implementations/moe/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/moe
  copying deepspeed/inference/v2/modules/implementations/moe/cutlass_multi_gemm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/moe
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/post_norm
  copying deepspeed/inference/v2/modules/implementations/post_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/post_norm
  copying deepspeed/inference/v2/modules/implementations/post_norm/cuda_post_ln.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/post_norm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/pre_norm
  copying deepspeed/inference/v2/modules/implementations/pre_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/pre_norm
  copying deepspeed/inference/v2/modules/implementations/pre_norm/cuda_pre_ln.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/pre_norm
  copying deepspeed/inference/v2/modules/implementations/pre_norm/cuda_pre_rms.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/pre_norm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/unembed
  copying deepspeed/inference/v2/modules/implementations/unembed/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/unembed
  copying deepspeed/inference/v2/modules/implementations/unembed/ragged_unembed.py -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/unembed
  creating build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/diffusers
  copying deepspeed/model_implementations/diffusers/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/diffusers
  copying deepspeed/model_implementations/diffusers/unet.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/diffusers
  copying deepspeed/model_implementations/diffusers/vae.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/diffusers
  creating build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/features
  copying deepspeed/model_implementations/features/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/features
  copying deepspeed/model_implementations/features/cuda_graph.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/features
  creating build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/clip_encoder.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_bert.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_bloom.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_gpt.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_llama2.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_megatron_gpt.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_opt.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  copying deepspeed/model_implementations/transformers/ds_transformer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers
  creating build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/base_moe.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/bert.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/bloom.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/clip.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/distil_bert.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/gpt2.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/gptj.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/gptneo.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/gptneox.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/internlm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/llama.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/llama2.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/megatron_gpt.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/megatron_gpt_moe.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/opt.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/unet.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  copying deepspeed/module_inject/containers/vae.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers
  creating build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  copying deepspeed/module_inject/containers/features/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  copying deepspeed/module_inject/containers/features/gated_mlp.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  copying deepspeed/module_inject/containers/features/hybrid_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  copying deepspeed/module_inject/containers/features/hybrid_megatron.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  copying deepspeed/module_inject/containers/features/megatron.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  copying deepspeed/module_inject/containers/features/meta_tensor.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  copying deepspeed/module_inject/containers/features/split_qkv.py -> build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/adagrad
  copying deepspeed/ops/adagrad/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/adagrad
  copying deepspeed/ops/adagrad/cpu_adagrad.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/adagrad
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam
  copying deepspeed/ops/adam/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam
  copying deepspeed/ops/adam/cpu_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam
  copying deepspeed/ops/adam/fused_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam
  copying deepspeed/ops/adam/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/aio
  copying deepspeed/ops/aio/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/aio
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/deepspeed4science
  copying deepspeed/ops/deepspeed4science/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/deepspeed4science
  copying deepspeed/ops/deepspeed4science/evoformer_attn.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/deepspeed4science
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/lamb
  copying deepspeed/ops/lamb/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/lamb
  copying deepspeed/ops/lamb/fused_lamb.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/lamb
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion
  copying deepspeed/ops/lion/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion
  copying deepspeed/ops/lion/cpu_lion.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion
  copying deepspeed/ops/lion/fused_lion.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion
  copying deepspeed/ops/lion/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/all_ops.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/async_io.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/builder.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/cpu_adagrad.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/cpu_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/cpu_lion.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/evoformer_attn.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/fused_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/fused_lamb.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/fused_lion.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/inference_core_ops.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/inference_cutlass_builder.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/quantizer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/ragged_ops.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/ragged_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/random_ltd.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/sparse_attn.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/spatial_inference.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/stochastic_transformer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/transformer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  copying deepspeed/ops/op_builder/transformer_inference.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/quantizer
  copying deepspeed/ops/quantizer/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/quantizer
  copying deepspeed/ops/quantizer/quantizer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/quantizer
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/random_ltd
  copying deepspeed/ops/random_ltd/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/random_ltd
  copying deepspeed/ops/random_ltd/dropping_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/random_ltd
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  copying deepspeed/ops/sparse_attention/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  copying deepspeed/ops/sparse_attention/bert_sparse_self_attention.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  copying deepspeed/ops/sparse_attention/matmul.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  copying deepspeed/ops/sparse_attention/softmax.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  copying deepspeed/ops/sparse_attention/sparse_attention_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  copying deepspeed/ops/sparse_attention/sparse_self_attention.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  copying deepspeed/ops/sparse_attention/sparsity_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer
  copying deepspeed/ops/transformer/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer
  copying deepspeed/ops/transformer/transformer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu
  copying deepspeed/ops/op_builder/cpu/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu
  copying deepspeed/ops/op_builder/cpu/builder.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu
  copying deepspeed/ops/op_builder/cpu/comm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu
  copying deepspeed/ops/op_builder/cpu/cpu_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu
  copying deepspeed/ops/op_builder/cpu/fused_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu
  copying deepspeed/ops/op_builder/cpu/no_impl.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  copying deepspeed/ops/op_builder/npu/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  copying deepspeed/ops/op_builder/npu/builder.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  copying deepspeed/ops/op_builder/npu/cpu_adagrad.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  copying deepspeed/ops/op_builder/npu/cpu_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  copying deepspeed/ops/op_builder/npu/cpu_lion.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  copying deepspeed/ops/op_builder/npu/fused_adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  copying deepspeed/ops/op_builder/npu/no_impl.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc
  copying deepspeed/ops/sparse_attention/trsrc/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/bias_add.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/diffusers_2d_transformer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/diffusers_attention.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/diffusers_transformer_block.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/ds_attention.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/ds_mlp.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/moe_inference.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  copying deepspeed/ops/transformer/inference/triton_ops.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/base.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/gelu_gemm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/linear.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/mlp_gemm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/qkv_gemm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/residual_add.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/softmax.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/softmax_context.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  copying deepspeed/ops/transformer/inference/op_binding/vector_matmul.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/attention.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/gelu.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/layer_norm.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/matmul_ext.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/mlp.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/ops.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/residual_add.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/softmax.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  copying deepspeed/ops/transformer/inference/triton/triton_matmul_kernel.py -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton
  creating build/lib.linux-x86_64-cpython-39/deepspeed/profiling/flops_profiler
  copying deepspeed/profiling/flops_profiler/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/profiling/flops_profiler
  copying deepspeed/profiling/flops_profiler/profiler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/profiling/flops_profiler
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/activation_checkpointing
  copying deepspeed/runtime/activation_checkpointing/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/activation_checkpointing
  copying deepspeed/runtime/activation_checkpointing/checkpointing.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/activation_checkpointing
  copying deepspeed/runtime/activation_checkpointing/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/activation_checkpointing
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine
  copying deepspeed/runtime/checkpoint_engine/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine
  copying deepspeed/runtime/checkpoint_engine/checkpoint_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine
  copying deepspeed/runtime/checkpoint_engine/nebula_checkpoint_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine
  copying deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm
  copying deepspeed/runtime/comm/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm
  copying deepspeed/runtime/comm/coalesced_collectives.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm
  copying deepspeed/runtime/comm/mpi.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm
  copying deepspeed/runtime/comm/nccl.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/compression
  copying deepspeed/runtime/compression/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/compression
  copying deepspeed/runtime/compression/cupy.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/compression
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline
  copying deepspeed/runtime/data_pipeline/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline
  copying deepspeed/runtime/data_pipeline/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline
  copying deepspeed/runtime/data_pipeline/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline
  copying deepspeed/runtime/data_pipeline/curriculum_scheduler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16
  copying deepspeed/runtime/fp16/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16
  copying deepspeed/runtime/fp16/fused_optimizer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16
  copying deepspeed/runtime/fp16/loss_scaler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16
  copying deepspeed/runtime/fp16/unfused_optimizer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe
  copying deepspeed/runtime/pipe/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe
  copying deepspeed/runtime/pipe/engine.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe
  copying deepspeed/runtime/pipe/module.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe
  copying deepspeed/runtime/pipe/p2p.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe
  copying deepspeed/runtime/pipe/schedule.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe
  copying deepspeed/runtime/pipe/topology.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/aio_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/async_swapper.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/constants.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/optimizer_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/partitioned_optimizer_swapper.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/partitioned_param_swapper.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/pipelined_optimizer_swapper.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  copying deepspeed/runtime/swap_tensor/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/contiguous_memory_allocator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/linear.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/mics.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/mics_utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/offload_config.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/parameter_offload.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/partition_parameters.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/partitioned_param_coordinator.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/partitioned_param_profiler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/stage3.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/stage_1_and_2.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/test.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/tiling.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  copying deepspeed/runtime/zero/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing
  copying deepspeed/runtime/data_pipeline/data_routing/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing
  copying deepspeed/runtime/data_pipeline/data_routing/basic_layer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing
  copying deepspeed/runtime/data_pipeline/data_routing/helper.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing
  copying deepspeed/runtime/data_pipeline/data_routing/scheduler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing
  copying deepspeed/runtime/data_pipeline/data_routing/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling
  copying deepspeed/runtime/data_pipeline/data_sampling/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling
  copying deepspeed/runtime/data_pipeline/data_sampling/data_analyzer.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling
  copying deepspeed/runtime/data_pipeline/data_sampling/data_sampler.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling
  copying deepspeed/runtime/data_pipeline/data_sampling/indexed_dataset.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling
  copying deepspeed/runtime/data_pipeline/data_sampling/utils.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling
  creating build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit
  copying deepspeed/runtime/fp16/onebit/__init__.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit
  copying deepspeed/runtime/fp16/onebit/adam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit
  copying deepspeed/runtime/fp16/onebit/lamb.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit
  copying deepspeed/runtime/fp16/onebit/zoadam.py -> build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit
  running egg_info
  writing deepspeed.egg-info/PKG-INFO
  writing dependency_links to deepspeed.egg-info/dependency_links.txt
  writing entry points to deepspeed.egg-info/entry_points.txt
  writing requirements to deepspeed.egg-info/requires.txt
  writing top-level names to deepspeed.egg-info/top_level.txt
  reading manifest file 'deepspeed.egg-info/SOURCES.txt'
  reading manifest template 'MANIFEST.in'
  warning: no files found matching 'deepspeed/inference/v2/kernels/ragged_ops/libs/*.so'
  warning: no files found matching 'deepspeed/inference/v2/kernels/cutlass_ops/libs/*.so'
  warning: no files found matching '*.hip' under directory 'deepspeed'
  warning: no files found matching '*.cc' under directory 'deepspeed'
  warning: no files found matching '*.tr' under directory 'csrc'
  warning: no files found matching '*.cc' under directory 'csrc'
  warning: no files found matching '*.py' under directory 'benchmarks'
  writing manifest file 'deepspeed.egg-info/SOURCES.txt'
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.autotuning.config_templates' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.autotuning.config_templates' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.autotuning.config_templates' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.autotuning.config_templates' to be distributed and are
          already explicitly excluding 'deepspeed.autotuning.config_templates' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.inference.v2.kernels.cutlass_ops.shared_resources' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.inference.v2.kernels.cutlass_ops.shared_resources' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.inference.v2.kernels.cutlass_ops.shared_resources' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.inference.v2.kernels.cutlass_ops.shared_resources' to be distributed and are
          already explicitly excluding 'deepspeed.inference.v2.kernels.cutlass_ops.shared_resources' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.inference.v2.kernels.includes' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.inference.v2.kernels.includes' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.inference.v2.kernels.includes' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.inference.v2.kernels.includes' to be distributed and are
          already explicitly excluding 'deepspeed.inference.v2.kernels.includes' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.inference.v2.kernels.ragged_ops.ragged_helpers' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.inference.v2.kernels.ragged_ops.ragged_helpers' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.inference.v2.kernels.ragged_ops.ragged_helpers' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.inference.v2.kernels.ragged_ops.ragged_helpers' to be distributed and are
          already explicitly excluding 'deepspeed.inference.v2.kernels.ragged_ops.ragged_helpers' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.inference.v2.ragged.csrc' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.inference.v2.ragged.csrc' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.inference.v2.ragged.csrc' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.inference.v2.ragged.csrc' to be distributed and are
          already explicitly excluding 'deepspeed.inference.v2.ragged.csrc' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.inference.v2.ragged.includes' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.inference.v2.ragged.includes' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.inference.v2.ragged.includes' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.inference.v2.ragged.includes' to be distributed and are
          already explicitly excluding 'deepspeed.inference.v2.ragged.includes' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.adagrad' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.adagrad' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.adagrad' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.adagrad' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.adagrad' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.adam' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.adam' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.adam' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.adam' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.adam' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.aio.common' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.aio.common' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.aio.common' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.aio.common' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.aio.common' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.aio.py_lib' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.aio.py_lib' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.aio.py_lib' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.aio.py_lib' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.aio.py_lib' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.aio.py_test' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.aio.py_test' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.aio.py_test' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.aio.py_test' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.aio.py_test' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.common' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.common' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.common' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.common' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.common' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.cpu.adam' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.cpu.adam' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.cpu.adam' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.cpu.adam' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.cpu.adam' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.cpu.comm' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.cpu.comm' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.cpu.comm' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.cpu.comm' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.cpu.comm' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.cpu.lion' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.cpu.lion' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.cpu.lion' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.cpu.lion' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.cpu.lion' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.epilogue' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.epilogue' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.epilogue' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.epilogue' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.epilogue' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.gemm' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.gemm' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.gemm' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.gemm' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.gemm' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.iterators' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.iterators' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.iterators' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.iterators' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.iterators' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.transform' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.transform' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.transform' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.transform' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.deepspeed4science.evoformer_attn.transform' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.includes' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.includes' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.includes' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.includes' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.includes' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.lamb' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.lamb' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.lamb' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.lamb' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.lamb' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.lion' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.lion' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.lion' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.lion' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.lion' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.quantization' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.quantization' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.quantization' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.quantization' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.quantization' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.random_ltd' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.random_ltd' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.random_ltd' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.random_ltd' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.random_ltd' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.sparse_attention' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.sparse_attention' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.sparse_attention' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.sparse_attention' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.sparse_attention' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.spatial.csrc' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.spatial.csrc' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.spatial.csrc' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.spatial.csrc' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.spatial.csrc' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.spatial.includes' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.spatial.includes' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.spatial.includes' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.spatial.includes' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.spatial.includes' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.transformer' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.transformer' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.transformer' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.transformer' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.transformer' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.transformer.inference.csrc' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.transformer.inference.csrc' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.transformer.inference.csrc' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.transformer.inference.csrc' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.transformer.inference.csrc' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.transformer.inference.includes' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.transformer.inference.includes' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.transformer.inference.includes' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.transformer.inference.includes' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.transformer.inference.includes' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/command/build_py.py:215: _Warning: Package 'deepspeed.ops.csrc.utils' is absent from the `packages` configuration.
  !!

          ********************************************************************************
          ############################
          # Package would be ignored #
          ############################
          Python recognizes 'deepspeed.ops.csrc.utils' as an importable package[^1],
          but it is absent from setuptools' `packages` configuration.

          This leads to an ambiguous overall configuration. If you want to distribute this
          package, please make sure that 'deepspeed.ops.csrc.utils' is explicitly added
          to the `packages` configuration field.

          Alternatively, you can also rely on setuptools' discovery methods
          (for example by using `find_namespace_packages(...)`/`find_namespace:`
          instead of `find_packages(...)`/`find:`).

          You can read more about "package discovery" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html

          If you don't want 'deepspeed.ops.csrc.utils' to be distributed and are
          already explicitly excluding 'deepspeed.ops.csrc.utils' via
          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,
          you can try to use `exclude_package_data`, or `include-package-data=False` in
          combination with a more fine grained `package-data` configuration.

          You can read more about "package data files" on setuptools documentation page:

          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html


          [^1]: For Python, any directory (with suitable naming) can be imported,
                even if it does not contain any `.py` files.
                On the other hand, currently there is no concept of package data
                directory, all directories are treated like packages.
          ********************************************************************************

  !!
    check.warn(importable)
  creating build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates
  copying deepspeed/autotuning/config_templates/template_zero0.json -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates
  copying deepspeed/autotuning/config_templates/template_zero1.json -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates
  copying deepspeed/autotuning/config_templates/template_zero2.json -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates
  copying deepspeed/autotuning/config_templates/template_zero3.json -> build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adagrad
  copying deepspeed/ops/csrc/adagrad/cpu_adagrad.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adagrad
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam
  copying deepspeed/ops/csrc/adam/cpu_adam.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam
  copying deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam
  copying deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam
  copying deepspeed/ops/csrc/adam/multi_tensor_adam.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam
  copying deepspeed/ops/csrc/adam/multi_tensor_apply.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common
  copying deepspeed/ops/csrc/aio/common/deepspeed_aio_common.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common
  copying deepspeed/ops/csrc/aio/common/deepspeed_aio_common.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common
  copying deepspeed/ops/csrc/aio/common/deepspeed_aio_types.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common
  copying deepspeed/ops/csrc/aio/common/deepspeed_aio_types.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common
  copying deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common
  copying deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_pin_tensor.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_pin_tensor.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  copying deepspeed/ops/csrc/aio/py_lib/py_ds_aio.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_test
  copying deepspeed/ops/csrc/aio/py_test/single_process_config.json -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_test
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/common
  copying deepspeed/ops/csrc/common/custom_cuda_kernel.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/common
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/adam
  copying deepspeed/ops/csrc/cpu/adam/fused_adam.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/adam
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/comm
  copying deepspeed/ops/csrc/cpu/comm/ccl.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/comm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/lion
  copying deepspeed/ops/csrc/cpu/lion/fused_lion.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/lion
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_back.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_cu.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm_kernel_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/kernel_backward.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/kernel_forward.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_grad_bias.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_pipelined.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_rescale_output.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_thread_apply_logsumexp.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_base.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_multistage.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_pipelined.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/find_default_mma.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/mma_accum_lambda_iterator.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/mma_from_smem.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/epilogue_predicated_tile_iterator.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/make_residual_last.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_access_iterator_residual_last.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_iterator_atomic.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_iterator_residual_last.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/transpose_warp_iterator.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/warp_iterator_from_smem.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform/bias_broadcast.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform
  copying deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform/tile_smem_loader.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/StopWatch.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/Timer.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/activation_type.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/compat.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/context.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/conversion_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/cpu_adagrad.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/cpu_adam.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/cpu_lion.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/cublas_wrappers.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/custom_cuda_layers.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/dequantization_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/dropout.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/ds_kernel_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/ds_transformer_cuda.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/feed_forward.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/gelu.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/gemm_test.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/general_kernels.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/memory_access_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/normalize_layer.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/quantization.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/quantization_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/quantizer.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/reduction_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/simd.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/softmax.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/strided_batch_gemm.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  copying deepspeed/ops/csrc/includes/type_shim.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lamb
  copying deepspeed/ops/csrc/lamb/fused_lamb_cuda.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lamb
  copying deepspeed/ops/csrc/lamb/fused_lamb_cuda_kernel.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lamb
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion
  copying deepspeed/ops/csrc/lion/cpu_lion.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion
  copying deepspeed/ops/csrc/lion/cpu_lion_impl.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion
  copying deepspeed/ops/csrc/lion/fused_lion_frontend.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion
  copying deepspeed/ops/csrc/lion/multi_tensor_apply.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion
  copying deepspeed/ops/csrc/lion/multi_tensor_lion.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  copying deepspeed/ops/csrc/quantization/dequantize.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  copying deepspeed/ops/csrc/quantization/fake_quantizer.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  copying deepspeed/ops/csrc/quantization/pt_binding.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  copying deepspeed/ops/csrc/quantization/quant_reduce.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  copying deepspeed/ops/csrc/quantization/quantize.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  copying deepspeed/ops/csrc/quantization/quantize_intX.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  copying deepspeed/ops/csrc/quantization/swizzled_quantize.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd
  copying deepspeed/ops/csrc/random_ltd/gather_scatter.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd
  copying deepspeed/ops/csrc/random_ltd/pt_binding.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd
  copying deepspeed/ops/csrc/random_ltd/slice_attn_masks.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd
  copying deepspeed/ops/csrc/random_ltd/token_sort.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/sparse_attention
  copying deepspeed/ops/csrc/sparse_attention/utils.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/sparse_attention
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/csrc
  copying deepspeed/ops/csrc/spatial/csrc/opt_bias_add.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/csrc
  copying deepspeed/ops/csrc/spatial/csrc/pt_binding.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/csrc
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/includes
  copying deepspeed/ops/csrc/spatial/includes/spatial_cuda_layers.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/includes
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/cublas_wrappers.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/dropout_kernels.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/ds_transformer_cuda.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/gelu_kernels.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/general_kernels.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/normalize_kernels.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/softmax_kernels.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  copying deepspeed/ops/csrc/transformer/transform_kernels.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/apply_rotary_pos_emb.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/dequantize.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/gelu.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/layer_norm.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/pointwise_ops.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/pt_binding.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/relu.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/rms_norm.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  copying deepspeed/ops/csrc/transformer/inference/csrc/transform.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/includes
  copying deepspeed/ops/csrc/transformer/inference/includes/inference_context.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/includes
  copying deepspeed/ops/csrc/transformer/inference/includes/inference_cublas_wrappers.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/includes
  copying deepspeed/ops/csrc/transformer/inference/includes/inference_cuda_layers.h -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/includes
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/utils
  copying deepspeed/ops/csrc/utils/flatten_unflatten.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/utils
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes
  copying deepspeed/inference/v2/kernels/includes/activation_type.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes
  copying deepspeed/inference/v2/kernels/includes/conversion_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes
  copying deepspeed/inference/v2/kernels/includes/ds_kernel_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes
  copying deepspeed/inference/v2/kernels/includes/memory_access_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes
  copying deepspeed/inference/v2/kernels/includes/reduction_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc
  copying deepspeed/inference/v2/ragged/csrc/fast_host_buffer.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc
  copying deepspeed/inference/v2/ragged/csrc/ragged_ops.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/includes
  copying deepspeed/inference/v2/ragged/includes/fast_host_buffer.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/includes
  copying deepspeed/inference/v2/kernels/core_ops/core_ops.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops
  copying deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/shared_resources
  copying deepspeed/inference/v2/kernels/cutlass_ops/shared_resources/weight_variant.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/shared_resources
  copying deepspeed/inference/v2/kernels/ragged_ops/ragged_ops.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops
  creating build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_dtypes.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas_utils.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm_api.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm_api.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/attention_atom.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/flash.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying deepspeed/inference/v2/kernels/ragged_ops/embed/embed.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cpp -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cu -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cuh -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.h -> build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying deepspeed/ops/sparse_attention/trsrc/matmul.tr -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc
  copying deepspeed/ops/sparse_attention/trsrc/softmax_bwd.tr -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc
  copying deepspeed/ops/sparse_attention/trsrc/softmax_fwd.tr -> build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc
  running build_ext
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no g++ version bounds defined for CUDA version 11.8
    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')
  building 'deepspeed.ops.aio.async_io_op' extension
  creating build/temp.linux-x86_64-cpython-39
  creating build/temp.linux-x86_64-cpython-39/csrc
  creating build/temp.linux-x86_64-cpython-39/csrc/aio
  creating build/temp.linux-x86_64-cpython-39/csrc/aio/common
  creating build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/common/deepspeed_aio_common.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/common/deepspeed_aio_common.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/aio/common/deepspeed_aio_common.cpp: In function â€˜void _do_io_submit_singles(long long int, long long int, std::unique_ptr<aio_context>&, std::vector<std::chrono::duration<double> >&)â€™:
  csrc/aio/common/deepspeed_aio_common.cpp:78:20: warning: unused variable â€˜submit_retâ€™ [-Wunused-variable]
           const auto submit_ret = io_submit(aio_ctxt->_io_ctxt, 1, aio_ctxt->_iocbs.data() + i);
                      ^~~~~~~~~~
  csrc/aio/common/deepspeed_aio_common.cpp: In function â€˜void _do_io_submit_block(long long int, long long int, std::unique_ptr<aio_context>&, std::vector<std::chrono::duration<double> >&)â€™:
  csrc/aio/common/deepspeed_aio_common.cpp:98:16: warning: unused variable â€˜submit_retâ€™ [-Wunused-variable]
       const auto submit_ret = io_submit(aio_ctxt->_io_ctxt, n_iocbs, aio_ctxt->_iocbs.data());
                  ^~~~~~~~~~
  csrc/aio/common/deepspeed_aio_common.cpp: In function â€˜int regular_read(const char*, std::vector<char>&)â€™:
  csrc/aio/common/deepspeed_aio_common.cpp:285:16: warning: unused variable â€˜f_sizeâ€™ [-Wunused-variable]
       const auto f_size = get_file_size(filename, num_bytes);
                  ^~~~~~
  csrc/aio/common/deepspeed_aio_common.cpp: In function â€˜bool _validate_buffer(const char*, void*, long long int)â€™:
  csrc/aio/common/deepspeed_aio_common.cpp:312:16: warning: unused variable â€˜reg_retâ€™ [-Wunused-variable]
       const auto reg_ret = regular_read(filename, regular_buffer);
                  ^~~~~~~
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/common/deepspeed_aio_types.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/common/deepspeed_aio_types.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/common/deepspeed_aio_utils.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/common/deepspeed_aio_utils.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/py_lib/deepspeed_aio_thread.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_aio_thread.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/py_lib/deepspeed_pin_tensor.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_pin_tensor.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/py_lib/deepspeed_py_aio.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_py_aio.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/py_lib/deepspeed_py_aio_handle.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_py_aio_handle.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/py_lib/deepspeed_py_copy.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_py_copy.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/aio/py_lib -Icsrc/aio/common -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/aio/py_lib/py_ds_aio.cpp -o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/py_ds_aio.o -g -Wall -O0 -std=c++17 -shared -fPIC -Wno-reorder -march=native -fopenmp -D__AVX512__ -laio -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=async_io_op -D_GLIBCXX_USE_CXX11_ABI=0
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/Exceptions.h:14,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/python.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:9,
                   from csrc/aio/py_lib/py_ds_aio.cpp:10:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/pybind11/pybind11.h: In instantiation of â€˜class pybind11::class_<deepspeed_aio_handle_t>â€™:
  csrc/aio/py_lib/py_ds_aio.cpp:22:55:   required from here
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/pybind11/pybind11.h:1496:7: warning: â€˜pybind11::class_<deepspeed_aio_handle_t>â€™ declared with greater visibility than its base â€˜pybind11::detail::generic_typeâ€™ [-Wattributes]
   class class_ : public detail::generic_type {
         ^~~~~~
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/aio/common/deepspeed_aio_common.o build/temp.linux-x86_64-cpython-39/csrc/aio/common/deepspeed_aio_types.o build/temp.linux-x86_64-cpython-39/csrc/aio/common/deepspeed_aio_utils.o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_aio_thread.o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_pin_tensor.o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_py_aio.o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_py_aio_handle.o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/deepspeed_py_copy.o build/temp.linux-x86_64-cpython-39/csrc/aio/py_lib/py_ds_aio.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/aio/async_io_op.cpython-39-x86_64-linux-gnu.so -laio
  building 'deepspeed.ops.adam.fused_adam_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/adam
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -Icsrc/adam -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/adam/fused_adam_frontend.cpp -o build/temp.linux-x86_64-cpython-39/csrc/adam/fused_adam_frontend.o -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_adam_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -Icsrc/adam -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/adam/multi_tensor_adam.cu -o build/temp.linux-x86_64-cpython-39/csrc/adam/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_adam_op -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/adam/fused_adam_frontend.o build/temp.linux-x86_64-cpython-39/csrc/adam/multi_tensor_adam.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/fused_adam_op.cpython-39-x86_64-linux-gnu.so
  building 'deepspeed.ops.adam.cpu_adam_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/common
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/adam/cpu_adam.cpp -o build/temp.linux-x86_64-cpython-39/csrc/adam/cpu_adam.o -O3 -std=c++17 -g -Wno-reorder -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_adam_op -D_GLIBCXX_USE_CXX11_ABI=0
  In file included from csrc/includes/cpu_adam.h:14,
                   from csrc/adam/cpu_adam.cpp:6:
  csrc/includes/simd.h:77: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:84: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:90: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:98: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:106: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:114: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:120: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:126: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:132: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:138: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:144: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:150: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:156: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:162: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:168: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:176: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:182: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:188: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:194: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/adam/cpu_adam_impl.cpp -o build/temp.linux-x86_64-cpython-39/csrc/adam/cpu_adam_impl.o -O3 -std=c++17 -g -Wno-reorder -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_adam_op -D_GLIBCXX_USE_CXX11_ABI=0
  In file included from csrc/includes/cpu_adam.h:14,
                   from csrc/adam/cpu_adam_impl.cpp:12:
  csrc/includes/simd.h:77: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:84: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:90: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:98: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:106: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:114: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:120: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:126: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:132: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:138: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:144: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:150: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:156: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:162: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:168: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:176: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:182: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:188: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:194: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/adam/cpu_adam_impl.cpp: In member function â€˜void Adam_Optimizer::Step_1(float*, float*, float*, float*, size_t, ds_half_precision_t*, bool)â€™:
  csrc/adam/cpu_adam_impl.cpp:52:30: warning: â€˜params_cast_hâ€™ may be used uninitialized in this function [-Wmaybe-uninitialized]
           ds_half_precision_t* params_cast_h;
                                ^~~~~~~~~~~~~
  csrc/adam/cpu_adam_impl.cpp:51:30: warning: â€˜grads_cast_hâ€™ may be used uninitialized in this function [-Wmaybe-uninitialized]
           ds_half_precision_t* grads_cast_h;
                                ^~~~~~~~~~~~
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/common/custom_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-39/csrc/common/custom_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_adam_op -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/adam/cpu_adam.o build/temp.linux-x86_64-cpython-39/csrc/adam/cpu_adam_impl.o build/temp.linux-x86_64-cpython-39/csrc/common/custom_cuda_kernel.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lcurand -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/cpu_adam_op.cpython-39-x86_64-linux-gnu.so -lcurand
  building 'deepspeed.ops.adagrad.cpu_adagrad_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/adagrad
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/adagrad/cpu_adagrad.cpp -o build/temp.linux-x86_64-cpython-39/csrc/adagrad/cpu_adagrad.o -O3 -std=c++17 -g -Wno-reorder -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_adagrad_op -D_GLIBCXX_USE_CXX11_ABI=0
  In file included from csrc/includes/cpu_adagrad.h:13,
                   from csrc/adagrad/cpu_adagrad.cpp:6:
  csrc/includes/simd.h:77: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:84: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:90: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:98: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:106: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:114: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:120: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:126: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:132: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:138: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:144: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:150: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:156: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:162: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:168: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:176: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:182: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:188: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:194: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/adagrad/cpu_adagrad.cpp: In member function â€˜void Adagrad_Optimizer::Step_1(float*, float*, float*, size_t, ds_half_precision_t*, bool)â€™:
  csrc/adagrad/cpu_adagrad.cpp:53:9: warning: â€˜params_cast_hâ€™ may be used uninitialized in this function [-Wmaybe-uninitialized]
   #pragma omp parallel for
           ^~~
  csrc/adagrad/cpu_adagrad.cpp:53:9: warning: â€˜grads_cast_hâ€™ may be used uninitialized in this function [-Wmaybe-uninitialized]
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/common/custom_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-39/csrc/common/custom_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_adagrad_op -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/adagrad/cpu_adagrad.o build/temp.linux-x86_64-cpython-39/csrc/common/custom_cuda_kernel.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lcurand -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/adagrad/cpu_adagrad_op.cpython-39-x86_64-linux-gnu.so -lcurand
  building 'deepspeed.ops.lion.cpu_lion_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/lion
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/common/custom_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-39/csrc/common/custom_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_lion_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/lion/cpu_lion.cpp -o build/temp.linux-x86_64-cpython-39/csrc/lion/cpu_lion.o -O3 -std=c++17 -g -Wno-reorder -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_lion_op -D_GLIBCXX_USE_CXX11_ABI=0
  In file included from csrc/includes/cpu_lion.h:14,
                   from csrc/lion/cpu_lion.cpp:6:
  csrc/includes/simd.h:77: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:84: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:90: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:98: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:106: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:114: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:120: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:126: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:132: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:138: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:144: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:150: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:156: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:162: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:168: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:176: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:182: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:188: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:194: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/lion/cpu_lion_impl.cpp -o build/temp.linux-x86_64-cpython-39/csrc/lion/cpu_lion_impl.o -O3 -std=c++17 -g -Wno-reorder -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX512__ -D__ENABLE_CUDA__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu_lion_op -D_GLIBCXX_USE_CXX11_ABI=0
  In file included from csrc/includes/cpu_lion.h:14,
                   from csrc/lion/cpu_lion_impl.cpp:13:
  csrc/includes/simd.h:77: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:84: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:90: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:98: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:106: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:114: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:120: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:126: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:132: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:138: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:144: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:150: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:156: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:162: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:168: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:176: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:182: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:188: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/includes/simd.h:194: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll

  csrc/lion/cpu_lion_impl.cpp: In member function â€˜void Lion_Optimizer::Step_1(float*, float*, float*, size_t, ds_half_precision_t*, bool)â€™:
  csrc/lion/cpu_lion_impl.cpp:60:9: warning: â€˜params_cast_hâ€™ may be used uninitialized in this function [-Wmaybe-uninitialized]
   #pragma omp parallel for
           ^~~
  csrc/lion/cpu_lion_impl.cpp:60:9: warning: â€˜grads_cast_hâ€™ may be used uninitialized in this function [-Wmaybe-uninitialized]
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/common/custom_cuda_kernel.o build/temp.linux-x86_64-cpython-39/csrc/lion/cpu_lion.o build/temp.linux-x86_64-cpython-39/csrc/lion/cpu_lion_impl.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lcurand -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/cpu_lion_op.cpython-39-x86_64-linux-gnu.so -lcurand
  building 'deepspeed.ops.lamb.fused_lamb_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/lamb
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/lamb/fused_lamb_cuda.cpp -o build/temp.linux-x86_64-cpython-39/csrc/lamb/fused_lamb_cuda.o -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_lamb_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/lamb/fused_lamb_cuda.cpp: In function â€˜at::Tensor lamb(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, float, float, float, float, float, float, int, int, int, float)â€™:
  csrc/lamb/fused_lamb_cuda.cpp:71:34: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
           p.options().dtype(p.type().scalarType() == at::ScalarType::Half ? at::ScalarType::Float
                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from csrc/lamb/fused_lamb_cuda.cpp:6:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  csrc/lamb/fused_lamb_cuda.cpp:72:82: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
                                                                           : p.type().scalarType()));
                                                                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from csrc/lamb/fused_lamb_cuda.cpp:6:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  csrc/lamb/fused_lamb_cuda.cpp:79:34: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
           p.options().dtype(p.type().scalarType() == at::ScalarType::Half ? at::ScalarType::Float
                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from csrc/lamb/fused_lamb_cuda.cpp:6:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  csrc/lamb/fused_lamb_cuda.cpp:80:82: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
                                                                           : p.type().scalarType()));
                                                                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from csrc/lamb/fused_lamb_cuda.cpp:6:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  csrc/lamb/fused_lamb_cuda.cpp:84:34: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
           p.options().dtype(p.type().scalarType() == at::ScalarType::Half ? at::ScalarType::Float
                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from csrc/lamb/fused_lamb_cuda.cpp:6:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  csrc/lamb/fused_lamb_cuda.cpp:85:82: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
                                                                           : p.type().scalarType()));
                                                                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from csrc/lamb/fused_lamb_cuda.cpp:6:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/lamb/fused_lamb_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-39/csrc/lamb/fused_lamb_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_lamb_op -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  csrc/lamb/fused_lamb_cuda_kernel.cu(358): warning #177-D: variable "threads" was declared but never referenced

  csrc/lamb/fused_lamb_cuda_kernel.cu(358): warning #177-D: variable "threads" was declared but never referenced

  csrc/lamb/fused_lamb_cuda_kernel.cu(358): warning #177-D: variable "threads" was declared but never referenced

  csrc/lamb/fused_lamb_cuda_kernel.cu(358): warning #177-D: variable "threads" was declared but never referenced

  csrc/lamb/fused_lamb_cuda_kernel.cu(358): warning #177-D: variable "threads" was declared but never referenced

  csrc/lamb/fused_lamb_cuda_kernel.cu(41): warning #114-D: function "<unnamed>::error" was referenced but not defined

  csrc/lamb/fused_lamb_cuda_kernel.cu: In function â€˜void fused_lamb_cuda(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, float, float, float, float, float, float, int, int, int, float, at::Tensor&, at::Tensor&, at::Tensor&)â€™:
  csrc/lamb/fused_lamb_cuda_kernel.cu:352:12: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
       if (p.type().scalarType() == at::ScalarType::Double)
              ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here
     DeprecatedTypeProperties & type() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:373:12: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
       if (g.type().scalarType() == at::ScalarType::Half) {
              ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here
     DeprecatedTypeProperties & type() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:375:59: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
           AT_ASSERTM(p.type().scalarType() == at::ScalarType::Float,
                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:1: note: declared here
     DeprecatedTypeProperties & type() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu: In lambda function:
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1125: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1173: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1206: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1228: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1250: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1353: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1380: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:163: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:190: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:339: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:387: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:420: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:442: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:464: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:589: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:616: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:647: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu: In lambda function:
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:943: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:990: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1022: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1043: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1064: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1166: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1192: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:160: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                  ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:186: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                            ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:332: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                              ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:379: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:411: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:432: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:453: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:577: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:603: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:633: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu: In lambda function:
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:947: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:998: warning: â€˜T* at::Tensor::data() const [with T = c10::Half]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1030: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1051: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1076: warning: â€˜T* at::Tensor::data() const [with T = c10::Half]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1178: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:1204: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:164: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:190: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:340: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:391: warning: â€˜T* at::Tensor::data() const [with T = c10::Half]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                         ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:423: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                         ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:444: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                              ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:469: warning: â€˜T* at::Tensor::data() const [with T = c10::Half]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:593: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:619: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:379:649: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES_AND_HALF(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu: In lambda function:
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1075: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1105: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1127: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1149: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1252: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1279: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:163: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:190: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:339: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:369: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                   ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:391: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                         ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:413: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                               ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:538: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:565: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:596: warning: â€˜T* at::Tensor::data() const [with T = double]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu: In lambda function:
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:894: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:923: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:944: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:965: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1067: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:1093: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:160: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                  ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:186: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                            ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:332: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                              ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:361: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                           ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:382: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:403: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:527: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:553: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  csrc/lamb/fused_lamb_cuda_kernel.cu:428:583: warning: â€˜T* at::Tensor::data() const [with T = float]â€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]
           AT_DISPATCH_FLOATING_TYPES(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:247:1: note: declared here
     T * data() const {
   ^ ~~
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/lamb/fused_lamb_cuda.o build/temp.linux-x86_64-cpython-39/csrc/lamb/fused_lamb_cuda_kernel.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/lamb/fused_lamb_op.cpython-39-x86_64-linux-gnu.so
  building 'deepspeed.ops.lion.fused_lion_op' extension
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -Icsrc/lion -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/lion/fused_lion_frontend.cpp -o build/temp.linux-x86_64-cpython-39/csrc/lion/fused_lion_frontend.o -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_lion_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -Icsrc/lion -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/lion/multi_tensor_lion.cu -o build/temp.linux-x86_64-cpython-39/csrc/lion/multi_tensor_lion.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=fused_lion_op -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/lion/fused_lion_frontend.o build/temp.linux-x86_64-cpython-39/csrc/lion/multi_tensor_lion.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/fused_lion_op.cpython-39-x86_64-linux-gnu.so
  building 'deepspeed.inference.v2.kernelsinference_core_ops' extension
  creating build/temp.linux-x86_64-cpython-39/deepspeed
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/core_ops.cpp -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/core_ops.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/core_ops/bias_activations -Ideepspeed/inference/v2/kernels/core_ops/blas_kernels -Ideepspeed/inference/v2/kernels/core_ops/cuda_layer_norm -Ideepspeed/inference/v2/kernels/core_ops/cuda_rms_norm -Ideepspeed/inference/v2/kernels/core_ops/gated_activations -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=kernelsinference_core_ops -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/core_ops.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernelsinference_core_ops.cpython-39-x86_64-linux-gnu.so
  building 'deepspeed.inference.v2.kernels.cutlass_ops.cutlass_ops' extension
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm -Ideepspeed/inference/v2/kernels/cutlass_ops/moe_gemm -Ideepspeed/inference/v2/kernels/cutlass_ops/shared_resources/ -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.cpp -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.o -O3 -std=c++17 -g -Wno-reorder -DBF16_AVAILABLE -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cutlass_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm -Ideepspeed/inference/v2/kernels/cutlass_ops/moe_gemm -Ideepspeed/inference/v2/kernels/cutlass_ops/shared_resources/ -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cutlass_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm -Ideepspeed/inference/v2/kernels/cutlass_ops/moe_gemm -Ideepspeed/inference/v2/kernels/cutlass_ops/shared_resources/ -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cutlass_ops -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.cpython-39-x86_64-linux-gnu.so -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/dskernels -ldeepspeedft -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/dskernels
  building 'deepspeed.ops.quantizer.quantizer_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/quantization
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/quantization/dequantize.cu -o build/temp.linux-x86_64-cpython-39/csrc/quantization/dequantize.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=quantizer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/quantization/fake_quantizer.cu -o build/temp.linux-x86_64-cpython-39/csrc/quantization/fake_quantizer.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=quantizer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/quantization/fake_quantizer.cu(32): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(33): warning #177-D: variable "reg_count" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(107): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(109): warning #177-D: variable "reg_count" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(107): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(109): warning #177-D: variable "reg_count" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(107): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(109): warning #177-D: variable "reg_count" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(32): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(33): warning #177-D: variable "reg_count" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(107): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(109): warning #177-D: variable "reg_count" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(32): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(33): warning #177-D: variable "reg_count" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(107): warning #177-D: variable "thread_index" was declared but never referenced

  csrc/quantization/fake_quantizer.cu(109): warning #177-D: variable "reg_count" was declared but never referenced

  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/quantization/pt_binding.cpp -o build/temp.linux-x86_64-cpython-39/csrc/quantization/pt_binding.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=quantizer_op -D_GLIBCXX_USE_CXX11_ABI=0
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/Exceptions.h:14,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/python.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:9,
                   from csrc/quantization/pt_binding.cpp:7:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/pybind11/pybind11.h: In instantiation of â€˜class pybind11::class_<quantize::Type>â€™:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/pybind11/pybind11.h:2170:7:   required from â€˜class pybind11::enum_<quantize::Type>â€™
  csrc/quantization/pt_binding.cpp:283:58:   required from here
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/pybind11/pybind11.h:1496:7: warning: â€˜pybind11::class_<quantize::Type>â€™ declared with greater visibility than its base â€˜pybind11::detail::generic_typeâ€™ [-Wattributes]
   class class_ : public detail::generic_type {
         ^~~~~~
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/quantization/quant_reduce.cu -o build/temp.linux-x86_64-cpython-39/csrc/quantization/quant_reduce.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=quantizer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/quantization/quantize.cu -o build/temp.linux-x86_64-cpython-39/csrc/quantization/quantize.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=quantizer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/quantization/quantize_intX.cu -o build/temp.linux-x86_64-cpython-39/csrc/quantization/quantize_intX.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=quantizer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/quantization/swizzled_quantize.cu -o build/temp.linux-x86_64-cpython-39/csrc/quantization/swizzled_quantize.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=quantizer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/quantization/dequantize.o build/temp.linux-x86_64-cpython-39/csrc/quantization/fake_quantizer.o build/temp.linux-x86_64-cpython-39/csrc/quantization/pt_binding.o build/temp.linux-x86_64-cpython-39/csrc/quantization/quant_reduce.o build/temp.linux-x86_64-cpython-39/csrc/quantization/quantize.o build/temp.linux-x86_64-cpython-39/csrc/quantization/quantize_intX.o build/temp.linux-x86_64-cpython-39/csrc/quantization/swizzled_quantize.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/quantizer/quantizer_op.cpython-39-x86_64-linux-gnu.so -lcurand
  building 'deepspeed.inference.v2.kernels.ragged_ops.ragged_device_ops' extension
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.cpp -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.o -O3 -std=c++17 -g -Wno-reorder -DBF16_AVAILABLE -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.cpp -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.o -O3 -std=c++17 -g -Wno-reorder -DBF16_AVAILABLE -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.cpp: In function â€˜void flash_attn_by_atoms(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, bool)â€™:
  deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.cpp:52:15: warning: unused variable â€˜total_qâ€™ [-Wunused-variable]
       const int total_q = q.size(0);
                 ^~~~~~~
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.cpp -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.o -O3 -std=c++17 -g -Wno-reorder -DBF16_AVAILABLE -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/ragged_ops.cpp -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_ops.o -O3 -std=c++17 -g -Wno-reorder -DBF16_AVAILABLE -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/kernels/includes -Ideepspeed/inference/v2/kernels/ragged_ops -Ideepspeed/inference/v2/kernels/ragged_ops/atom_builder -Ideepspeed/inference/v2/kernels/ragged_ops/blocked_flash -Ideepspeed/inference/v2/kernels/ragged_ops/embed -Ideepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary -Ideepspeed/inference/v2/kernels/ragged_ops/logits_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_gather -Ideepspeed/inference/v2/kernels/ragged_ops/moe_scatter -Ideepspeed/inference/v2/kernels/ragged_ops/ragged_helpers -Ideepspeed/inference/v2/kernels/ragged_ops/top_1_gating -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_device_ops -D_GLIBCXX_USE_CXX11_ABI=0
  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  deepspeed/inference/v2/kernels/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_ops.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_device_ops.cpython-39-x86_64-linux-gnu.so -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/dskernels -lblockedflash -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/dskernels
  building 'deepspeed.inference.v2.ragged_ops' extension
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged
  creating build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Ideepspeed/inference/v2/ragged/includes -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/ragged/csrc/fast_host_buffer.cu -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc/fast_host_buffer.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_ops -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Ideepspeed/inference/v2/ragged/includes -Ideepspeed/inference/v2/kernels/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c deepspeed/inference/v2/ragged/csrc/ragged_ops.cpp -o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc/ragged_ops.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=ragged_ops -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc/fast_host_buffer.o build/temp.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc/ragged_ops.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged_ops.cpython-39-x86_64-linux-gnu.so
  building 'deepspeed.ops.random_ltd_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/random_ltd
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/random_ltd/gather_scatter.cu -o build/temp.linux-x86_64-cpython-39/csrc/random_ltd/gather_scatter.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=random_ltd_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/random_ltd/pt_binding.cpp -o build/temp.linux-x86_64-cpython-39/csrc/random_ltd/pt_binding.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=random_ltd_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/random_ltd/slice_attn_masks.cu -o build/temp.linux-x86_64-cpython-39/csrc/random_ltd/slice_attn_masks.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=random_ltd_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/random_ltd/token_sort.cu -o build/temp.linux-x86_64-cpython-39/csrc/random_ltd/token_sort.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=random_ltd_op -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/random_ltd/gather_scatter.o build/temp.linux-x86_64-cpython-39/csrc/random_ltd/pt_binding.o build/temp.linux-x86_64-cpython-39/csrc/random_ltd/slice_attn_masks.o build/temp.linux-x86_64-cpython-39/csrc/random_ltd/token_sort.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/random_ltd_op.cpython-39-x86_64-linux-gnu.so -lcurand
  building 'deepspeed.ops.spatial.spatial_inference_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/spatial
  creating build/temp.linux-x86_64-cpython-39/csrc/spatial/csrc
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/spatial/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/spatial/csrc/opt_bias_add.cu -o build/temp.linux-x86_64-cpython-39/csrc/spatial/csrc/opt_bias_add.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=spatial_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/spatial/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/spatial/csrc/pt_binding.cpp -o build/temp.linux-x86_64-cpython-39/csrc/spatial/csrc/pt_binding.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=spatial_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  creating build/lib.linux-x86_64-cpython-39/deepspeed/ops/spatial
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/spatial/csrc/opt_bias_add.o build/temp.linux-x86_64-cpython-39/csrc/spatial/csrc/pt_binding.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/spatial/spatial_inference_op.cpython-39-x86_64-linux-gnu.so
  building 'deepspeed.ops.transformer.transformer_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/transformer
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/cublas_wrappers.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/cublas_wrappers.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/dropout_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/dropout_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/ds_transformer_cuda.cpp -o build/temp.linux-x86_64-cpython-39/csrc/transformer/ds_transformer_cuda.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/gelu_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/gelu_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/general_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/general_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/normalize_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/normalize_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/softmax_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/softmax_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/transform_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/transform_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/transformer/cublas_wrappers.o build/temp.linux-x86_64-cpython-39/csrc/transformer/dropout_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/ds_transformer_cuda.o build/temp.linux-x86_64-cpython-39/csrc/transformer/gelu_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/general_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/normalize_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/softmax_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/transform_kernels.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/transformer_op.cpython-39-x86_64-linux-gnu.so -lcurand
  building 'deepspeed.ops.transformer.stochastic_transformer_op' extension
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/cublas_wrappers.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/cublas_wrappers.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -D__STOCHASTIC_MODE__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/dropout_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/dropout_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -D__STOCHASTIC_MODE__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(480): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(541): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(661): warning #177-D: variable "tid" was declared but never referenced

  csrc/transformer/dropout_kernels.cu(738): warning #177-D: variable "tid" was declared but never referenced

  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/ds_transformer_cuda.cpp -o build/temp.linux-x86_64-cpython-39/csrc/transformer/ds_transformer_cuda.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/gelu_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/gelu_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -D__STOCHASTIC_MODE__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/general_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/general_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -D__STOCHASTIC_MODE__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/normalize_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/normalize_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -D__STOCHASTIC_MODE__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  csrc/transformer/normalize_kernels.cu(1051): warning #177-D: variable "block_dim" was declared but never referenced

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/softmax_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/softmax_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -D__STOCHASTIC_MODE__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/transform_kernels.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/transform_kernels.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -D__STOCHASTIC_MODE__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=stochastic_transformer_op -D_GLIBCXX_USE_CXX11_ABI=0
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/transformer/cublas_wrappers.o build/temp.linux-x86_64-cpython-39/csrc/transformer/dropout_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/ds_transformer_cuda.o build/temp.linux-x86_64-cpython-39/csrc/transformer/gelu_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/general_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/normalize_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/softmax_kernels.o build/temp.linux-x86_64-cpython-39/csrc/transformer/transform_kernels.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/stochastic_transformer_op.cpython-39-x86_64-linux-gnu.so -lcurand
  building 'deepspeed.ops.transformer.inference.transformer_inference_op' extension
  creating build/temp.linux-x86_64-cpython-39/csrc/transformer/inference
  creating build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/apply_rotary_pos_emb.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/apply_rotary_pos_emb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/dequantize.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/dequantize.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/gelu.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/gelu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/layer_norm.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/layer_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/pointwise_ops.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/pointwise_ops.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  gcc -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/pt_binding.cpp -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/pt_binding.o -O3 -std=c++17 -g -Wno-reorder -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_softmax_context(at::Tensor&, at::Tensor&, int, bool, bool, int, int, float, bool, bool, int, bool, unsigned int, unsigned int, at::Tensor&, float) [with T = float]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2015:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:541:50: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                                        {hidden_dim * InferenceContext::Instance().GetMaxTokenLength(),
                                         ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:541:50: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp:542:41: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                                         k * InferenceContext::Instance().GetMaxTokenLength(),
                                         ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:542:41: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp:550:38: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                            {hidden_dim * InferenceContext::Instance().GetMaxTokenLength(),
                             ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:550:38: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp:551:29: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                             k * InferenceContext::Instance().GetMaxTokenLength(),
                             ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:551:29: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜at::Tensor ds_bias_residual(at::Tensor&, at::Tensor&, at::Tensor&) [with T = float]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2015:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:655:9: warning: unused variable â€˜bszâ€™ [-Wunused-variable]
       int bsz = input_cont.size(0) * input_cont.size(1);
           ^~~
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_qkv_gemm(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, bool, bool, bool) [with T = float]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2015:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:1028:9: warning: unused variable â€˜bszâ€™ [-Wunused-variable]
       int bsz = input.size(0) * input.size(1);
           ^~~
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_mlp_gemm(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, bool, bool, at::Tensor&, at::Tensor&, bool, int, bool) [with T = float]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2015:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:1525:9: warning: unused variable â€˜bszâ€™ [-Wunused-variable]
       int bsz = input.size(0) * input.size(1);
           ^~~
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_rms_mlp_gemm(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, at::Tensor&, at::Tensor&, bool, int, bool) [with T = float]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2015:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:1581:22: warning: narrowing conversion of â€˜(size_t)mlp_1_out_neuronsâ€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
           at::from_blob(intermediate_ptr, {input.size(0), input.size(1), mlp_1_out_neurons}, options);
           ~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:1581:22: warning: narrowing conversion of â€˜mlp_1_out_neuronsâ€™ from â€˜const size_tâ€™ {aka â€˜const long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_softmax_context(at::Tensor&, at::Tensor&, int, bool, bool, int, int, float, bool, bool, int, bool, unsigned int, unsigned int, at::Tensor&, float) [with T = __half]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2016:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:541:50: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                                        {hidden_dim * InferenceContext::Instance().GetMaxTokenLength(),
                                         ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:541:50: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp:542:41: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                                         k * InferenceContext::Instance().GetMaxTokenLength(),
                                         ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:542:41: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp:550:38: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                            {hidden_dim * InferenceContext::Instance().GetMaxTokenLength(),
                             ~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:550:38: warning: narrowing conversion of â€˜(((size_t)hidden_dim) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp:551:29: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
                             k * InferenceContext::Instance().GetMaxTokenLength(),
                             ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:551:29: warning: narrowing conversion of â€˜(((size_t)k) * (& InferenceContext::Instance())->InferenceContext::GetMaxTokenLength())â€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜at::Tensor ds_bias_residual(at::Tensor&, at::Tensor&, at::Tensor&) [with T = __half]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2016:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:655:9: warning: unused variable â€˜bszâ€™ [-Wunused-variable]
       int bsz = input_cont.size(0) * input_cont.size(1);
           ^~~
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_qkv_gemm(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, bool, bool, bool) [with T = __half]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2016:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:1028:9: warning: unused variable â€˜bszâ€™ [-Wunused-variable]
       int bsz = input.size(0) * input.size(1);
           ^~~
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_mlp_gemm(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, bool, bool, at::Tensor&, at::Tensor&, bool, int, bool) [with T = __half]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2016:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:1525:9: warning: unused variable â€˜bszâ€™ [-Wunused-variable]
       int bsz = input.size(0) * input.size(1);
           ^~~
  csrc/transformer/inference/csrc/pt_binding.cpp: In instantiation of â€˜std::vector<at::Tensor> ds_rms_mlp_gemm(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, float, at::Tensor&, at::Tensor&, bool, int, bool) [with T = __half]â€™:
  csrc/transformer/inference/csrc/pt_binding.cpp:2016:5:   required from here
  csrc/transformer/inference/csrc/pt_binding.cpp:1581:22: warning: narrowing conversion of â€˜(size_t)mlp_1_out_neuronsâ€™ from â€˜size_tâ€™ {aka â€˜long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
           at::from_blob(intermediate_ptr, {input.size(0), input.size(1), mlp_1_out_neurons}, options);
           ~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  csrc/transformer/inference/csrc/pt_binding.cpp:1581:22: warning: narrowing conversion of â€˜mlp_1_out_neuronsâ€™ from â€˜const size_tâ€™ {aka â€˜const long unsigned intâ€™} to â€˜long intâ€™ inside { } [-Wnarrowing]
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/relu.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/relu.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/rms_norm.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/rms_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  csrc/includes/reduction_utils.h(739): warning #1866-D: attribute does not apply to any entity

  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/softmax.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/softmax.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc -Icsrc/transformer/inference/includes -Icsrc/includes -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c csrc/transformer/inference/csrc/transform.cu -o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/transform.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_61,code=sm_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=transformer_inference_op -D_GLIBCXX_USE_CXX11_ABI=0
  csrc/transformer/inference/csrc/transform.cu(38): warning #177-D: variable "d0_stride" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(66): warning #177-D: variable "lane" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(109): warning #177-D: variable "half_dim" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(110): warning #177-D: variable "d0_stride" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(126): warning #177-D: variable "vals_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(127): warning #177-D: variable "output_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(144): warning #177-D: variable "lane" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(38): warning #177-D: variable "d0_stride" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(66): warning #177-D: variable "lane" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(109): warning #177-D: variable "half_dim" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(110): warning #177-D: variable "d0_stride" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(126): warning #177-D: variable "vals_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(127): warning #177-D: variable "output_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(144): warning #177-D: variable "lane" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(38): warning #177-D: variable "d0_stride" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(66): warning #177-D: variable "lane" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(109): warning #177-D: variable "half_dim" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(110): warning #177-D: variable "d0_stride" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(126): warning #177-D: variable "vals_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(127): warning #177-D: variable "output_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(144): warning #177-D: variable "lane" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(38): warning #177-D: variable "d0_stride" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(66): warning #177-D: variable "lane" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(109): warning #177-D: variable "half_dim" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(110): warning #177-D: variable "d0_stride" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(126): warning #177-D: variable "vals_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(127): warning #177-D: variable "output_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(144): warning #177-D: variable "lane" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(38): warning #177-D: variable "d0_stride" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(66): warning #177-D: variable "lane" was declared but never referenced

  csrc/transformer/inference/csrc/transform.cu(109): warning #177-D: variable "half_dim" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(110): warning #177-D: variable "d0_stride" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(126): warning #177-D: variable "vals_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(127): warning #177-D: variable "output_half" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  csrc/transformer/inference/csrc/transform.cu(144): warning #177-D: variable "lane" was declared but never referenced
            detected during instantiation of "void launch_bias_add_transform_0213(T *, T *, T *, const T *, const T *, int, int, unsigned int, int, int, int, int, int, __nv_bool, __nv_bool, cudaStream_t, int, int, float) [with T=__half]"
  (283): here

  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/apply_rotary_pos_emb.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/dequantize.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/gelu.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/layer_norm.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/pointwise_ops.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/pt_binding.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/relu.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/rms_norm.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/softmax.o build/temp.linux-x86_64-cpython-39/csrc/transformer/inference/csrc/transform.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/transformer_inference_op.cpython-39-x86_64-linux-gnu.so -lcurand
  running build_scripts
  creating build/scripts-3.9
  copying and adjusting bin/deepspeed -> build/scripts-3.9
  copying and adjusting bin/deepspeed.pt -> build/scripts-3.9
  copying and adjusting bin/ds -> build/scripts-3.9
  copying bin/ds_ssh -> build/scripts-3.9
  copying and adjusting bin/ds_report -> build/scripts-3.9
  copying and adjusting bin/ds_bench -> build/scripts-3.9
  copying and adjusting bin/dsr -> build/scripts-3.9
  copying and adjusting bin/ds_elastic -> build/scripts-3.9
  changing mode of build/scripts-3.9/deepspeed from 640 to 755
  changing mode of build/scripts-3.9/deepspeed.pt from 640 to 755
  changing mode of build/scripts-3.9/ds from 640 to 755
  changing mode of build/scripts-3.9/ds_ssh from 751 to 755
  changing mode of build/scripts-3.9/ds_report from 640 to 755
  changing mode of build/scripts-3.9/ds_bench from 640 to 755
  changing mode of build/scripts-3.9/dsr from 640 to 755
  changing mode of build/scripts-3.9/ds_elastic from 640 to 755
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
  !!

          ********************************************************************************
          Please avoid running ``setup.py`` directly.
          Instead, use pypa/build, pypa/installer or other
          standards-based tools.

          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
          ********************************************************************************

  !!
    self.initialize_options()
  installing to build/bdist.linux-x86_64/wheel
  running install
  running install_lib
  creating build/bdist.linux-x86_64
  creating build/bdist.linux-x86_64/wheel
  creating build/bdist.linux-x86_64/wheel/deepspeed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/env_report.py -> build/bdist.linux-x86_64/wheel/deepspeed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/git_version_info.py -> build/bdist.linux-x86_64/wheel/deepspeed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/git_version_info_installed.py -> build/bdist.linux-x86_64/wheel/deepspeed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/pydantic_v1.py -> build/bdist.linux-x86_64/wheel/deepspeed
  creating build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  copying build/lib.linux-x86_64-cpython-39/deepspeed/accelerator/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  copying build/lib.linux-x86_64-cpython-39/deepspeed/accelerator/abstract_accelerator.py -> build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  copying build/lib.linux-x86_64-cpython-39/deepspeed/accelerator/cpu_accelerator.py -> build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  copying build/lib.linux-x86_64-cpython-39/deepspeed/accelerator/cuda_accelerator.py -> build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  copying build/lib.linux-x86_64-cpython-39/deepspeed/accelerator/mps_accelerator.py -> build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  copying build/lib.linux-x86_64-cpython-39/deepspeed/accelerator/npu_accelerator.py -> build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  copying build/lib.linux-x86_64-cpython-39/deepspeed/accelerator/real_accelerator.py -> build/bdist.linux-x86_64/wheel/deepspeed/accelerator
  creating build/bdist.linux-x86_64/wheel/deepspeed/autotuning
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/autotuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/scheduler.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning
  creating build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner/base_tuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner/cost_model.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner/index_based_tuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner/model_based_tuner.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/tuner/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/tuner
  creating build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates/template_zero0.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates/template_zero1.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates/template_zero2.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates
  copying build/lib.linux-x86_64-cpython-39/deepspeed/autotuning/config_templates/template_zero3.json -> build/bdist.linux-x86_64/wheel/deepspeed/autotuning/config_templates
  creating build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/deepspeed_checkpoint.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/ds_to_universal.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/reshape_3d_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/reshape_meg_2d.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/reshape_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/universal_checkpoint.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/checkpoint/zero_checkpoint.py -> build/bdist.linux-x86_64/wheel/deepspeed/checkpoint
  creating build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/backend.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/ccl.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/comm.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/reduce_op.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/torch.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/comm/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/comm
  creating build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/basic_layer.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/compress.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/helper.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/scheduler.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/compression/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/compression
  creating build/bdist.linux-x86_64/wheel/deepspeed/elasticity
  copying build/lib.linux-x86_64-cpython-39/deepspeed/elasticity/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity
  copying build/lib.linux-x86_64-cpython-39/deepspeed/elasticity/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity
  copying build/lib.linux-x86_64-cpython-39/deepspeed/elasticity/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity
  copying build/lib.linux-x86_64-cpython-39/deepspeed/elasticity/elastic_agent.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity
  copying build/lib.linux-x86_64-cpython-39/deepspeed/elasticity/elasticity.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity
  copying build/lib.linux-x86_64-cpython-39/deepspeed/elasticity/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/elasticity
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization/layers.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization/quantization.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization/quantization_context.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/quantization/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/quantization
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/allocator.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/config_v2.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/engine_factory.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/engine_v2.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/inference_parameter.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/inference_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/logging.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/scheduling_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint/base_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint/huggingface_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/checkpoint
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/checkpoint/in_memory_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/checkpoint
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ds_kernel.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/bias_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/bias_activations
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas_linear.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/blas_kernels
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_fp_ln_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_ln.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_post_ln.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_pre_ln.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_pre_norm.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops/gated_activations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/core_ops/core_ops.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/core_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm_api.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/mixed_moe_gemm.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm_api.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/shared_resources
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/shared_resources/weight_variant.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops/shared_resources
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/cutlass_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/atom_builder
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/attention_atom.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/flash.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/blocked_flash
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/embed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/embed/embed.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/embed
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_trained_kv_rotary.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/linear_blocked_kv_copy.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/logits_gather
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_gather
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/moe_scatter
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/top_1_gating
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_ops.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_dtypes.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/ragged_ops/ragged_device_ops.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/ragged_ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes/activation_type.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes/conversion_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes/ds_kernel_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes/memory_access_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernels/includes/reduction_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/kernels/includes
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/flat_model_helpers.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/inference_model_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/inference_policy_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/inference_transformer_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/layer_container_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/parameter_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/attn_output_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/embedding_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/invfreq_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/mlp_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/moe_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/norm_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/qkv_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/common_parameters/unembed_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/common_parameters
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/llama_v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/llama_v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_containers.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/llama_v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_model.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/llama_v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_policy.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/llama_v2
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/mistral
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/mistral
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral/container.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/mistral
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral/model.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/mistral
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/mistral/policy.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/mistral
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/opt
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/opt
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt/container.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/opt
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt/model.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/opt
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/opt/policy.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/opt
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/attn.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/attn_out.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/embedding.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/mlp.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/qkv.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/types.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/unembed.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/model_implementations/sharding/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/model_implementations/sharding
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/ds_module.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/heuristics.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/module_registry.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs/attention_configs.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs/embedding_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs/linear_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs/moe_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs/norm_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/configs/unembed_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/configs
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/attention/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/attention/dense_blocked_attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/attention
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/embedding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/embedding/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/embedding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/embedding/ragged_embedding.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/embedding
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/linear
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/linear/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/linear
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/linear/blas_fp_linear.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/linear
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/moe/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/moe/cutlass_multi_gemm.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/moe
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/post_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/post_norm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/post_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/post_norm/cuda_post_ln.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/post_norm
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/pre_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/pre_norm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/pre_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/pre_norm/cuda_pre_ln.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/pre_norm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/pre_norm/cuda_pre_rms.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/pre_norm
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/unembed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/unembed/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/unembed
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/implementations/unembed/ragged_unembed.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/implementations/unembed
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/attention_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/embedding_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/linear_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/moe_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/post_norm_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/pre_norm_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/modules/interfaces/unembed_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/modules/interfaces
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/blocked_allocator.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/kv_cache.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/manager_configs.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/ragged_manager.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/ragged_wrapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/sequence_descriptor.py -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc/fast_host_buffer.cu -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/csrc/ragged_ops.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged/csrc
  creating build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged/includes/fast_host_buffer.h -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2/ragged/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/kernelsinference_core_ops.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  copying build/lib.linux-x86_64-cpython-39/deepspeed/inference/v2/ragged_ops.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/inference/v2
  creating build/bdist.linux-x86_64/wheel/deepspeed/launcher
  copying build/lib.linux-x86_64-cpython-39/deepspeed/launcher/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher
  copying build/lib.linux-x86_64-cpython-39/deepspeed/launcher/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher
  copying build/lib.linux-x86_64-cpython-39/deepspeed/launcher/launch.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher
  copying build/lib.linux-x86_64-cpython-39/deepspeed/launcher/multinode_runner.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher
  copying build/lib.linux-x86_64-cpython-39/deepspeed/launcher/runner.py -> build/bdist.linux-x86_64/wheel/deepspeed/launcher
  creating build/bdist.linux-x86_64/wheel/deepspeed/model_implementations
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations
  creating build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/diffusers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/diffusers/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/diffusers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/diffusers/unet.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/diffusers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/diffusers/vae.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/diffusers
  creating build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/features/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/features/cuda_graph.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/features
  creating build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/clip_encoder.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_base.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_bert.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_bloom.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_gpt.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_llama2.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_megatron_gpt.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_opt.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/model_implementations/transformers/ds_transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/model_implementations/transformers
  creating build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/auto_tp.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/auto_tp_model_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/fusedqkv_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/inject.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/layers.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/load_checkpoint.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/module_quantize.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/policy.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/replace_module.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/replace_policy.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/tp_shard.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject
  creating build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/base.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/base_moe.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/bert.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/bloom.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/clip.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/distil_bert.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/gpt2.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/gptj.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/gptneo.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/gptneox.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/internlm.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/llama.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/llama2.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/megatron_gpt.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/megatron_gpt_moe.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/opt.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/unet.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/vae.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers
  creating build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features/gated_mlp.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features/hybrid_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features/hybrid_megatron.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features/megatron.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features/meta_tensor.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  copying build/lib.linux-x86_64-cpython-39/deepspeed/module_inject/containers/features/split_qkv.py -> build/bdist.linux-x86_64/wheel/deepspeed/module_inject/containers/features
  creating build/bdist.linux-x86_64/wheel/deepspeed/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/moe/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/moe/experts.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/moe/layer.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/moe/mappings.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/moe/sharded_moe.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/moe/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/moe
  creating build/bdist.linux-x86_64/wheel/deepspeed/monitor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/monitor/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/monitor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/monitor/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/monitor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/monitor/csv_monitor.py -> build/bdist.linux-x86_64/wheel/deepspeed/monitor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/monitor/monitor.py -> build/bdist.linux-x86_64/wheel/deepspeed/monitor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/monitor/tensorboard.py -> build/bdist.linux-x86_64/wheel/deepspeed/monitor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/monitor/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/monitor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/monitor/wandb.py -> build/bdist.linux-x86_64/wheel/deepspeed/monitor
  creating build/bdist.linux-x86_64/wheel/deepspeed/nebula
  copying build/lib.linux-x86_64-cpython-39/deepspeed/nebula/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/nebula
  copying build/lib.linux-x86_64-cpython-39/deepspeed/nebula/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/nebula
  copying build/lib.linux-x86_64-cpython-39/deepspeed/nebula/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/nebula
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/adagrad
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adagrad/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adagrad
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adagrad/cpu_adagrad.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adagrad
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adagrad/cpu_adagrad_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adagrad
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/cpu_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/fused_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/fused_adam_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/adam/cpu_adam_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/adam
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/aio
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/aio/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/aio
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/aio/async_io_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/aio
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/deepspeed4science
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/deepspeed4science/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/deepspeed4science
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/deepspeed4science/evoformer_attn.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/deepspeed4science
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/lamb
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lamb/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lamb
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lamb/fused_lamb.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lamb
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lamb/fused_lamb_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lamb
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/cpu_lion.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/fused_lion.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/cpu_lion_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/lion/fused_lion_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/lion
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/all_ops.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/async_io.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/builder.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu_adagrad.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu_lion.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/evoformer_attn.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/fused_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/fused_lamb.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/fused_lion.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/inference_core_ops.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/inference_cutlass_builder.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/quantizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/ragged_ops.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/ragged_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/random_ltd.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/sparse_attn.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/spatial_inference.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/stochastic_transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/transformer_inference.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/cpu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/cpu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu/builder.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/cpu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu/comm.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/cpu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu/cpu_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/cpu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu/fused_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/cpu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/cpu/no_impl.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/cpu
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu/builder.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu/cpu_adagrad.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu/cpu_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu/cpu_lion.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu/fused_adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/op_builder/npu/no_impl.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/op_builder/npu
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/quantizer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/quantizer/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/quantizer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/quantizer/quantizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/quantizer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/quantizer/quantizer_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/quantizer
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/random_ltd
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/random_ltd/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/random_ltd
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/random_ltd/dropping_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/random_ltd
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/bert_sparse_self_attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/matmul.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/softmax.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/sparse_attention_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/sparse_self_attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/sparsity_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc/matmul.tr -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc/softmax_bwd.tr -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/sparse_attention/trsrc/softmax_fwd.tr -> build/bdist.linux-x86_64/wheel/deepspeed/ops/sparse_attention/trsrc
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/bias_add.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/diffusers_2d_transformer.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/diffusers_attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/diffusers_transformer_block.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/ds_attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/ds_mlp.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/moe_inference.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton_ops.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/base.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/gelu_gemm.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/linear.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/mlp_gemm.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/qkv_gemm.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/residual_add.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/softmax.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/softmax_context.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/op_binding/vector_matmul.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/op_binding
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/attention.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/gelu.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/layer_norm.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/matmul_ext.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/mlp.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/ops.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/residual_add.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/softmax.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/triton/triton_matmul_kernel.py -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference/triton
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/inference/transformer_inference_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer/inference
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/transformer_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/transformer/stochastic_transformer_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/transformer
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adagrad
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adagrad/cpu_adagrad.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adagrad
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam/cpu_adam.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/adam/multi_tensor_apply.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/adam
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common/deepspeed_aio_common.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common/deepspeed_aio_common.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common/deepspeed_aio_types.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common/deepspeed_aio_types.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/common
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_pin_tensor.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_pin_tensor.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_lib/py_ds_aio.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_lib
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_test
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/aio/py_test/single_process_config.json -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/aio/py_test
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/common
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/common
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/cpu
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/cpu/adam
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/adam/fused_adam.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/cpu/adam
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/cpu/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/comm/ccl.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/cpu/comm
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/cpu/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/cpu/lion/fused_lion.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/cpu/lion
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_back.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_cu.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm_kernel_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/kernel_backward.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/kernel_forward.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_grad_bias.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_pipelined.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_rescale_output.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_thread_apply_logsumexp.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_base.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_multistage.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_pipelined.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/find_default_mma.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/mma_accum_lambda_iterator.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/mma_from_smem.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/epilogue_predicated_tile_iterator.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/make_residual_last.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_access_iterator_residual_last.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_iterator_atomic.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_iterator_residual_last.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/transpose_warp_iterator.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/warp_iterator_from_smem.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform/bias_broadcast.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform/tile_smem_loader.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/StopWatch.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/Timer.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/activation_type.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/compat.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/context.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/conversion_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/cpu_adagrad.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/cpu_adam.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/cpu_lion.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/cublas_wrappers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/custom_cuda_layers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/dequantization_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/dropout.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/ds_kernel_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/ds_transformer_cuda.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/feed_forward.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/gelu.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/gemm_test.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/general_kernels.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/memory_access_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/normalize_layer.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/quantization.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/quantization_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/quantizer.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/reduction_utils.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/simd.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/softmax.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/strided_batch_gemm.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/includes/type_shim.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/includes
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lamb
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lamb/fused_lamb_cuda.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lamb
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lamb/fused_lamb_cuda_kernel.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lamb
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion/cpu_lion.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion/cpu_lion_impl.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion/fused_lion_frontend.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion/multi_tensor_apply.cuh -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lion
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/lion/multi_tensor_lion.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/lion
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization/dequantize.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization/fake_quantizer.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization/pt_binding.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization/quant_reduce.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization/quantize.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization/quantize_intX.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/quantization/swizzled_quantize.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/quantization
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/random_ltd
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd/gather_scatter.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/random_ltd
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd/pt_binding.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/random_ltd
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd/slice_attn_masks.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/random_ltd
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/random_ltd/token_sort.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/random_ltd
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/sparse_attention
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/sparse_attention/utils.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/sparse_attention
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/spatial
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/spatial/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/csrc/opt_bias_add.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/spatial/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/csrc/pt_binding.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/spatial/csrc
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/spatial/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/spatial/includes/spatial_cuda_layers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/spatial/includes
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/cublas_wrappers.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/dropout_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/ds_transformer_cuda.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/gelu_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/general_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/normalize_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/softmax_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/transform_kernels.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/apply_rotary_pos_emb.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/dequantize.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/gelu.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/layer_norm.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/pointwise_ops.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/pt_binding.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/relu.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/rms_norm.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/csrc/transform.cu -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/csrc
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/includes/inference_context.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/includes/inference_cublas_wrappers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/transformer/inference/includes/inference_cuda_layers.h -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/transformer/inference/includes
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -> build/bdist.linux-x86_64/wheel/deepspeed/ops/csrc/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/random_ltd_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops
  creating build/bdist.linux-x86_64/wheel/deepspeed/ops/spatial
  copying build/lib.linux-x86_64-cpython-39/deepspeed/ops/spatial/spatial_inference_op.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/deepspeed/ops/spatial
  creating build/bdist.linux-x86_64/wheel/deepspeed/pipe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/pipe/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/pipe
  creating build/bdist.linux-x86_64/wheel/deepspeed/profiling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/profiling/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/profiling/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/profiling/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling
  creating build/bdist.linux-x86_64/wheel/deepspeed/profiling/flops_profiler
  copying build/lib.linux-x86_64-cpython-39/deepspeed/profiling/flops_profiler/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling/flops_profiler
  copying build/lib.linux-x86_64-cpython-39/deepspeed/profiling/flops_profiler/profiler.py -> build/bdist.linux-x86_64/wheel/deepspeed/profiling/flops_profiler
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/bf16_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/config_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/dataloader.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/eigenvalue.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/hybrid_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/lr_schedules.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/progressive_layer_drop.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/quantize.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/sparse_tensor.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/state_dict_factory.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/weight_quantizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/activation_checkpointing/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/activation_checkpointing/checkpointing.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/activation_checkpointing/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/activation_checkpointing
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/checkpoint_engine
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/checkpoint_engine
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine/checkpoint_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/checkpoint_engine
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine/nebula_checkpoint_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/checkpoint_engine
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/checkpoint_engine
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm/coalesced_collectives.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm/mpi.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/comm/nccl.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/comm
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/compression/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/compression
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/compression/cupy.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/compression
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/curriculum_scheduler.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_routing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_routing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing/basic_layer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_routing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing/helper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_routing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing/scheduler.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_routing
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_routing/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_routing
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_sampling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_sampling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling/data_analyzer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_sampling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling/data_sampler.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_sampling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling/indexed_dataset.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_sampling
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/data_pipeline/data_sampling/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/data_pipeline/data_sampling
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/fused_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/loss_scaler.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/unfused_optimizer.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit/adam.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit/lamb.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/fp16/onebit/zoadam.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/fp16/onebit
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe/engine.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe/module.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe/p2p.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe/schedule.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/pipe/topology.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/pipe
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/aio_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/async_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/constants.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/optimizer_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/partitioned_optimizer_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/partitioned_param_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/pipelined_optimizer_swapper.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/swap_tensor/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/swap_tensor
  creating build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/contiguous_memory_allocator.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/linear.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/mics.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/mics_utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/offload_config.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/parameter_offload.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/partition_parameters.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/partitioned_param_coordinator.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/partitioned_param_profiler.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/stage3.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/stage_1_and_2.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/test.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/tiling.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  copying build/lib.linux-x86_64-cpython-39/deepspeed/runtime/zero/utils.py -> build/bdist.linux-x86_64/wheel/deepspeed/runtime/zero
  creating build/bdist.linux-x86_64/wheel/deepspeed/sequence
  copying build/lib.linux-x86_64-cpython-39/deepspeed/sequence/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/sequence
  copying build/lib.linux-x86_64-cpython-39/deepspeed/sequence/layer.py -> build/bdist.linux-x86_64/wheel/deepspeed/sequence
  creating build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/__init__.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/comms_logging.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/debug.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/exceptions.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/groups.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/init_on_device.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/logging.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/mixed_precision_linkage.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/numa.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/nvtx.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/tensor_fragment.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/timer.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/types.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  copying build/lib.linux-x86_64-cpython-39/deepspeed/utils/zero_to_fp32.py -> build/bdist.linux-x86_64/wheel/deepspeed/utils
  running install_egg_info
  Copying deepspeed.egg-info to build/bdist.linux-x86_64/wheel/deepspeed-0.12.4-py3.9.egg-info
  running install_scripts
  creating build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data
  creating build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/deepspeed -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/deepspeed.pt -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/ds -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/ds_ssh -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/ds_report -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/ds_bench -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/dsr -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  copying build/scripts-3.9/ds_elastic -> build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/deepspeed to 755
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/deepspeed.pt to 755
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/ds to 755
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/ds_ssh to 755
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/ds_report to 755
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/ds_bench to 755
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/dsr to 755
  changing mode of build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.data/scripts/ds_elastic to 755
  creating build/bdist.linux-x86_64/wheel/deepspeed-0.12.4.dist-info/WHEEL
  creating '/tmp/pip-wheel-1agdlzm5/deepspeed-0.12.4-cp39-cp39-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it
  adding 'deepspeed/__init__.py'
  adding 'deepspeed/constants.py'
  adding 'deepspeed/env_report.py'
  adding 'deepspeed/git_version_info.py'
  adding 'deepspeed/git_version_info_installed.py'
  adding 'deepspeed/pydantic_v1.py'
  adding 'deepspeed/accelerator/__init__.py'
  adding 'deepspeed/accelerator/abstract_accelerator.py'
  adding 'deepspeed/accelerator/cpu_accelerator.py'
  adding 'deepspeed/accelerator/cuda_accelerator.py'
  adding 'deepspeed/accelerator/mps_accelerator.py'
  adding 'deepspeed/accelerator/npu_accelerator.py'
  adding 'deepspeed/accelerator/real_accelerator.py'
  adding 'deepspeed/autotuning/__init__.py'
  adding 'deepspeed/autotuning/autotuner.py'
  adding 'deepspeed/autotuning/config.py'
  adding 'deepspeed/autotuning/constants.py'
  adding 'deepspeed/autotuning/scheduler.py'
  adding 'deepspeed/autotuning/utils.py'
  adding 'deepspeed/autotuning/config_templates/template_zero0.json'
  adding 'deepspeed/autotuning/config_templates/template_zero1.json'
  adding 'deepspeed/autotuning/config_templates/template_zero2.json'
  adding 'deepspeed/autotuning/config_templates/template_zero3.json'
  adding 'deepspeed/autotuning/tuner/__init__.py'
  adding 'deepspeed/autotuning/tuner/base_tuner.py'
  adding 'deepspeed/autotuning/tuner/cost_model.py'
  adding 'deepspeed/autotuning/tuner/index_based_tuner.py'
  adding 'deepspeed/autotuning/tuner/model_based_tuner.py'
  adding 'deepspeed/autotuning/tuner/utils.py'
  adding 'deepspeed/checkpoint/__init__.py'
  adding 'deepspeed/checkpoint/constants.py'
  adding 'deepspeed/checkpoint/deepspeed_checkpoint.py'
  adding 'deepspeed/checkpoint/ds_to_universal.py'
  adding 'deepspeed/checkpoint/reshape_3d_utils.py'
  adding 'deepspeed/checkpoint/reshape_meg_2d.py'
  adding 'deepspeed/checkpoint/reshape_utils.py'
  adding 'deepspeed/checkpoint/universal_checkpoint.py'
  adding 'deepspeed/checkpoint/utils.py'
  adding 'deepspeed/checkpoint/zero_checkpoint.py'
  adding 'deepspeed/comm/__init__.py'
  adding 'deepspeed/comm/backend.py'
  adding 'deepspeed/comm/ccl.py'
  adding 'deepspeed/comm/comm.py'
  adding 'deepspeed/comm/config.py'
  adding 'deepspeed/comm/constants.py'
  adding 'deepspeed/comm/reduce_op.py'
  adding 'deepspeed/comm/torch.py'
  adding 'deepspeed/comm/utils.py'
  adding 'deepspeed/compression/__init__.py'
  adding 'deepspeed/compression/basic_layer.py'
  adding 'deepspeed/compression/compress.py'
  adding 'deepspeed/compression/config.py'
  adding 'deepspeed/compression/constants.py'
  adding 'deepspeed/compression/helper.py'
  adding 'deepspeed/compression/scheduler.py'
  adding 'deepspeed/compression/utils.py'
  adding 'deepspeed/elasticity/__init__.py'
  adding 'deepspeed/elasticity/config.py'
  adding 'deepspeed/elasticity/constants.py'
  adding 'deepspeed/elasticity/elastic_agent.py'
  adding 'deepspeed/elasticity/elasticity.py'
  adding 'deepspeed/elasticity/utils.py'
  adding 'deepspeed/inference/__init__.py'
  adding 'deepspeed/inference/config.py'
  adding 'deepspeed/inference/engine.py'
  adding 'deepspeed/inference/quantization/__init__.py'
  adding 'deepspeed/inference/quantization/layers.py'
  adding 'deepspeed/inference/quantization/quantization.py'
  adding 'deepspeed/inference/quantization/quantization_context.py'
  adding 'deepspeed/inference/quantization/utils.py'
  adding 'deepspeed/inference/v2/__init__.py'
  adding 'deepspeed/inference/v2/allocator.py'
  adding 'deepspeed/inference/v2/config_v2.py'
  adding 'deepspeed/inference/v2/engine_factory.py'
  adding 'deepspeed/inference/v2/engine_v2.py'
  adding 'deepspeed/inference/v2/inference_parameter.py'
  adding 'deepspeed/inference/v2/inference_utils.py'
  adding 'deepspeed/inference/v2/kernelsinference_core_ops.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/inference/v2/logging.py'
  adding 'deepspeed/inference/v2/ragged_ops.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/inference/v2/scheduling_utils.py'
  adding 'deepspeed/inference/v2/checkpoint/__init__.py'
  adding 'deepspeed/inference/v2/checkpoint/base_engine.py'
  adding 'deepspeed/inference/v2/checkpoint/huggingface_engine.py'
  adding 'deepspeed/inference/v2/checkpoint/in_memory_engine.py'
  adding 'deepspeed/inference/v2/kernels/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ds_kernel.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/__init__.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/core_ops.cpp'
  adding 'deepspeed/inference/v2/kernels/core_ops/bias_activations/__init__.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cpp'
  adding 'deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.cu'
  adding 'deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.h'
  adding 'deepspeed/inference/v2/kernels/core_ops/bias_activations/bias_activation.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/blas_kernels/__init__.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas.h'
  adding 'deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas_linear.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/blas_kernels/blas_utils.h'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/__init__.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_fp_ln_base.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_ln.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_post_ln.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/cuda_pre_ln.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cpp'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.cu'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_layer_norm/layer_norm.h'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/__init__.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cpp'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.cu'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.h'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_norm_base.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/cuda_rms_norm/rms_pre_norm.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/gated_activations/__init__.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation.py'
  adding 'deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cpp'
  adding 'deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.cu'
  adding 'deepspeed/inference/v2/kernels/core_ops/gated_activations/gated_activation_kernels.h'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/__init__.py'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.cpp'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/cutlass_ops.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/__init__.py'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.cu'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.h'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm.py'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/mixed_gemm/mixed_gemm_api.h'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/__init__.py'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/mixed_moe_gemm.py'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.cu'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.h'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm.py'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/moe_gemm/moe_gemm_api.h'
  adding 'deepspeed/inference/v2/kernels/cutlass_ops/shared_resources/weight_variant.h'
  adding 'deepspeed/inference/v2/kernels/includes/activation_type.h'
  adding 'deepspeed/inference/v2/kernels/includes/conversion_utils.h'
  adding 'deepspeed/inference/v2/kernels/includes/ds_kernel_utils.h'
  adding 'deepspeed/inference/v2/kernels/includes/memory_access_utils.h'
  adding 'deepspeed/inference/v2/kernels/includes/reduction_utils.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/ragged_device_ops.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/ragged_ops.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/atom_builder/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/atom_builder/atom_builder.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/attention_atom.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/blocked_flash.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/blocked_flash/flash.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/embed/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cu'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/embed/embed.cuh'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/embed/embed.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/embed/embed.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cu'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.cuh'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_kv_rotary.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/blocked_trained_kv_rotary.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/linear_blocked_kv_rotary/linear_blocked_kv_copy.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/logits_gather/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cu'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.cuh'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/logits_gather/logits_gather.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_gather/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cu'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.cuh'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_gather/moe_gather.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cu'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.cuh'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/moe_scatter/moe_scatter.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_dtypes.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/ragged_helpers/ragged_kernel_helpers.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/__init__.py'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cpp'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cu'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.cuh'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.h'
  adding 'deepspeed/inference/v2/kernels/ragged_ops/top_1_gating/top_1_gating.py'
  adding 'deepspeed/inference/v2/model_implementations/__init__.py'
  adding 'deepspeed/inference/v2/model_implementations/flat_model_helpers.py'
  adding 'deepspeed/inference/v2/model_implementations/inference_model_base.py'
  adding 'deepspeed/inference/v2/model_implementations/inference_policy_base.py'
  adding 'deepspeed/inference/v2/model_implementations/inference_transformer_base.py'
  adding 'deepspeed/inference/v2/model_implementations/layer_container_base.py'
  adding 'deepspeed/inference/v2/model_implementations/parameter_base.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/__init__.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/attn_output_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/embedding_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/invfreq_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/mlp_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/moe_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/norm_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/qkv_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/common_parameters/unembed_parameters.py'
  adding 'deepspeed/inference/v2/model_implementations/llama_v2/__init__.py'
  adding 'deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_containers.py'
  adding 'deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_model.py'
  adding 'deepspeed/inference/v2/model_implementations/llama_v2/llama_v2_policy.py'
  adding 'deepspeed/inference/v2/model_implementations/mistral/__init__.py'
  adding 'deepspeed/inference/v2/model_implementations/mistral/container.py'
  adding 'deepspeed/inference/v2/model_implementations/mistral/model.py'
  adding 'deepspeed/inference/v2/model_implementations/mistral/policy.py'
  adding 'deepspeed/inference/v2/model_implementations/opt/__init__.py'
  adding 'deepspeed/inference/v2/model_implementations/opt/container.py'
  adding 'deepspeed/inference/v2/model_implementations/opt/model.py'
  adding 'deepspeed/inference/v2/model_implementations/opt/policy.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/__init__.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/attn.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/attn_out.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/embedding.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/mlp.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/qkv.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/types.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/unembed.py'
  adding 'deepspeed/inference/v2/model_implementations/sharding/utils.py'
  adding 'deepspeed/inference/v2/modules/__init__.py'
  adding 'deepspeed/inference/v2/modules/ds_module.py'
  adding 'deepspeed/inference/v2/modules/heuristics.py'
  adding 'deepspeed/inference/v2/modules/module_registry.py'
  adding 'deepspeed/inference/v2/modules/configs/__init__.py'
  adding 'deepspeed/inference/v2/modules/configs/attention_configs.py'
  adding 'deepspeed/inference/v2/modules/configs/embedding_config.py'
  adding 'deepspeed/inference/v2/modules/configs/linear_config.py'
  adding 'deepspeed/inference/v2/modules/configs/moe_config.py'
  adding 'deepspeed/inference/v2/modules/configs/norm_config.py'
  adding 'deepspeed/inference/v2/modules/configs/unembed_config.py'
  adding 'deepspeed/inference/v2/modules/implementations/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/attention/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/attention/dense_blocked_attention.py'
  adding 'deepspeed/inference/v2/modules/implementations/embedding/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/embedding/ragged_embedding.py'
  adding 'deepspeed/inference/v2/modules/implementations/linear/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/linear/blas_fp_linear.py'
  adding 'deepspeed/inference/v2/modules/implementations/moe/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/moe/cutlass_multi_gemm.py'
  adding 'deepspeed/inference/v2/modules/implementations/post_norm/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/post_norm/cuda_post_ln.py'
  adding 'deepspeed/inference/v2/modules/implementations/pre_norm/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/pre_norm/cuda_pre_ln.py'
  adding 'deepspeed/inference/v2/modules/implementations/pre_norm/cuda_pre_rms.py'
  adding 'deepspeed/inference/v2/modules/implementations/unembed/__init__.py'
  adding 'deepspeed/inference/v2/modules/implementations/unembed/ragged_unembed.py'
  adding 'deepspeed/inference/v2/modules/interfaces/__init__.py'
  adding 'deepspeed/inference/v2/modules/interfaces/attention_base.py'
  adding 'deepspeed/inference/v2/modules/interfaces/embedding_base.py'
  adding 'deepspeed/inference/v2/modules/interfaces/linear_base.py'
  adding 'deepspeed/inference/v2/modules/interfaces/moe_base.py'
  adding 'deepspeed/inference/v2/modules/interfaces/post_norm_base.py'
  adding 'deepspeed/inference/v2/modules/interfaces/pre_norm_base.py'
  adding 'deepspeed/inference/v2/modules/interfaces/unembed_base.py'
  adding 'deepspeed/inference/v2/ragged/__init__.py'
  adding 'deepspeed/inference/v2/ragged/blocked_allocator.py'
  adding 'deepspeed/inference/v2/ragged/kv_cache.py'
  adding 'deepspeed/inference/v2/ragged/manager_configs.py'
  adding 'deepspeed/inference/v2/ragged/ragged_manager.py'
  adding 'deepspeed/inference/v2/ragged/ragged_wrapper.py'
  adding 'deepspeed/inference/v2/ragged/sequence_descriptor.py'
  adding 'deepspeed/inference/v2/ragged/csrc/fast_host_buffer.cu'
  adding 'deepspeed/inference/v2/ragged/csrc/ragged_ops.cpp'
  adding 'deepspeed/inference/v2/ragged/includes/fast_host_buffer.h'
  adding 'deepspeed/launcher/__init__.py'
  adding 'deepspeed/launcher/constants.py'
  adding 'deepspeed/launcher/launch.py'
  adding 'deepspeed/launcher/multinode_runner.py'
  adding 'deepspeed/launcher/runner.py'
  adding 'deepspeed/model_implementations/__init__.py'
  adding 'deepspeed/model_implementations/diffusers/__init__.py'
  adding 'deepspeed/model_implementations/diffusers/unet.py'
  adding 'deepspeed/model_implementations/diffusers/vae.py'
  adding 'deepspeed/model_implementations/features/__init__.py'
  adding 'deepspeed/model_implementations/features/cuda_graph.py'
  adding 'deepspeed/model_implementations/transformers/__init__.py'
  adding 'deepspeed/model_implementations/transformers/clip_encoder.py'
  adding 'deepspeed/model_implementations/transformers/ds_base.py'
  adding 'deepspeed/model_implementations/transformers/ds_bert.py'
  adding 'deepspeed/model_implementations/transformers/ds_bloom.py'
  adding 'deepspeed/model_implementations/transformers/ds_gpt.py'
  adding 'deepspeed/model_implementations/transformers/ds_llama2.py'
  adding 'deepspeed/model_implementations/transformers/ds_megatron_gpt.py'
  adding 'deepspeed/model_implementations/transformers/ds_opt.py'
  adding 'deepspeed/model_implementations/transformers/ds_transformer.py'
  adding 'deepspeed/module_inject/__init__.py'
  adding 'deepspeed/module_inject/auto_tp.py'
  adding 'deepspeed/module_inject/auto_tp_model_utils.py'
  adding 'deepspeed/module_inject/fusedqkv_utils.py'
  adding 'deepspeed/module_inject/inject.py'
  adding 'deepspeed/module_inject/layers.py'
  adding 'deepspeed/module_inject/load_checkpoint.py'
  adding 'deepspeed/module_inject/module_quantize.py'
  adding 'deepspeed/module_inject/policy.py'
  adding 'deepspeed/module_inject/replace_module.py'
  adding 'deepspeed/module_inject/replace_policy.py'
  adding 'deepspeed/module_inject/tp_shard.py'
  adding 'deepspeed/module_inject/utils.py'
  adding 'deepspeed/module_inject/containers/__init__.py'
  adding 'deepspeed/module_inject/containers/base.py'
  adding 'deepspeed/module_inject/containers/base_moe.py'
  adding 'deepspeed/module_inject/containers/bert.py'
  adding 'deepspeed/module_inject/containers/bloom.py'
  adding 'deepspeed/module_inject/containers/clip.py'
  adding 'deepspeed/module_inject/containers/distil_bert.py'
  adding 'deepspeed/module_inject/containers/gpt2.py'
  adding 'deepspeed/module_inject/containers/gptj.py'
  adding 'deepspeed/module_inject/containers/gptneo.py'
  adding 'deepspeed/module_inject/containers/gptneox.py'
  adding 'deepspeed/module_inject/containers/internlm.py'
  adding 'deepspeed/module_inject/containers/llama.py'
  adding 'deepspeed/module_inject/containers/llama2.py'
  adding 'deepspeed/module_inject/containers/megatron_gpt.py'
  adding 'deepspeed/module_inject/containers/megatron_gpt_moe.py'
  adding 'deepspeed/module_inject/containers/opt.py'
  adding 'deepspeed/module_inject/containers/unet.py'
  adding 'deepspeed/module_inject/containers/vae.py'
  adding 'deepspeed/module_inject/containers/features/__init__.py'
  adding 'deepspeed/module_inject/containers/features/gated_mlp.py'
  adding 'deepspeed/module_inject/containers/features/hybrid_engine.py'
  adding 'deepspeed/module_inject/containers/features/hybrid_megatron.py'
  adding 'deepspeed/module_inject/containers/features/megatron.py'
  adding 'deepspeed/module_inject/containers/features/meta_tensor.py'
  adding 'deepspeed/module_inject/containers/features/split_qkv.py'
  adding 'deepspeed/moe/__init__.py'
  adding 'deepspeed/moe/experts.py'
  adding 'deepspeed/moe/layer.py'
  adding 'deepspeed/moe/mappings.py'
  adding 'deepspeed/moe/sharded_moe.py'
  adding 'deepspeed/moe/utils.py'
  adding 'deepspeed/monitor/__init__.py'
  adding 'deepspeed/monitor/config.py'
  adding 'deepspeed/monitor/csv_monitor.py'
  adding 'deepspeed/monitor/monitor.py'
  adding 'deepspeed/monitor/tensorboard.py'
  adding 'deepspeed/monitor/utils.py'
  adding 'deepspeed/monitor/wandb.py'
  adding 'deepspeed/nebula/__init__.py'
  adding 'deepspeed/nebula/config.py'
  adding 'deepspeed/nebula/constants.py'
  adding 'deepspeed/ops/__init__.py'
  adding 'deepspeed/ops/random_ltd_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/adagrad/__init__.py'
  adding 'deepspeed/ops/adagrad/cpu_adagrad.py'
  adding 'deepspeed/ops/adagrad/cpu_adagrad_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/adam/__init__.py'
  adding 'deepspeed/ops/adam/cpu_adam.py'
  adding 'deepspeed/ops/adam/cpu_adam_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/adam/fused_adam.py'
  adding 'deepspeed/ops/adam/fused_adam_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/adam/multi_tensor_apply.py'
  adding 'deepspeed/ops/aio/__init__.py'
  adding 'deepspeed/ops/aio/async_io_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/csrc/adagrad/cpu_adagrad.cpp'
  adding 'deepspeed/ops/csrc/adam/cpu_adam.cpp'
  adding 'deepspeed/ops/csrc/adam/cpu_adam_impl.cpp'
  adding 'deepspeed/ops/csrc/adam/fused_adam_frontend.cpp'
  adding 'deepspeed/ops/csrc/adam/multi_tensor_adam.cu'
  adding 'deepspeed/ops/csrc/adam/multi_tensor_apply.cuh'
  adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_common.cpp'
  adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_common.h'
  adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_types.cpp'
  adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_types.h'
  adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.cpp'
  adding 'deepspeed/ops/csrc/aio/common/deepspeed_aio_utils.h'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.cpp'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_aio_thread.h'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_pin_tensor.cpp'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_pin_tensor.h'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.cpp'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio.h'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.cpp'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_aio_handle.h'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.cpp'
  adding 'deepspeed/ops/csrc/aio/py_lib/deepspeed_py_copy.h'
  adding 'deepspeed/ops/csrc/aio/py_lib/py_ds_aio.cpp'
  adding 'deepspeed/ops/csrc/aio/py_test/single_process_config.json'
  adding 'deepspeed/ops/csrc/common/custom_cuda_kernel.cu'
  adding 'deepspeed/ops/csrc/cpu/adam/fused_adam.cpp'
  adding 'deepspeed/ops/csrc/cpu/comm/ccl.cpp'
  adding 'deepspeed/ops/csrc/cpu/lion/fused_lion.cpp'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention.cpp'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_back.cu'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/attention_cu.cu'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm_kernel_utils.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/kernel_backward.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/kernel_forward.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_grad_bias.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_pipelined.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_rescale_output.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/epilogue/epilogue_thread_apply_logsumexp.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_base.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_multistage.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/custom_mma_pipelined.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/find_default_mma.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/mma_accum_lambda_iterator.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/gemm/mma_from_smem.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/epilogue_predicated_tile_iterator.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/make_residual_last.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_access_iterator_residual_last.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_iterator_atomic.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/predicated_tile_iterator_residual_last.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/transpose_warp_iterator.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/iterators/warp_iterator_from_smem.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform/bias_broadcast.h'
  adding 'deepspeed/ops/csrc/deepspeed4science/evoformer_attn/transform/tile_smem_loader.h'
  adding 'deepspeed/ops/csrc/includes/StopWatch.h'
  adding 'deepspeed/ops/csrc/includes/Timer.h'
  adding 'deepspeed/ops/csrc/includes/activation_type.h'
  adding 'deepspeed/ops/csrc/includes/compat.h'
  adding 'deepspeed/ops/csrc/includes/context.h'
  adding 'deepspeed/ops/csrc/includes/conversion_utils.h'
  adding 'deepspeed/ops/csrc/includes/cpu_adagrad.h'
  adding 'deepspeed/ops/csrc/includes/cpu_adam.h'
  adding 'deepspeed/ops/csrc/includes/cpu_lion.h'
  adding 'deepspeed/ops/csrc/includes/cublas_wrappers.h'
  adding 'deepspeed/ops/csrc/includes/custom_cuda_layers.h'
  adding 'deepspeed/ops/csrc/includes/dequantization_utils.h'
  adding 'deepspeed/ops/csrc/includes/dropout.h'
  adding 'deepspeed/ops/csrc/includes/ds_kernel_utils.h'
  adding 'deepspeed/ops/csrc/includes/ds_transformer_cuda.h'
  adding 'deepspeed/ops/csrc/includes/feed_forward.h'
  adding 'deepspeed/ops/csrc/includes/gelu.h'
  adding 'deepspeed/ops/csrc/includes/gemm_test.h'
  adding 'deepspeed/ops/csrc/includes/general_kernels.h'
  adding 'deepspeed/ops/csrc/includes/memory_access_utils.h'
  adding 'deepspeed/ops/csrc/includes/normalize_layer.h'
  adding 'deepspeed/ops/csrc/includes/quantization.h'
  adding 'deepspeed/ops/csrc/includes/quantization_utils.h'
  adding 'deepspeed/ops/csrc/includes/quantizer.h'
  adding 'deepspeed/ops/csrc/includes/reduction_utils.h'
  adding 'deepspeed/ops/csrc/includes/simd.h'
  adding 'deepspeed/ops/csrc/includes/softmax.h'
  adding 'deepspeed/ops/csrc/includes/strided_batch_gemm.h'
  adding 'deepspeed/ops/csrc/includes/type_shim.h'
  adding 'deepspeed/ops/csrc/lamb/fused_lamb_cuda.cpp'
  adding 'deepspeed/ops/csrc/lamb/fused_lamb_cuda_kernel.cu'
  adding 'deepspeed/ops/csrc/lion/cpu_lion.cpp'
  adding 'deepspeed/ops/csrc/lion/cpu_lion_impl.cpp'
  adding 'deepspeed/ops/csrc/lion/fused_lion_frontend.cpp'
  adding 'deepspeed/ops/csrc/lion/multi_tensor_apply.cuh'
  adding 'deepspeed/ops/csrc/lion/multi_tensor_lion.cu'
  adding 'deepspeed/ops/csrc/quantization/dequantize.cu'
  adding 'deepspeed/ops/csrc/quantization/fake_quantizer.cu'
  adding 'deepspeed/ops/csrc/quantization/pt_binding.cpp'
  adding 'deepspeed/ops/csrc/quantization/quant_reduce.cu'
  adding 'deepspeed/ops/csrc/quantization/quantize.cu'
  adding 'deepspeed/ops/csrc/quantization/quantize_intX.cu'
  adding 'deepspeed/ops/csrc/quantization/swizzled_quantize.cu'
  adding 'deepspeed/ops/csrc/random_ltd/gather_scatter.cu'
  adding 'deepspeed/ops/csrc/random_ltd/pt_binding.cpp'
  adding 'deepspeed/ops/csrc/random_ltd/slice_attn_masks.cu'
  adding 'deepspeed/ops/csrc/random_ltd/token_sort.cu'
  adding 'deepspeed/ops/csrc/sparse_attention/utils.cpp'
  adding 'deepspeed/ops/csrc/spatial/csrc/opt_bias_add.cu'
  adding 'deepspeed/ops/csrc/spatial/csrc/pt_binding.cpp'
  adding 'deepspeed/ops/csrc/spatial/includes/spatial_cuda_layers.h'
  adding 'deepspeed/ops/csrc/transformer/cublas_wrappers.cu'
  adding 'deepspeed/ops/csrc/transformer/dropout_kernels.cu'
  adding 'deepspeed/ops/csrc/transformer/ds_transformer_cuda.cpp'
  adding 'deepspeed/ops/csrc/transformer/gelu_kernels.cu'
  adding 'deepspeed/ops/csrc/transformer/general_kernels.cu'
  adding 'deepspeed/ops/csrc/transformer/normalize_kernels.cu'
  adding 'deepspeed/ops/csrc/transformer/softmax_kernels.cu'
  adding 'deepspeed/ops/csrc/transformer/transform_kernels.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/apply_rotary_pos_emb.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/dequantize.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/gelu.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/layer_norm.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/pointwise_ops.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/pt_binding.cpp'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/relu.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/rms_norm.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/softmax.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/csrc/transform.cu'
  adding 'deepspeed/ops/csrc/transformer/inference/includes/inference_context.h'
  adding 'deepspeed/ops/csrc/transformer/inference/includes/inference_cublas_wrappers.h'
  adding 'deepspeed/ops/csrc/transformer/inference/includes/inference_cuda_layers.h'
  adding 'deepspeed/ops/csrc/utils/flatten_unflatten.cpp'
  adding 'deepspeed/ops/deepspeed4science/__init__.py'
  adding 'deepspeed/ops/deepspeed4science/evoformer_attn.py'
  adding 'deepspeed/ops/lamb/__init__.py'
  adding 'deepspeed/ops/lamb/fused_lamb.py'
  adding 'deepspeed/ops/lamb/fused_lamb_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/lion/__init__.py'
  adding 'deepspeed/ops/lion/cpu_lion.py'
  adding 'deepspeed/ops/lion/cpu_lion_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/lion/fused_lion.py'
  adding 'deepspeed/ops/lion/fused_lion_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/lion/multi_tensor_apply.py'
  adding 'deepspeed/ops/op_builder/__init__.py'
  adding 'deepspeed/ops/op_builder/all_ops.py'
  adding 'deepspeed/ops/op_builder/async_io.py'
  adding 'deepspeed/ops/op_builder/builder.py'
  adding 'deepspeed/ops/op_builder/cpu_adagrad.py'
  adding 'deepspeed/ops/op_builder/cpu_adam.py'
  adding 'deepspeed/ops/op_builder/cpu_lion.py'
  adding 'deepspeed/ops/op_builder/evoformer_attn.py'
  adding 'deepspeed/ops/op_builder/fused_adam.py'
  adding 'deepspeed/ops/op_builder/fused_lamb.py'
  adding 'deepspeed/ops/op_builder/fused_lion.py'
  adding 'deepspeed/ops/op_builder/inference_core_ops.py'
  adding 'deepspeed/ops/op_builder/inference_cutlass_builder.py'
  adding 'deepspeed/ops/op_builder/quantizer.py'
  adding 'deepspeed/ops/op_builder/ragged_ops.py'
  adding 'deepspeed/ops/op_builder/ragged_utils.py'
  adding 'deepspeed/ops/op_builder/random_ltd.py'
  adding 'deepspeed/ops/op_builder/sparse_attn.py'
  adding 'deepspeed/ops/op_builder/spatial_inference.py'
  adding 'deepspeed/ops/op_builder/stochastic_transformer.py'
  adding 'deepspeed/ops/op_builder/transformer.py'
  adding 'deepspeed/ops/op_builder/transformer_inference.py'
  adding 'deepspeed/ops/op_builder/cpu/__init__.py'
  adding 'deepspeed/ops/op_builder/cpu/builder.py'
  adding 'deepspeed/ops/op_builder/cpu/comm.py'
  adding 'deepspeed/ops/op_builder/cpu/cpu_adam.py'
  adding 'deepspeed/ops/op_builder/cpu/fused_adam.py'
  adding 'deepspeed/ops/op_builder/cpu/no_impl.py'
  adding 'deepspeed/ops/op_builder/npu/__init__.py'
  adding 'deepspeed/ops/op_builder/npu/builder.py'
  adding 'deepspeed/ops/op_builder/npu/cpu_adagrad.py'
  adding 'deepspeed/ops/op_builder/npu/cpu_adam.py'
  adding 'deepspeed/ops/op_builder/npu/cpu_lion.py'
  adding 'deepspeed/ops/op_builder/npu/fused_adam.py'
  adding 'deepspeed/ops/op_builder/npu/no_impl.py'
  adding 'deepspeed/ops/quantizer/__init__.py'
  adding 'deepspeed/ops/quantizer/quantizer.py'
  adding 'deepspeed/ops/quantizer/quantizer_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/random_ltd/__init__.py'
  adding 'deepspeed/ops/random_ltd/dropping_utils.py'
  adding 'deepspeed/ops/sparse_attention/__init__.py'
  adding 'deepspeed/ops/sparse_attention/bert_sparse_self_attention.py'
  adding 'deepspeed/ops/sparse_attention/matmul.py'
  adding 'deepspeed/ops/sparse_attention/softmax.py'
  adding 'deepspeed/ops/sparse_attention/sparse_attention_utils.py'
  adding 'deepspeed/ops/sparse_attention/sparse_self_attention.py'
  adding 'deepspeed/ops/sparse_attention/sparsity_config.py'
  adding 'deepspeed/ops/sparse_attention/trsrc/__init__.py'
  adding 'deepspeed/ops/sparse_attention/trsrc/matmul.tr'
  adding 'deepspeed/ops/sparse_attention/trsrc/softmax_bwd.tr'
  adding 'deepspeed/ops/sparse_attention/trsrc/softmax_fwd.tr'
  adding 'deepspeed/ops/spatial/spatial_inference_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/transformer/__init__.py'
  adding 'deepspeed/ops/transformer/stochastic_transformer_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/transformer/transformer.py'
  adding 'deepspeed/ops/transformer/transformer_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/transformer/inference/__init__.py'
  adding 'deepspeed/ops/transformer/inference/bias_add.py'
  adding 'deepspeed/ops/transformer/inference/config.py'
  adding 'deepspeed/ops/transformer/inference/diffusers_2d_transformer.py'
  adding 'deepspeed/ops/transformer/inference/diffusers_attention.py'
  adding 'deepspeed/ops/transformer/inference/diffusers_transformer_block.py'
  adding 'deepspeed/ops/transformer/inference/ds_attention.py'
  adding 'deepspeed/ops/transformer/inference/ds_mlp.py'
  adding 'deepspeed/ops/transformer/inference/moe_inference.py'
  adding 'deepspeed/ops/transformer/inference/transformer_inference_op.cpython-39-x86_64-linux-gnu.so'
  adding 'deepspeed/ops/transformer/inference/triton_ops.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/__init__.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/base.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/gelu_gemm.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/linear.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/mlp_gemm.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/qkv_gemm.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/residual_add.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/softmax.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/softmax_context.py'
  adding 'deepspeed/ops/transformer/inference/op_binding/vector_matmul.py'
  adding 'deepspeed/ops/transformer/inference/triton/__init__.py'
  adding 'deepspeed/ops/transformer/inference/triton/attention.py'
  adding 'deepspeed/ops/transformer/inference/triton/gelu.py'
  adding 'deepspeed/ops/transformer/inference/triton/layer_norm.py'
  adding 'deepspeed/ops/transformer/inference/triton/matmul_ext.py'
  adding 'deepspeed/ops/transformer/inference/triton/mlp.py'
  adding 'deepspeed/ops/transformer/inference/triton/ops.py'
  adding 'deepspeed/ops/transformer/inference/triton/residual_add.py'
  adding 'deepspeed/ops/transformer/inference/triton/softmax.py'
  adding 'deepspeed/ops/transformer/inference/triton/triton_matmul_kernel.py'
  adding 'deepspeed/pipe/__init__.py'
  adding 'deepspeed/profiling/__init__.py'
  adding 'deepspeed/profiling/config.py'
  adding 'deepspeed/profiling/constants.py'
  adding 'deepspeed/profiling/flops_profiler/__init__.py'
  adding 'deepspeed/profiling/flops_profiler/profiler.py'
  adding 'deepspeed/runtime/__init__.py'
  adding 'deepspeed/runtime/bf16_optimizer.py'
  adding 'deepspeed/runtime/config.py'
  adding 'deepspeed/runtime/config_utils.py'
  adding 'deepspeed/runtime/constants.py'
  adding 'deepspeed/runtime/dataloader.py'
  adding 'deepspeed/runtime/eigenvalue.py'
  adding 'deepspeed/runtime/engine.py'
  adding 'deepspeed/runtime/hybrid_engine.py'
  adding 'deepspeed/runtime/lr_schedules.py'
  adding 'deepspeed/runtime/progressive_layer_drop.py'
  adding 'deepspeed/runtime/quantize.py'
  adding 'deepspeed/runtime/sparse_tensor.py'
  adding 'deepspeed/runtime/state_dict_factory.py'
  adding 'deepspeed/runtime/utils.py'
  adding 'deepspeed/runtime/weight_quantizer.py'
  adding 'deepspeed/runtime/activation_checkpointing/__init__.py'
  adding 'deepspeed/runtime/activation_checkpointing/checkpointing.py'
  adding 'deepspeed/runtime/activation_checkpointing/config.py'
  adding 'deepspeed/runtime/checkpoint_engine/__init__.py'
  adding 'deepspeed/runtime/checkpoint_engine/checkpoint_engine.py'
  adding 'deepspeed/runtime/checkpoint_engine/nebula_checkpoint_engine.py'
  adding 'deepspeed/runtime/checkpoint_engine/torch_checkpoint_engine.py'
  adding 'deepspeed/runtime/comm/__init__.py'
  adding 'deepspeed/runtime/comm/coalesced_collectives.py'
  adding 'deepspeed/runtime/comm/mpi.py'
  adding 'deepspeed/runtime/comm/nccl.py'
  adding 'deepspeed/runtime/compression/__init__.py'
  adding 'deepspeed/runtime/compression/cupy.py'
  adding 'deepspeed/runtime/data_pipeline/__init__.py'
  adding 'deepspeed/runtime/data_pipeline/config.py'
  adding 'deepspeed/runtime/data_pipeline/constants.py'
  adding 'deepspeed/runtime/data_pipeline/curriculum_scheduler.py'
  adding 'deepspeed/runtime/data_pipeline/data_routing/__init__.py'
  adding 'deepspeed/runtime/data_pipeline/data_routing/basic_layer.py'
  adding 'deepspeed/runtime/data_pipeline/data_routing/helper.py'
  adding 'deepspeed/runtime/data_pipeline/data_routing/scheduler.py'
  adding 'deepspeed/runtime/data_pipeline/data_routing/utils.py'
  adding 'deepspeed/runtime/data_pipeline/data_sampling/__init__.py'
  adding 'deepspeed/runtime/data_pipeline/data_sampling/data_analyzer.py'
  adding 'deepspeed/runtime/data_pipeline/data_sampling/data_sampler.py'
  adding 'deepspeed/runtime/data_pipeline/data_sampling/indexed_dataset.py'
  adding 'deepspeed/runtime/data_pipeline/data_sampling/utils.py'
  adding 'deepspeed/runtime/fp16/__init__.py'
  adding 'deepspeed/runtime/fp16/fused_optimizer.py'
  adding 'deepspeed/runtime/fp16/loss_scaler.py'
  adding 'deepspeed/runtime/fp16/unfused_optimizer.py'
  adding 'deepspeed/runtime/fp16/onebit/__init__.py'
  adding 'deepspeed/runtime/fp16/onebit/adam.py'
  adding 'deepspeed/runtime/fp16/onebit/lamb.py'
  adding 'deepspeed/runtime/fp16/onebit/zoadam.py'
  adding 'deepspeed/runtime/pipe/__init__.py'
  adding 'deepspeed/runtime/pipe/engine.py'
  adding 'deepspeed/runtime/pipe/module.py'
  adding 'deepspeed/runtime/pipe/p2p.py'
  adding 'deepspeed/runtime/pipe/schedule.py'
  adding 'deepspeed/runtime/pipe/topology.py'
  adding 'deepspeed/runtime/swap_tensor/__init__.py'
  adding 'deepspeed/runtime/swap_tensor/aio_config.py'
  adding 'deepspeed/runtime/swap_tensor/async_swapper.py'
  adding 'deepspeed/runtime/swap_tensor/constants.py'
  adding 'deepspeed/runtime/swap_tensor/optimizer_utils.py'
  adding 'deepspeed/runtime/swap_tensor/partitioned_optimizer_swapper.py'
  adding 'deepspeed/runtime/swap_tensor/partitioned_param_swapper.py'
  adding 'deepspeed/runtime/swap_tensor/pipelined_optimizer_swapper.py'
  adding 'deepspeed/runtime/swap_tensor/utils.py'
  adding 'deepspeed/runtime/zero/__init__.py'
  adding 'deepspeed/runtime/zero/config.py'
  adding 'deepspeed/runtime/zero/contiguous_memory_allocator.py'
  adding 'deepspeed/runtime/zero/linear.py'
  adding 'deepspeed/runtime/zero/mics.py'
  adding 'deepspeed/runtime/zero/mics_utils.py'
  adding 'deepspeed/runtime/zero/offload_config.py'
  adding 'deepspeed/runtime/zero/parameter_offload.py'
  adding 'deepspeed/runtime/zero/partition_parameters.py'
  adding 'deepspeed/runtime/zero/partitioned_param_coordinator.py'
  adding 'deepspeed/runtime/zero/partitioned_param_profiler.py'
  adding 'deepspeed/runtime/zero/stage3.py'
  adding 'deepspeed/runtime/zero/stage_1_and_2.py'
  adding 'deepspeed/runtime/zero/test.py'
  adding 'deepspeed/runtime/zero/tiling.py'
  adding 'deepspeed/runtime/zero/utils.py'
  adding 'deepspeed/sequence/__init__.py'
  adding 'deepspeed/sequence/layer.py'
  adding 'deepspeed/utils/__init__.py'
  adding 'deepspeed/utils/comms_logging.py'
  adding 'deepspeed/utils/debug.py'
  adding 'deepspeed/utils/exceptions.py'
  adding 'deepspeed/utils/groups.py'
  adding 'deepspeed/utils/init_on_device.py'
  adding 'deepspeed/utils/logging.py'
  adding 'deepspeed/utils/mixed_precision_linkage.py'
  adding 'deepspeed/utils/numa.py'
  adding 'deepspeed/utils/nvtx.py'
  adding 'deepspeed/utils/tensor_fragment.py'
  adding 'deepspeed/utils/timer.py'
  adding 'deepspeed/utils/types.py'
  adding 'deepspeed/utils/zero_to_fp32.py'
  adding 'deepspeed-0.12.4.data/scripts/deepspeed'
  adding 'deepspeed-0.12.4.data/scripts/deepspeed.pt'
  adding 'deepspeed-0.12.4.data/scripts/ds'
  adding 'deepspeed-0.12.4.data/scripts/ds_bench'
  adding 'deepspeed-0.12.4.data/scripts/ds_elastic'
  adding 'deepspeed-0.12.4.data/scripts/ds_report'
  adding 'deepspeed-0.12.4.data/scripts/ds_ssh'
  adding 'deepspeed-0.12.4.data/scripts/dsr'
  adding 'deepspeed-0.12.4.dist-info/METADATA'
  adding 'deepspeed-0.12.4.dist-info/WHEEL'
  adding 'deepspeed-0.12.4.dist-info/entry_points.txt'
  adding 'deepspeed-0.12.4.dist-info/top_level.txt'
  adding 'deepspeed-0.12.4.dist-info/RECORD'
  removing build/bdist.linux-x86_64/wheel
  deepspeed build time = 1548.6334388256073 secs
  Building wheel for deepspeed (setup.py): finished with status 'done'
  Created wheel for deepspeed: filename=deepspeed-0.12.4-cp39-cp39-linux_x86_64.whl size=103631812 sha256=5de68e313a275e54989fa2c28ec0123f3b16fe61e8b55a0c84a15bae88f26047
  Stored in directory: /work/02/gb20/b20048/.cache/pip/wheels/5a/b1/89/75e50e2120c0db0004b8514adabb5ec1aec4cce108c06dd7ae
Successfully built deepspeed
Installing collected packages: py-cpuinfo, hjson, pynvml, pydantic-core, annotated-types, pydantic, deepspeed
  changing mode of /work/gb20/b20048/miniconda3/envs/deep/bin/cpuinfo to 755
  changing mode of /work/gb20/b20048/miniconda3/envs/deep/bin/hjson to 755
Successfully installed annotated-types-0.7.0 deepspeed-0.12.4 hjson-3.1.0 py-cpuinfo-9.0.0 pydantic-2.8.2 pydantic-core-2.20.1 pynvml-11.5.3
* Confirming deepspeed installation
[2024-09-02 17:10:51,092] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
[93m [WARNING] [0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch']
torch version .................... 2.1.0+cu118
deepspeed install path ........... ['/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/deepspeed']
deepspeed info ................... 0.12.4, unknown, unknown
torch cuda version ............... 11.8
torch hip version ................ None
nvcc version ..................... 11.8
deepspeed wheel compiled w. ...... torch 2.1, cuda 11.8
shared memory (/dev/shm) size .... 56.00 GB
* Installing NVIDIA apex
Cloning into 'apex'...
Using pip 24.2 from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/pip (python 3.9)
Processing /work/02/gb20/b20048/crypto_llm/train/apex
  Preparing metadata (pyproject.toml): started
  Running command Preparing metadata (pyproject.toml)


  torch.__version__  = 2.1.0+cu118


  running dist_info
  creating /tmp/pip-modern-metadata-5zo5__s_/apex.egg-info
  writing /tmp/pip-modern-metadata-5zo5__s_/apex.egg-info/PKG-INFO
  writing dependency_links to /tmp/pip-modern-metadata-5zo5__s_/apex.egg-info/dependency_links.txt
  writing requirements to /tmp/pip-modern-metadata-5zo5__s_/apex.egg-info/requires.txt
  writing top-level names to /tmp/pip-modern-metadata-5zo5__s_/apex.egg-info/top_level.txt
  writing manifest file '/tmp/pip-modern-metadata-5zo5__s_/apex.egg-info/SOURCES.txt'
  reading manifest file '/tmp/pip-modern-metadata-5zo5__s_/apex.egg-info/SOURCES.txt'
  adding license file 'LICENSE'
  writing manifest file '/tmp/pip-modern-metadata-5zo5__s_/apex.egg-info/SOURCES.txt'
  creating '/tmp/pip-modern-metadata-5zo5__s_/apex-0.1.dist-info'
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: packaging>20.6 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from apex==0.1) (24.1)
Building wheels for collected packages: apex
  Building wheel for apex (pyproject.toml): started
  Running command Building wheel for apex (pyproject.toml)


  torch.__version__  = 2.1.0+cu118



  Compiling cuda extensions with
  nvcc: NVIDIA (R) Cuda compiler driver
  Copyright (c) 2005-2022 NVIDIA Corporation
  Built on Wed_Sep_21_10:33:58_PDT_2022
  Cuda compilation tools, release 11.8, V11.8.89
  Build cuda_11.8.r11.8/compiler.31833905_0
  from /work/opt/local/x86_64/cores/cuda/11.8/bin

  running bdist_wheel
  running build
  running build_py
  creating build
  creating build/lib.linux-x86_64-cpython-39
  creating build/lib.linux-x86_64-cpython-39/apex
  copying apex/_autocast_utils.py -> build/lib.linux-x86_64-cpython-39/apex
  copying apex/__init__.py -> build/lib.linux-x86_64-cpython-39/apex
  creating build/lib.linux-x86_64-cpython-39/apex/normalization
  copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-cpython-39/apex/normalization
  copying apex/normalization/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/normalization
  creating build/lib.linux-x86_64-cpython-39/apex/fp16_utils
  copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-cpython-39/apex/fp16_utils
  copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-39/apex/fp16_utils
  copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/fp16_utils
  copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-cpython-39/apex/fp16_utils
  creating build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/utils.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/scaler.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/opt.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/compat.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/wrap.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/handle.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/_initialize.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/amp.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/__version__.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  copying apex/amp/frontend.py -> build/lib.linux-x86_64-cpython-39/apex/amp
  creating build/lib.linux-x86_64-cpython-39/apex/optimizers
  copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-39/apex/optimizers
  copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-39/apex/optimizers
  copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/optimizers
  copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-39/apex/optimizers
  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-cpython-39/apex/optimizers
  copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-cpython-39/apex/optimizers
  copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-cpython-39/apex/optimizers
  creating build/lib.linux-x86_64-cpython-39/apex/transformer
  copying apex/transformer/utils.py -> build/lib.linux-x86_64-cpython-39/apex/transformer
  copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-cpython-39/apex/transformer
  copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-cpython-39/apex/transformer
  copying apex/transformer/enums.py -> build/lib.linux-x86_64-cpython-39/apex/transformer
  copying apex/transformer/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer
  copying apex/transformer/log_util.py -> build/lib.linux-x86_64-cpython-39/apex/transformer
  copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-cpython-39/apex/transformer
  creating build/lib.linux-x86_64-cpython-39/apex/mlp
  copying apex/mlp/mlp.py -> build/lib.linux-x86_64-cpython-39/apex/mlp
  copying apex/mlp/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/mlp
  creating build/lib.linux-x86_64-cpython-39/apex/fused_dense
  copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-cpython-39/apex/fused_dense
  copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/fused_dense
  creating build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/distributed.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/LARC.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-cpython-39/apex/parallel
  creating build/lib.linux-x86_64-cpython-39/apex/RNN
  copying apex/RNN/cells.py -> build/lib.linux-x86_64-cpython-39/apex/RNN
  copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-cpython-39/apex/RNN
  copying apex/RNN/models.py -> build/lib.linux-x86_64-cpython-39/apex/RNN
  copying apex/RNN/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/RNN
  creating build/lib.linux-x86_64-cpython-39/apex/contrib
  copying apex/contrib/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib
  creating build/lib.linux-x86_64-cpython-39/apex/multi_tensor_apply
  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-39/apex/multi_tensor_apply
  copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/multi_tensor_apply
  creating build/lib.linux-x86_64-cpython-39/apex/amp/lists
  copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-cpython-39/apex/amp/lists
  copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-cpython-39/apex/amp/lists
  copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/amp/lists
  copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-cpython-39/apex/amp/lists
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/amp
  copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/amp
  copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/amp
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/_data
  copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/_data
  copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/_data
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/functional
  copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/functional
  copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/functional
  copying apex/transformer/functional/fused_rope.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/functional
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel
  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel
  copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel
  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel
  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/layers
  copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/layers
  copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/layers
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/testing
  creating build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules
  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules
  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules
  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules
  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules
  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/fmha
  copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/fmha
  copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/fmha
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/xentropy
  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/xentropy
  copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/xentropy
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/conv_bias_relu
  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/conv_bias_relu
  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/conv_bias_relu
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/index_mul_2d
  copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/index_mul_2d
  copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/index_mul_2d
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/layer_norm.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/_mha_kernel.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/fused_adam_swa.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  copying apex/contrib/openfold_triton/mha.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/transducer
  copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/transducer
  copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/transducer
  copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/transducer
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test
  copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/nccl_allocator
  copying apex/contrib/nccl_allocator/nccl_allocator.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/nccl_allocator
  copying apex/contrib/nccl_allocator/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/nccl_allocator
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity
  copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity
  copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity
  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity
  copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/group_norm
  copying apex/contrib/group_norm/group_norm.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/group_norm
  copying apex/contrib/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/group_norm
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/gpu_direct_storage
  copying apex/contrib/gpu_direct_storage/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/gpu_direct_storage
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/cudnn_gbn
  copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/cudnn_gbn
  copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/cudnn_gbn
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/clip_grad
  copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/clip_grad
  copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/clip_grad
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck
  copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck
  copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck
  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck
  copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/groupbn
  copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/groupbn
  copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/groupbn
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/focal_loss
  copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/focal_loss
  copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/focal_loss
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/peer_memory
  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/peer_memory
  copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/peer_memory
  copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/peer_memory
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/layer_norm
  copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/layer_norm
  copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/layer_norm
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/fmha
  copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/fmha
  copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/fmha
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/xentropy
  copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/xentropy
  copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/xentropy
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/conv_bias_relu
  copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/conv_bias_relu
  copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/conv_bias_relu
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/index_mul_2d
  copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/index_mul_2d
  copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/index_mul_2d
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/transducer
  copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/transducer
  copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/transducer
  copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/transducer
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/optimizers
  copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/optimizers
  copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/optimizers
  copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/optimizers
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/group_norm
  copying apex/contrib/test/group_norm/test_group_norm.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/group_norm
  copying apex/contrib/test/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/group_norm
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/cudnn_gbn
  copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/cudnn_gbn
  copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/cudnn_gbn
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/clip_grad
  copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/clip_grad
  copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/clip_grad
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/bottleneck
  copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/bottleneck
  copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/bottleneck
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/focal_loss
  copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/focal_loss
  copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/focal_loss
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/peer_memory
  copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/peer_memory
  copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/peer_memory
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/test/layer_norm
  copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/layer_norm
  copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/test/layer_norm
  creating build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels
  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels
  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels
  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels
  copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels
  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels
  running build_ext
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no g++ version bounds defined for CUDA version 11.8
    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')
  building 'apex_C' extension
  creating /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39
  creating /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/1] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/flatten_unflatten.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/flatten_unflatten.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/flatten_unflatten.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-39/apex_C.cpython-39-x86_64-linux-gnu.so
  building 'amp_C' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/15] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/amp_C_frontend.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/amp_C_frontend.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_l2norm_kernel_mp.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [3/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_l2norm_scale_kernel.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [4/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_lamb_stage_1.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [5/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_adagrad.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [6/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_adam.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [7/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_axpby_kernel.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [8/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_lamb.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [9/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_lamb_stage_2.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [10/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_lamb_mp.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [11/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_l2norm_kernel.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [12/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_novograd.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [13/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/update_scale_hysteresis.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/update_scale_hysteresis.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [14/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_sgd_kernel.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  [15/15] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/multi_tensor_scale_kernel.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/amp_C_frontend.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_adagrad.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_adam.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_axpby_kernel.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_l2norm_kernel.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_l2norm_kernel_mp.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_l2norm_scale_kernel.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb_mp.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb_stage_1.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_lamb_stage_2.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_novograd.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_scale_kernel.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/multi_tensor_sgd_kernel.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/update_scale_hysteresis.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/amp_C.cpython-39-x86_64-linux-gnu.so
  building 'syncbn' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/syncbn.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/syncbn.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/welford.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/syncbn.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/welford.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/syncbn.cpython-39-x86_64-linux-gnu.so
  building 'fused_layer_norm_cuda' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/layer_norm_cuda.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/layer_norm_cuda.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/layer_norm_cuda_kernel.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/layer_norm_cuda.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/layer_norm_cuda_kernel.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/fused_layer_norm_cuda.cpython-39-x86_64-linux-gnu.so
  building 'mlp_cuda' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/mlp.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)â€™:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
     for (int i = 0; i < num_layers; i++) {
                     ~~^~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:64:77: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());
                                                                               ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:65:86: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());
                                                                                        ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:67:59: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto lt_workspace = at::empty({1 << 22}, inputs[0].type());
                                                             ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
                                                        ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:215:28: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
       const auto& the_type = TYPE;                                            \
                              ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:218:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]
       at::ScalarType _st = ::detail::scalar_type(the_type);                   \
                                                          ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:245:3: note: in expansion of macro â€˜AT_DISPATCH_SWITCHâ€™
     AT_DISPATCH_SWITCH(                                        \
     ^~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here
   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {
                         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:218:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]
       at::ScalarType _st = ::detail::scalar_type(the_type);                   \
                                                          ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:245:3: note: in expansion of macro â€˜AT_DISPATCH_SWITCHâ€™
     AT_DISPATCH_SWITCH(                                        \
     ^~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here
   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {
                         ^~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
       for (int i = 0; i < num_layers; i++) {
                       ~~^~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:78:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = mlp_fp<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
       for (int i = 0; i < num_layers; i++) {
                       ~~^~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:78:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = mlp_fp<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
       for (int i = 0; i < num_layers; i++) {
                       ~~^~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:78:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = mlp_fp<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:69:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)â€™:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
     for (int i = 0; i < num_layers; i++) {
                     ~~^~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜std::vector<at::Tensor>::size_typeâ€™ {aka â€˜long unsigned intâ€™} [-Wsign-compare]
     for (int i = 0; i < inputs.size(); i++) {
                     ~~^~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:121:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
       outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now
                                                                     ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
                                                        ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:215:28: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
       const auto& the_type = TYPE;                                            \
                              ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:218:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]
       at::ScalarType _st = ::detail::scalar_type(the_type);                   \
                                                          ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:245:3: note: in expansion of macro â€˜AT_DISPATCH_SWITCHâ€™
     AT_DISPATCH_SWITCH(                                        \
     ^~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here
   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {
                         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:218:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]
       at::ScalarType _st = ::detail::scalar_type(the_type);                   \
                                                          ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:245:3: note: in expansion of macro â€˜AT_DISPATCH_SWITCHâ€™
     AT_DISPATCH_SWITCH(                                        \
     ^~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here
   inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {
                         ^~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
       for (int i = 0; i < num_layers; i++) {
                       ~~^~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜std::vector<at::Tensor>::size_typeâ€™ {aka â€˜long unsigned intâ€™} [-Wsign-compare]
       for (int i = 0; i < inputs.size(); i++) {
                       ~~^~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:138:99: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
       auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());
                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:140:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = mlp_bp<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
       for (int i = 0; i < num_layers; i++) {
                       ~~^~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜std::vector<at::Tensor>::size_typeâ€™ {aka â€˜long unsigned intâ€™} [-Wsign-compare]
       for (int i = 0; i < inputs.size(); i++) {
                       ~~^~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:138:99: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
       auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());
                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:140:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = mlp_bp<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜long unsigned intâ€™ [-Wsign-compare]
       for (int i = 0; i < num_layers; i++) {
                       ~~^~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: â€˜intâ€™ and â€˜std::vector<at::Tensor>::size_typeâ€™ {aka â€˜long unsigned intâ€™} [-Wsign-compare]
       for (int i = 0; i < inputs.size(); i++) {
                       ~~^~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:138:99: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
       auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());
                                                                                                     ^
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:140:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = mlp_bp<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALFâ€™
         TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))
                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp.cpp:124:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), "mlp_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/mlp_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/mlp.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/mlp_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/mlp_cuda.cpython-39-x86_64-linux-gnu.so
  building 'fused_dense_cuda' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/fused_dense.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In function â€˜at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)â€™:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:30:63: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto out = at::empty({batch_size, out_features}, input.type());
                                                                 ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:33:55: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto lt_workspace = at::empty({1 << 22}, input.type());
                                                         ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:37:15: warning: unused variable â€˜b_ptrâ€™ [-Wunused-variable]
       scalar_t* b_ptr = bias.data_ptr<scalar_t>();
                 ^~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:38:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:37:15: warning: unused variable â€˜b_ptrâ€™ [-Wunused-variable]
       scalar_t* b_ptr = bias.data_ptr<scalar_t>();
                 ^~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:38:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:37:15: warning: unused variable â€˜b_ptrâ€™ [-Wunused-variable]
       scalar_t* b_ptr = bias.data_ptr<scalar_t>();
                 ^~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:38:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:37:15: warning: unused variable â€˜b_ptrâ€™ [-Wunused-variable]
       scalar_t* b_ptr = bias.data_ptr<scalar_t>();
                 ^~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:38:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In function â€˜std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)â€™:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:64:69: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_weight = at::empty({out_features, in_features}, input.type());
                                                                       ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:68:54: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_bias = at::empty({out_features}, input.type());
                                                        ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:70:66: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_input = at::empty({batch_size, in_features}, input.type());
                                                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:73:55: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto lt_workspace = at::empty({1 << 22}, input.type());
                                                         ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:77:15: warning: unused variable â€˜d_b_ptrâ€™ [-Wunused-variable]
       scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();
                 ^~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:78:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:77:15: warning: unused variable â€˜d_b_ptrâ€™ [-Wunused-variable]
       scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();
                 ^~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:78:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:77:15: warning: unused variable â€˜d_b_ptrâ€™ [-Wunused-variable]
       scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();
                 ^~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:78:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:77:15: warning: unused variable â€˜d_b_ptrâ€™ [-Wunused-variable]
       scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();
                 ^~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:78:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_bias_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In function â€˜std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)â€™:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:106:70: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto output1 = at::empty({batch_size, hidden_features}, input.type());
                                                                        ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:107:70: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto gelu_in = at::empty({batch_size, hidden_features}, input.type());
                                                                        ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:108:67: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto output2 = at::empty({batch_size, out_features}, input.type());
                                                                     ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:111:55: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto lt_workspace = at::empty({1 << 22}, input.type());
                                                         ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:118:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_gelu_linear_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:118:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_gelu_linear_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:118:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_gelu_linear_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:118:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_forward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_gelu_linear_forward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In function â€˜std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)â€™:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:149:73: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_weight1 = at::empty({hidden_features, in_features}, input.type());
                                                                           ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:150:74: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_weight2 = at::empty({out_features, hidden_features}, input.type());
                                                                            ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:151:58: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_bias1 = at::empty({hidden_features}, input.type());
                                                            ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:152:55: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_bias2 = at::empty({out_features}, input.type());
                                                         ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:153:66: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_input = at::empty({batch_size, in_features}, input.type());
                                                                    ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:154:72: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto d_output1 = at::empty({batch_size, hidden_features}, input.type());
                                                                          ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:157:55: warning: â€˜at::DeprecatedTypeProperties& at::Tensor::type() constâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]
     auto lt_workspace = at::empty({1 << 22}, input.type());
                                                         ^
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Tensor.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/variable.h:6,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here
     DeprecatedTypeProperties & type() const {
                                ^~~~
  In file included from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/ATen.h:11,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,
                   from /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/extension.h:5,
                   from /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:1:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:163:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:163:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPESâ€™
     AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:163:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp: In lambda function:
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:163:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]
       auto result = linear_gelu_linear_backward_cuda<scalar_t>(
            ^~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro â€˜AT_DISPATCH_SWITCHâ€™
         __VA_ARGS__                                                           \
         ^~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro â€˜AT_PRIVATE_CASE_TYPE_USING_HINTâ€™
     AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro â€˜AT_DISPATCH_CASEâ€™
     AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)
     ^~~~~~~~~~~~~~~~
  /work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro â€˜AT_DISPATCH_CASE_FLOATING_TYPES_AND2â€™
         AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND2â€™
     AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), "linear_bias_backward", [&] {
     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/fused_dense_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/fused_dense.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/fused_dense_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/fused_dense_cuda.cpython-39-x86_64-linux-gnu.so
  building 'scaled_upper_triang_masked_softmax_cuda' extension
  creating /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_upper_triang_masked_softmax.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_upper_triang_masked_softmax.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/scaled_upper_triang_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so
  building 'generic_scaled_masked_softmax_cuda' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/generic_scaled_masked_softmax.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/generic_scaled_masked_softmax.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/generic_scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/generic_scaled_masked_softmax_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/generic_scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/generic_scaled_masked_softmax.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/generic_scaled_masked_softmax_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/generic_scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so
  building 'scaled_masked_softmax_cuda' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_masked_softmax.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/scaled_masked_softmax.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/scaled_masked_softmax_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_masked_softmax.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_masked_softmax_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so
  building 'scaled_softmax_cuda' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_softmax.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/scaled_softmax.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/scaled_softmax_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_softmax.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/scaled_softmax_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/scaled_softmax_cuda.cpython-39-x86_64-linux-gnu.so
  building 'fused_rotary_positional_embedding' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/2] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_rotary_positional_embedding.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/fused_rotary_positional_embedding.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_rotary_positional_embedding.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/2] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/fused_rotary_positional_embedding_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_rotary_positional_embedding_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_rotary_positional_embedding.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_rotary_positional_embedding_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/fused_rotary_positional_embedding.cpython-39-x86_64-linux-gnu.so
  building 'fused_weight_gradient_mlp_cuda' extension
  Emitting ninja build file /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/build.ninja...
  Compiling objects...
  Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
  [1/3] c++ -MMD -MF /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_weight_gradient_dense.o.d -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -I/work/gb20/b20048/miniconda3/envs/deep/include -fPIC -O2 -isystem /work/gb20/b20048/miniconda3/envs/deep/include -fPIC -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/fused_weight_gradient_dense.cpp -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [2/3] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/fused_weight_gradient_dense_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  [3/3] /work/opt/local/x86_64/cores/cuda/11.8/bin/nvcc  -I/work/02/gb20/b20048/crypto_llm/train/apex/csrc -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/TH -I/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/include/THC -I/work/opt/local/x86_64/cores/cuda/11.8/include -I/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/include -I/work/gb20/b20048/miniconda3/envs/deep/include/python3.9 -c -c /work/02/gb20/b20048/crypto_llm/train/apex/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''"'"'-fPIC'"'"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE="_gcc"' '-DPYBIND11_STDLIB="_libstdcpp"' '-DPYBIND11_BUILD_ABI="_cxxabi1011"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17
  g++ -pthread -B /work/gb20/b20048/miniconda3/envs/deep/compiler_compat -shared -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath,/work/gb20/b20048/miniconda3/envs/deep/lib -Wl,-rpath-link,/work/gb20/b20048/miniconda3/envs/deep/lib -L/work/gb20/b20048/miniconda3/envs/deep/lib /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_weight_gradient_dense.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o /work/02/gb20/b20048/crypto_llm/train/apex/build/temp.linux-x86_64-cpython-39/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/torch/lib -L/work/opt/local/x86_64/cores/cuda/11.8/lib64 -L/work/opt/local/x86_64/apps/cuda/11.8/cudnn/8.8.0/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-39/fused_weight_gradient_mlp_cuda.cpython-39-x86_64-linux-gnu.so
  installing to build/bdist.linux-x86_64/wheel
  running install
  running install_lib
  creating build/bdist.linux-x86_64
  creating build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/mlp_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/fused_weight_gradient_mlp_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/fused_dense_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/scaled_upper_triang_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/syncbn.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  creating build/bdist.linux-x86_64/wheel/apex
  creating build/bdist.linux-x86_64/wheel/apex/normalization
  copying build/lib.linux-x86_64-cpython-39/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization
  copying build/lib.linux-x86_64-cpython-39/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization
  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils
  copying build/lib.linux-x86_64-cpython-39/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils
  copying build/lib.linux-x86_64-cpython-39/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils
  copying build/lib.linux-x86_64-cpython-39/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils
  copying build/lib.linux-x86_64-cpython-39/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils
  copying build/lib.linux-x86_64-cpython-39/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/apex
  creating build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp
  creating build/bdist.linux-x86_64/wheel/apex/amp/lists
  copying build/lib.linux-x86_64-cpython-39/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists
  copying build/lib.linux-x86_64-cpython-39/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists
  copying build/lib.linux-x86_64-cpython-39/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists
  copying build/lib.linux-x86_64-cpython-39/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists
  copying build/lib.linux-x86_64-cpython-39/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp
  copying build/lib.linux-x86_64-cpython-39/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp
  creating build/bdist.linux-x86_64/wheel/apex/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers
  creating build/bdist.linux-x86_64/wheel/apex/transformer
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer
  creating build/bdist.linux-x86_64/wheel/apex/transformer/amp
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp
  creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/apex/transformer
  creating build/bdist.linux-x86_64/wheel/apex/transformer/_data
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/apex/transformer
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/apex/transformer
  creating build/bdist.linux-x86_64/wheel/apex/transformer/functional
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/functional/fused_rope.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional
  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel
  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel
  creating build/bdist.linux-x86_64/wheel/apex/transformer/layers
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers
  creating build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing
  copying build/lib.linux-x86_64-cpython-39/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex
  creating build/bdist.linux-x86_64/wheel/apex/mlp
  copying build/lib.linux-x86_64-cpython-39/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp
  copying build/lib.linux-x86_64-cpython-39/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp
  creating build/bdist.linux-x86_64/wheel/apex/fused_dense
  copying build/lib.linux-x86_64-cpython-39/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense
  copying build/lib.linux-x86_64-cpython-39/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense
  creating build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  copying build/lib.linux-x86_64-cpython-39/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel
  creating build/bdist.linux-x86_64/wheel/apex/RNN
  copying build/lib.linux-x86_64-cpython-39/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN
  copying build/lib.linux-x86_64-cpython-39/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN
  copying build/lib.linux-x86_64-cpython-39/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN
  copying build/lib.linux-x86_64-cpython-39/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN
  creating build/bdist.linux-x86_64/wheel/apex/contrib
  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha
  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy
  creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu
  creating build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d
  creating build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/_mha_kernel.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/fused_adam_swa.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/openfold_triton/mha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton
  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory
  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm
  creating build/bdist.linux-x86_64/wheel/apex/contrib/nccl_allocator
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/nccl_allocator/nccl_allocator.py -> build/bdist.linux-x86_64/wheel/apex/contrib/nccl_allocator
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/nccl_allocator/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/nccl_allocator
  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity
  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity
  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers
  creating build/bdist.linux-x86_64/wheel/apex/contrib/group_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/group_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/group_norm
  creating build/bdist.linux-x86_64/wheel/apex/contrib/gpu_direct_storage
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/gpu_direct_storage/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/gpu_direct_storage
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib
  creating build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn
  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn
  creating build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad
  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck
  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn
  creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss
  creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory
  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm
  copying build/lib.linux-x86_64-cpython-39/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm
  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply
  copying build/lib.linux-x86_64-cpython-39/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply
  copying build/lib.linux-x86_64-cpython-39/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply
  copying build/lib.linux-x86_64-cpython-39/fused_layer_norm_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/apex_C.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/scaled_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/amp_C.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/generic_scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  copying build/lib.linux-x86_64-cpython-39/fused_rotary_positional_embedding.cpython-39-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
  running install_egg_info
  running egg_info
  creating apex.egg-info
  writing apex.egg-info/PKG-INFO
  writing dependency_links to apex.egg-info/dependency_links.txt
  writing requirements to apex.egg-info/requires.txt
  writing top-level names to apex.egg-info/top_level.txt
  writing manifest file 'apex.egg-info/SOURCES.txt'
  reading manifest file 'apex.egg-info/SOURCES.txt'
  adding license file 'LICENSE'
  writing manifest file 'apex.egg-info/SOURCES.txt'
  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.9.egg-info
  running install_scripts
  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL
  creating '/tmp/pip-wheel-pxq8k049/.tmp-9md58s77/apex-0.1-cp39-cp39-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it
  adding 'amp_C.cpython-39-x86_64-linux-gnu.so'
  adding 'apex_C.cpython-39-x86_64-linux-gnu.so'
  adding 'fused_dense_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'fused_layer_norm_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'fused_rotary_positional_embedding.cpython-39-x86_64-linux-gnu.so'
  adding 'fused_weight_gradient_mlp_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'generic_scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'mlp_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'scaled_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'scaled_softmax_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'scaled_upper_triang_masked_softmax_cuda.cpython-39-x86_64-linux-gnu.so'
  adding 'syncbn.cpython-39-x86_64-linux-gnu.so'
  adding 'apex/__init__.py'
  adding 'apex/_autocast_utils.py'
  adding 'apex/RNN/RNNBackend.py'
  adding 'apex/RNN/__init__.py'
  adding 'apex/RNN/cells.py'
  adding 'apex/RNN/models.py'
  adding 'apex/amp/__init__.py'
  adding 'apex/amp/__version__.py'
  adding 'apex/amp/_amp_state.py'
  adding 'apex/amp/_initialize.py'
  adding 'apex/amp/_process_optimizer.py'
  adding 'apex/amp/amp.py'
  adding 'apex/amp/compat.py'
  adding 'apex/amp/frontend.py'
  adding 'apex/amp/handle.py'
  adding 'apex/amp/opt.py'
  adding 'apex/amp/rnn_compat.py'
  adding 'apex/amp/scaler.py'
  adding 'apex/amp/utils.py'
  adding 'apex/amp/wrap.py'
  adding 'apex/amp/lists/__init__.py'
  adding 'apex/amp/lists/functional_overrides.py'
  adding 'apex/amp/lists/tensor_overrides.py'
  adding 'apex/amp/lists/torch_overrides.py'
  adding 'apex/contrib/__init__.py'
  adding 'apex/contrib/bottleneck/__init__.py'
  adding 'apex/contrib/bottleneck/bottleneck.py'
  adding 'apex/contrib/bottleneck/halo_exchangers.py'
  adding 'apex/contrib/bottleneck/test.py'
  adding 'apex/contrib/clip_grad/__init__.py'
  adding 'apex/contrib/clip_grad/clip_grad.py'
  adding 'apex/contrib/conv_bias_relu/__init__.py'
  adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'
  adding 'apex/contrib/cudnn_gbn/__init__.py'
  adding 'apex/contrib/cudnn_gbn/batch_norm.py'
  adding 'apex/contrib/fmha/__init__.py'
  adding 'apex/contrib/fmha/fmha.py'
  adding 'apex/contrib/focal_loss/__init__.py'
  adding 'apex/contrib/focal_loss/focal_loss.py'
  adding 'apex/contrib/gpu_direct_storage/__init__.py'
  adding 'apex/contrib/group_norm/__init__.py'
  adding 'apex/contrib/group_norm/group_norm.py'
  adding 'apex/contrib/groupbn/__init__.py'
  adding 'apex/contrib/groupbn/batch_norm.py'
  adding 'apex/contrib/index_mul_2d/__init__.py'
  adding 'apex/contrib/index_mul_2d/index_mul_2d.py'
  adding 'apex/contrib/layer_norm/__init__.py'
  adding 'apex/contrib/layer_norm/layer_norm.py'
  adding 'apex/contrib/multihead_attn/__init__.py'
  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'
  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'
  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'
  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'
  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'
  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'
  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'
  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'
  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'
  adding 'apex/contrib/nccl_allocator/__init__.py'
  adding 'apex/contrib/nccl_allocator/nccl_allocator.py'
  adding 'apex/contrib/openfold_triton/__init__.py'
  adding 'apex/contrib/openfold_triton/_layer_norm_backward_kernels.py'
  adding 'apex/contrib/openfold_triton/_layer_norm_config_ampere.py'
  adding 'apex/contrib/openfold_triton/_layer_norm_config_hopper.py'
  adding 'apex/contrib/openfold_triton/_layer_norm_forward_kernels.py'
  adding 'apex/contrib/openfold_triton/_mha_kernel.py'
  adding 'apex/contrib/openfold_triton/fused_adam_swa.py'
  adding 'apex/contrib/openfold_triton/layer_norm.py'
  adding 'apex/contrib/openfold_triton/mha.py'
  adding 'apex/contrib/optimizers/__init__.py'
  adding 'apex/contrib/optimizers/distributed_fused_adam.py'
  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'
  adding 'apex/contrib/optimizers/fp16_optimizer.py'
  adding 'apex/contrib/optimizers/fused_adam.py'
  adding 'apex/contrib/optimizers/fused_lamb.py'
  adding 'apex/contrib/optimizers/fused_sgd.py'
  adding 'apex/contrib/peer_memory/__init__.py'
  adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'
  adding 'apex/contrib/peer_memory/peer_memory.py'
  adding 'apex/contrib/sparsity/__init__.py'
  adding 'apex/contrib/sparsity/asp.py'
  adding 'apex/contrib/sparsity/permutation_lib.py'
  adding 'apex/contrib/sparsity/sparse_masklib.py'
  adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'
  adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'
  adding 'apex/contrib/sparsity/permutation_search_kernels/channel_swap.py'
  adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'
  adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'
  adding 'apex/contrib/test/__init__.py'
  adding 'apex/contrib/test/bottleneck/__init__.py'
  adding 'apex/contrib/test/bottleneck/test_bottleneck_module.py'
  adding 'apex/contrib/test/clip_grad/__init__.py'
  adding 'apex/contrib/test/clip_grad/test_clip_grad.py'
  adding 'apex/contrib/test/conv_bias_relu/__init__.py'
  adding 'apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py'
  adding 'apex/contrib/test/cudnn_gbn/__init__.py'
  adding 'apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'
  adding 'apex/contrib/test/fmha/__init__.py'
  adding 'apex/contrib/test/fmha/test_fmha.py'
  adding 'apex/contrib/test/focal_loss/__init__.py'
  adding 'apex/contrib/test/focal_loss/test_focal_loss.py'
  adding 'apex/contrib/test/group_norm/__init__.py'
  adding 'apex/contrib/test/group_norm/test_group_norm.py'
  adding 'apex/contrib/test/index_mul_2d/__init__.py'
  adding 'apex/contrib/test/index_mul_2d/test_index_mul_2d.py'
  adding 'apex/contrib/test/layer_norm/__init__.py'
  adding 'apex/contrib/test/layer_norm/test_fast_layer_norm.py'
  adding 'apex/contrib/test/multihead_attn/__init__.py'
  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py'
  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'
  adding 'apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'
  adding 'apex/contrib/test/multihead_attn/test_mha_fused_softmax.py'
  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn.py'
  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'
  adding 'apex/contrib/test/optimizers/__init__.py'
  adding 'apex/contrib/test/optimizers/test_dist_adam.py'
  adding 'apex/contrib/test/optimizers/test_distributed_fused_lamb.py'
  adding 'apex/contrib/test/peer_memory/__init__.py'
  adding 'apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py'
  adding 'apex/contrib/test/transducer/__init__.py'
  adding 'apex/contrib/test/transducer/test_transducer_joint.py'
  adding 'apex/contrib/test/transducer/test_transducer_loss.py'
  adding 'apex/contrib/test/xentropy/__init__.py'
  adding 'apex/contrib/test/xentropy/test_label_smoothing.py'
  adding 'apex/contrib/transducer/__init__.py'
  adding 'apex/contrib/transducer/_transducer_ref.py'
  adding 'apex/contrib/transducer/transducer.py'
  adding 'apex/contrib/xentropy/__init__.py'
  adding 'apex/contrib/xentropy/softmax_xentropy.py'
  adding 'apex/fp16_utils/__init__.py'
  adding 'apex/fp16_utils/fp16_optimizer.py'
  adding 'apex/fp16_utils/fp16util.py'
  adding 'apex/fp16_utils/loss_scaler.py'
  adding 'apex/fused_dense/__init__.py'
  adding 'apex/fused_dense/fused_dense.py'
  adding 'apex/mlp/__init__.py'
  adding 'apex/mlp/mlp.py'
  adding 'apex/multi_tensor_apply/__init__.py'
  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'
  adding 'apex/normalization/__init__.py'
  adding 'apex/normalization/fused_layer_norm.py'
  adding 'apex/optimizers/__init__.py'
  adding 'apex/optimizers/fused_adagrad.py'
  adding 'apex/optimizers/fused_adam.py'
  adding 'apex/optimizers/fused_lamb.py'
  adding 'apex/optimizers/fused_mixed_precision_lamb.py'
  adding 'apex/optimizers/fused_novograd.py'
  adding 'apex/optimizers/fused_sgd.py'
  adding 'apex/parallel/LARC.py'
  adding 'apex/parallel/__init__.py'
  adding 'apex/parallel/distributed.py'
  adding 'apex/parallel/multiproc.py'
  adding 'apex/parallel/optimized_sync_batchnorm.py'
  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'
  adding 'apex/parallel/sync_batchnorm.py'
  adding 'apex/parallel/sync_batchnorm_kernel.py'
  adding 'apex/transformer/__init__.py'
  adding 'apex/transformer/_ucc_util.py'
  adding 'apex/transformer/enums.py'
  adding 'apex/transformer/log_util.py'
  adding 'apex/transformer/microbatches.py'
  adding 'apex/transformer/parallel_state.py'
  adding 'apex/transformer/utils.py'
  adding 'apex/transformer/_data/__init__.py'
  adding 'apex/transformer/_data/_batchsampler.py'
  adding 'apex/transformer/amp/__init__.py'
  adding 'apex/transformer/amp/grad_scaler.py'
  adding 'apex/transformer/functional/__init__.py'
  adding 'apex/transformer/functional/fused_rope.py'
  adding 'apex/transformer/functional/fused_softmax.py'
  adding 'apex/transformer/layers/__init__.py'
  adding 'apex/transformer/layers/layer_norm.py'
  adding 'apex/transformer/pipeline_parallel/__init__.py'
  adding 'apex/transformer/pipeline_parallel/_timers.py'
  adding 'apex/transformer/pipeline_parallel/p2p_communication.py'
  adding 'apex/transformer/pipeline_parallel/utils.py'
  adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'
  adding 'apex/transformer/pipeline_parallel/schedules/common.py'
  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'
  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'
  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'
  adding 'apex/transformer/tensor_parallel/__init__.py'
  adding 'apex/transformer/tensor_parallel/cross_entropy.py'
  adding 'apex/transformer/tensor_parallel/data.py'
  adding 'apex/transformer/tensor_parallel/layers.py'
  adding 'apex/transformer/tensor_parallel/mappings.py'
  adding 'apex/transformer/tensor_parallel/memory.py'
  adding 'apex/transformer/tensor_parallel/random.py'
  adding 'apex/transformer/tensor_parallel/utils.py'
  adding 'apex/transformer/testing/__init__.py'
  adding 'apex/transformer/testing/arguments.py'
  adding 'apex/transformer/testing/commons.py'
  adding 'apex/transformer/testing/distributed_test_base.py'
  adding 'apex/transformer/testing/global_vars.py'
  adding 'apex/transformer/testing/standalone_bert.py'
  adding 'apex/transformer/testing/standalone_gpt.py'
  adding 'apex/transformer/testing/standalone_transformer_lm.py'
  adding 'apex-0.1.dist-info/LICENSE'
  adding 'apex-0.1.dist-info/METADATA'
  adding 'apex-0.1.dist-info/WHEEL'
  adding 'apex-0.1.dist-info/top_level.txt'
  adding 'apex-0.1.dist-info/RECORD'
  removing build/bdist.linux-x86_64/wheel
  Building wheel for apex (pyproject.toml): finished with status 'done'
  Created wheel for apex: filename=apex-0.1-cp39-cp39-linux_x86_64.whl size=4866766 sha256=b8b47e0f2f98305404300f68b394d7bec5df034d0cd1819a9879c1d8c321210e
  Stored in directory: /tmp/pip-ephem-wheel-cache-be2pjvbh/wheels/76/c7/a5/1ef86d001d1d8144644bf0563446305cf70b26500ff30a5070
Successfully built apex
Installing collected packages: apex
Successfully installed apex-0.1
* Installing Megatron-DeepSpeed
Cloning into 'Megatron-DeepSpeed'...
running install
/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.
!!

        ********************************************************************************
        Please avoid running ``setup.py`` directly.
        Instead, use pypa/build, pypa/installer or other
        standards-based tools.

        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.
        ********************************************************************************

!!
  self.initialize_options()
/work/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.
!!

        ********************************************************************************
        Please avoid running ``setup.py`` and ``easy_install``.
        Instead, use pypa/build, pypa/installer or other
        standards-based tools.

        See https://github.com/pypa/setuptools/issues/917 for details.
        ********************************************************************************

!!
  self.initialize_options()
running bdist_egg
running egg_info
creating megatron_core.egg-info
writing megatron_core.egg-info/PKG-INFO
writing dependency_links to megatron_core.egg-info/dependency_links.txt
writing requirements to megatron_core.egg-info/requires.txt
writing top-level names to megatron_core.egg-info/top_level.txt
writing manifest file 'megatron_core.egg-info/SOURCES.txt'
reading manifest file 'megatron_core.egg-info/SOURCES.txt'
reading manifest template 'MANIFEST.in'
warning: no files found matching '*.tr' under directory 'megatron/fused_kernels'
warning: no files found matching '*.cuh' under directory 'megatron/fused_kernels'
warning: no files found matching '*.cc' under directory 'megatron/fused_kernels'
adding license file 'LICENSE'
writing manifest file 'megatron_core.egg-info/SOURCES.txt'
installing library code to build/bdist.linux-x86_64/egg
running install_lib
running build_py
creating build
creating build/lib
creating build/lib/tests
copying tests/test_megatron.py -> build/lib/tests
copying tests/__init__.py -> build/lib/tests
copying tests/conftest.py -> build/lib/tests
copying tests/run_megatron.py -> build/lib/tests
creating build/lib/megatron
copying megatron/p2p_communication.py -> build/lib/megatron
copying megatron/initialize.py -> build/lib/megatron
copying megatron/global_vars.py -> build/lib/megatron
copying megatron/checkpointing.py -> build/lib/megatron
copying megatron/utils.py -> build/lib/megatron
copying megatron/dist_signal_handler.py -> build/lib/megatron
copying megatron/profiler.py -> build/lib/megatron
copying megatron/indexer.py -> build/lib/megatron
copying megatron/microbatches.py -> build/lib/megatron
copying megatron/enums.py -> build/lib/megatron
copying megatron/__init__.py -> build/lib/megatron
copying megatron/arguments.py -> build/lib/megatron
copying megatron/text_generation_utils.py -> build/lib/megatron
copying megatron/optimizer_param_scheduler.py -> build/lib/megatron
copying megatron/memory.py -> build/lib/megatron
copying megatron/text_generation_server.py -> build/lib/megatron
copying megatron/timers.py -> build/lib/megatron
copying megatron/training.py -> build/lib/megatron
creating build/lib/tools
copying tools/hf2megads_weight_converter.py -> build/lib/tools
copying tools/merge_datasets.py -> build/lib/tools
copying tools/run_text_generation_server.py -> build/lib/tools
copying tools/linter.py -> build/lib/tools
copying tools/preprocess_data.py -> build/lib/tools
copying tools/checkpoint_loader_megatron.py -> build/lib/tools
copying tools/checkpoint_saver_megatron.py -> build/lib/tools
copying tools/generate_samples_gpt.py -> build/lib/tools
copying tools/preprocess_data_nmt.py -> build/lib/tools
copying tools/__init__.py -> build/lib/tools
copying tools/text_generation_cli.py -> build/lib/tools
copying tools/checkpoint_util.py -> build/lib/tools
creating build/lib/tests/functional_tests
copying tests/functional_tests/__init__.py -> build/lib/tests/functional_tests
creating build/lib/tests/unit_tests
copying tests/unit_tests/test_utilities.py -> build/lib/tests/unit_tests
copying tests/unit_tests/__init__.py -> build/lib/tests/unit_tests
copying tests/unit_tests/test_utils.py -> build/lib/tests/unit_tests
copying tests/unit_tests/test_basic.py -> build/lib/tests/unit_tests
copying tests/unit_tests/test_parallel_state.py -> build/lib/tests/unit_tests
creating build/lib/tests/models
copying tests/models/test_gpt_embedding.py -> build/lib/tests/models
copying tests/models/__init__.py -> build/lib/tests/models
copying tests/models/test_gpt_model.py -> build/lib/tests/models
creating build/lib/tests/transformer
copying tests/transformer/test_transformer_config.py -> build/lib/tests/transformer
copying tests/transformer/test_core_attention.py -> build/lib/tests/transformer
copying tests/transformer/test_module.py -> build/lib/tests/transformer
copying tests/transformer/__init__.py -> build/lib/tests/transformer
copying tests/transformer/test_parallel_mlp.py -> build/lib/tests/transformer
copying tests/transformer/test_parallel_attention.py -> build/lib/tests/transformer
copying tests/transformer/test_parallel_transformer_block.py -> build/lib/tests/transformer
copying tests/transformer/test_parallel_transformer_layer.py -> build/lib/tests/transformer
creating build/lib/tests/pipeline_parallel
copying tests/pipeline_parallel/test_schedules.py -> build/lib/tests/pipeline_parallel
copying tests/pipeline_parallel/__init__.py -> build/lib/tests/pipeline_parallel
creating build/lib/tests/functional_tests/python_test_utils
copying tests/functional_tests/python_test_utils/check_slurm_job_completion.py -> build/lib/tests/functional_tests/python_test_utils
copying tests/functional_tests/python_test_utils/test_ci_pipeline.py -> build/lib/tests/functional_tests/python_test_utils
copying tests/functional_tests/python_test_utils/test_resume_checkpoint_pipeline.py -> build/lib/tests/functional_tests/python_test_utils
copying tests/functional_tests/python_test_utils/__init__.py -> build/lib/tests/functional_tests/python_test_utils
copying tests/functional_tests/python_test_utils/get_test_results_from_tensorboard_logs.py -> build/lib/tests/functional_tests/python_test_utils
creating build/lib/megatron/text_generation
copying megatron/text_generation/communication.py -> build/lib/megatron/text_generation
copying megatron/text_generation/tokenization.py -> build/lib/megatron/text_generation
copying megatron/text_generation/__init__.py -> build/lib/megatron/text_generation
copying megatron/text_generation/forward_step.py -> build/lib/megatron/text_generation
copying megatron/text_generation/sampling.py -> build/lib/megatron/text_generation
copying megatron/text_generation/api.py -> build/lib/megatron/text_generation
copying megatron/text_generation/generation.py -> build/lib/megatron/text_generation
copying megatron/text_generation/beam_utils.py -> build/lib/megatron/text_generation
creating build/lib/megatron/data
copying megatron/data/blendable_dataset.py -> build/lib/megatron/data
copying megatron/data/image_folder.py -> build/lib/megatron/data
copying megatron/data/prompt_dataset.py -> build/lib/megatron/data
copying megatron/data/gpt_dataset.py -> build/lib/megatron/data
copying megatron/data/t5_dataset.py -> build/lib/megatron/data
copying megatron/data/data_samplers.py -> build/lib/megatron/data
copying megatron/data/dataset_utils.py -> build/lib/megatron/data
copying megatron/data/bert_dataset.py -> build/lib/megatron/data
copying megatron/data/realm_index.py -> build/lib/megatron/data
copying megatron/data/vit_dataset.py -> build/lib/megatron/data
copying megatron/data/orqa_wiki_dataset.py -> build/lib/megatron/data
copying megatron/data/__init__.py -> build/lib/megatron/data
copying megatron/data/realm_dataset_utils.py -> build/lib/megatron/data
copying megatron/data/ict_dataset.py -> build/lib/megatron/data
copying megatron/data/indexed_dataset.py -> build/lib/megatron/data
copying megatron/data/biencoder_dataset_utils.py -> build/lib/megatron/data
copying megatron/data/autoaugment.py -> build/lib/megatron/data
creating build/lib/megatron/tokenizer
copying megatron/tokenizer/bert_tokenization.py -> build/lib/megatron/tokenizer
copying megatron/tokenizer/gpt2_tokenization.py -> build/lib/megatron/tokenizer
copying megatron/tokenizer/tokenizer.py -> build/lib/megatron/tokenizer
copying megatron/tokenizer/__init__.py -> build/lib/megatron/tokenizer
creating build/lib/megatron/optimizer
copying megatron/optimizer/optimizer.py -> build/lib/megatron/optimizer
copying megatron/optimizer/__init__.py -> build/lib/megatron/optimizer
copying megatron/optimizer/clip_grads.py -> build/lib/megatron/optimizer
copying megatron/optimizer/distrib_optimizer.py -> build/lib/megatron/optimizer
copying megatron/optimizer/grad_scaler.py -> build/lib/megatron/optimizer
creating build/lib/megatron/model
copying megatron/model/biencoder_model.py -> build/lib/megatron/model
copying megatron/model/rmsnorm.py -> build/lib/megatron/model
copying megatron/model/utils.py -> build/lib/megatron/model
copying megatron/model/language_model.py -> build/lib/megatron/model
copying megatron/model/transformer.py -> build/lib/megatron/model
copying megatron/model/fused_softmax.py -> build/lib/megatron/model
copying megatron/model/rotary_pos_embedding.py -> build/lib/megatron/model
copying megatron/model/fused_layer_norm.py -> build/lib/megatron/model
copying megatron/model/distributed.py -> build/lib/megatron/model
copying megatron/model/fused_bias_gelu.py -> build/lib/megatron/model
copying megatron/model/enums.py -> build/lib/megatron/model
copying megatron/model/module.py -> build/lib/megatron/model
copying megatron/model/classification.py -> build/lib/megatron/model
copying megatron/model/__init__.py -> build/lib/megatron/model
copying megatron/model/fused_rmsnorm.py -> build/lib/megatron/model
copying megatron/model/t5_model.py -> build/lib/megatron/model
copying megatron/model/gpt_model.py -> build/lib/megatron/model
copying megatron/model/bert_model.py -> build/lib/megatron/model
copying megatron/model/multiple_choice.py -> build/lib/megatron/model
copying megatron/model/realm_model.py -> build/lib/megatron/model
creating build/lib/megatron/fused_kernels
copying megatron/fused_kernels/__init__.py -> build/lib/megatron/fused_kernels
creating build/lib/megatron/core
copying megatron/core/utils.py -> build/lib/megatron/core
copying megatron/core/enums.py -> build/lib/megatron/core
copying megatron/core/__init__.py -> build/lib/megatron/core
copying megatron/core/package_info.py -> build/lib/megatron/core
copying megatron/core/parallel_state.py -> build/lib/megatron/core
copying megatron/core/model_parallel_config.py -> build/lib/megatron/core
creating build/lib/megatron/model/vision
copying megatron/model/vision/inpainting.py -> build/lib/megatron/model/vision
copying megatron/model/vision/knn_monitor.py -> build/lib/megatron/model/vision
copying megatron/model/vision/utils.py -> build/lib/megatron/model/vision
copying megatron/model/vision/esvit_swin_backbone.py -> build/lib/megatron/model/vision
copying megatron/model/vision/vit_backbone.py -> build/lib/megatron/model/vision
copying megatron/model/vision/swin_backbone.py -> build/lib/megatron/model/vision
copying megatron/model/vision/mit_backbone.py -> build/lib/megatron/model/vision
copying megatron/model/vision/classification.py -> build/lib/megatron/model/vision
copying megatron/model/vision/__init__.py -> build/lib/megatron/model/vision
copying megatron/model/vision/dino.py -> build/lib/megatron/model/vision
creating build/lib/megatron/fused_kernels/tests
copying megatron/fused_kernels/tests/test_fused_kernels.py -> build/lib/megatron/fused_kernels/tests
copying megatron/fused_kernels/tests/__init__.py -> build/lib/megatron/fused_kernels/tests
creating build/lib/megatron/core/sequence_parallel
copying megatron/core/sequence_parallel/__init__.py -> build/lib/megatron/core/sequence_parallel
copying megatron/core/sequence_parallel/cross_entropy.py -> build/lib/megatron/core/sequence_parallel
creating build/lib/megatron/core/models
copying megatron/core/models/__init__.py -> build/lib/megatron/core/models
creating build/lib/megatron/core/transformer
copying megatron/core/transformer/utils.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/mlp.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/transformer_layer.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/attention.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/core_attention.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/enums.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/module.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/__init__.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/transformer_block.py -> build/lib/megatron/core/transformer
copying megatron/core/transformer/transformer_config.py -> build/lib/megatron/core/transformer
creating build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/mappings.py -> build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/utils.py -> build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/random.py -> build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/layers.py -> build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/weight_grad_store.py -> build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/data.py -> build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/__init__.py -> build/lib/megatron/core/tensor_parallel
copying megatron/core/tensor_parallel/cross_entropy.py -> build/lib/megatron/core/tensor_parallel
creating build/lib/megatron/core/fusions
copying megatron/core/fusions/fused_softmax.py -> build/lib/megatron/core/fusions
copying megatron/core/fusions/fused_layer_norm.py -> build/lib/megatron/core/fusions
copying megatron/core/fusions/fused_bias_dropout.py -> build/lib/megatron/core/fusions
copying megatron/core/fusions/fused_bias_gelu.py -> build/lib/megatron/core/fusions
copying megatron/core/fusions/__init__.py -> build/lib/megatron/core/fusions
creating build/lib/megatron/core/pipeline_parallel
copying megatron/core/pipeline_parallel/p2p_communication.py -> build/lib/megatron/core/pipeline_parallel
copying megatron/core/pipeline_parallel/schedules.py -> build/lib/megatron/core/pipeline_parallel
copying megatron/core/pipeline_parallel/deepspeed_zbh1_engine.py -> build/lib/megatron/core/pipeline_parallel
copying megatron/core/pipeline_parallel/__init__.py -> build/lib/megatron/core/pipeline_parallel
copying megatron/core/pipeline_parallel/deepspeed_zbh1_schedule.py -> build/lib/megatron/core/pipeline_parallel
creating build/lib/megatron/core/models/gpt
copying megatron/core/models/gpt/gpt_embedding.py -> build/lib/megatron/core/models/gpt
copying megatron/core/models/gpt/__init__.py -> build/lib/megatron/core/models/gpt
copying megatron/core/models/gpt/gpt_model.py -> build/lib/megatron/core/models/gpt
creating build/lib/tools/retro
copying tools/retro/utils.py -> build/lib/tools/retro
copying tools/retro/__init__.py -> build/lib/tools/retro
copying tools/retro/external_libs.py -> build/lib/tools/retro
copying tools/retro/main.py -> build/lib/tools/retro
creating build/lib/tools/bert_embedding
copying tools/bert_embedding/embed.py -> build/lib/tools/bert_embedding
copying tools/bert_embedding/utils.py -> build/lib/tools/bert_embedding
copying tools/bert_embedding/__init__.py -> build/lib/tools/bert_embedding
copying tools/bert_embedding/huggingface.py -> build/lib/tools/bert_embedding
copying tools/bert_embedding/external_libs.py -> build/lib/tools/bert_embedding
copying tools/bert_embedding/dataset.py -> build/lib/tools/bert_embedding
creating build/lib/tools/retro/db
copying tools/retro/db/utils.py -> build/lib/tools/retro/db
copying tools/retro/db/build.py -> build/lib/tools/retro/db
copying tools/retro/db/__init__.py -> build/lib/tools/retro/db
copying tools/retro/db/dataset.py -> build/lib/tools/retro/db
creating build/lib/tools/retro/query
copying tools/retro/query/utils.py -> build/lib/tools/retro/query
copying tools/retro/query/chunk_dataset.py -> build/lib/tools/retro/query
copying tools/retro/query/__init__.py -> build/lib/tools/retro/query
copying tools/retro/query/query.py -> build/lib/tools/retro/query
copying tools/retro/query/retro_dataset.py -> build/lib/tools/retro/query
creating build/lib/tools/retro/index
copying tools/retro/index/utils.py -> build/lib/tools/retro/index
copying tools/retro/index/build.py -> build/lib/tools/retro/index
copying tools/retro/index/__init__.py -> build/lib/tools/retro/index
copying tools/retro/index/index.py -> build/lib/tools/retro/index
copying tools/retro/index/factory.py -> build/lib/tools/retro/index
creating build/lib/tools/retro/cli
copying tools/retro/cli/__main__.py -> build/lib/tools/retro/cli
copying tools/retro/cli/__init__.py -> build/lib/tools/retro/cli
copying tools/retro/cli/cli.py -> build/lib/tools/retro/cli
creating build/lib/tools/retro/index/indexes
copying tools/retro/index/indexes/faiss_base.py -> build/lib/tools/retro/index/indexes
copying tools/retro/index/indexes/__init__.py -> build/lib/tools/retro/index/indexes
copying tools/retro/index/indexes/faiss_par_add.py -> build/lib/tools/retro/index/indexes
copying megatron/data/Makefile -> build/lib/megatron/data
copying megatron/data/helpers.cpp -> build/lib/megatron/data
copying megatron/fused_kernels/compat.h -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_masked_softmax.cpp -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_masked_softmax.h -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_masked_softmax_cuda.cu -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_softmax.cpp -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_softmax_cuda.cu -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_upper_triang_masked_softmax.h -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -> build/lib/megatron/fused_kernels
copying megatron/fused_kernels/type_shim.h -> build/lib/megatron/fused_kernels
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/egg
creating build/bdist.linux-x86_64/egg/tests
copying build/lib/tests/test_megatron.py -> build/bdist.linux-x86_64/egg/tests
creating build/bdist.linux-x86_64/egg/tests/functional_tests
creating build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils
copying build/lib/tests/functional_tests/python_test_utils/check_slurm_job_completion.py -> build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils
copying build/lib/tests/functional_tests/python_test_utils/test_ci_pipeline.py -> build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils
copying build/lib/tests/functional_tests/python_test_utils/test_resume_checkpoint_pipeline.py -> build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils
copying build/lib/tests/functional_tests/python_test_utils/__init__.py -> build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils
copying build/lib/tests/functional_tests/python_test_utils/get_test_results_from_tensorboard_logs.py -> build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils
copying build/lib/tests/functional_tests/__init__.py -> build/bdist.linux-x86_64/egg/tests/functional_tests
creating build/bdist.linux-x86_64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/test_utilities.py -> build/bdist.linux-x86_64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/__init__.py -> build/bdist.linux-x86_64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/test_utils.py -> build/bdist.linux-x86_64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/test_basic.py -> build/bdist.linux-x86_64/egg/tests/unit_tests
copying build/lib/tests/unit_tests/test_parallel_state.py -> build/bdist.linux-x86_64/egg/tests/unit_tests
creating build/bdist.linux-x86_64/egg/tests/models
copying build/lib/tests/models/test_gpt_embedding.py -> build/bdist.linux-x86_64/egg/tests/models
copying build/lib/tests/models/__init__.py -> build/bdist.linux-x86_64/egg/tests/models
copying build/lib/tests/models/test_gpt_model.py -> build/bdist.linux-x86_64/egg/tests/models
creating build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/test_transformer_config.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/test_core_attention.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/test_module.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/__init__.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/test_parallel_mlp.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/test_parallel_attention.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/test_parallel_transformer_block.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/transformer/test_parallel_transformer_layer.py -> build/bdist.linux-x86_64/egg/tests/transformer
copying build/lib/tests/__init__.py -> build/bdist.linux-x86_64/egg/tests
copying build/lib/tests/conftest.py -> build/bdist.linux-x86_64/egg/tests
copying build/lib/tests/run_megatron.py -> build/bdist.linux-x86_64/egg/tests
creating build/bdist.linux-x86_64/egg/tests/pipeline_parallel
copying build/lib/tests/pipeline_parallel/test_schedules.py -> build/bdist.linux-x86_64/egg/tests/pipeline_parallel
copying build/lib/tests/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/egg/tests/pipeline_parallel
creating build/bdist.linux-x86_64/egg/megatron
creating build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/communication.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/tokenization.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/__init__.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/forward_step.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/sampling.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/api.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/generation.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/text_generation/beam_utils.py -> build/bdist.linux-x86_64/egg/megatron/text_generation
copying build/lib/megatron/p2p_communication.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/initialize.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/global_vars.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/checkpointing.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/utils.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/dist_signal_handler.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/profiler.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/indexer.py -> build/bdist.linux-x86_64/egg/megatron
creating build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/Makefile -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/blendable_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/image_folder.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/prompt_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/gpt_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/t5_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/data_samplers.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/dataset_utils.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/bert_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/realm_index.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/vit_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/orqa_wiki_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/__init__.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/realm_dataset_utils.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/ict_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/helpers.cpp -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/indexed_dataset.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/biencoder_dataset_utils.py -> build/bdist.linux-x86_64/egg/megatron/data
copying build/lib/megatron/data/autoaugment.py -> build/bdist.linux-x86_64/egg/megatron/data
creating build/bdist.linux-x86_64/egg/megatron/tokenizer
copying build/lib/megatron/tokenizer/bert_tokenization.py -> build/bdist.linux-x86_64/egg/megatron/tokenizer
copying build/lib/megatron/tokenizer/gpt2_tokenization.py -> build/bdist.linux-x86_64/egg/megatron/tokenizer
copying build/lib/megatron/tokenizer/tokenizer.py -> build/bdist.linux-x86_64/egg/megatron/tokenizer
copying build/lib/megatron/tokenizer/__init__.py -> build/bdist.linux-x86_64/egg/megatron/tokenizer
copying build/lib/megatron/microbatches.py -> build/bdist.linux-x86_64/egg/megatron
creating build/bdist.linux-x86_64/egg/megatron/optimizer
copying build/lib/megatron/optimizer/optimizer.py -> build/bdist.linux-x86_64/egg/megatron/optimizer
copying build/lib/megatron/optimizer/__init__.py -> build/bdist.linux-x86_64/egg/megatron/optimizer
copying build/lib/megatron/optimizer/clip_grads.py -> build/bdist.linux-x86_64/egg/megatron/optimizer
copying build/lib/megatron/optimizer/distrib_optimizer.py -> build/bdist.linux-x86_64/egg/megatron/optimizer
copying build/lib/megatron/optimizer/grad_scaler.py -> build/bdist.linux-x86_64/egg/megatron/optimizer
copying build/lib/megatron/enums.py -> build/bdist.linux-x86_64/egg/megatron
creating build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/biencoder_model.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/rmsnorm.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/utils.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/language_model.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/transformer.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/fused_softmax.py -> build/bdist.linux-x86_64/egg/megatron/model
creating build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/inpainting.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/knn_monitor.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/utils.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/esvit_swin_backbone.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/vit_backbone.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/swin_backbone.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/mit_backbone.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/classification.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/__init__.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/vision/dino.py -> build/bdist.linux-x86_64/egg/megatron/model/vision
copying build/lib/megatron/model/rotary_pos_embedding.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/distributed.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/fused_bias_gelu.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/enums.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/module.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/classification.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/__init__.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/fused_rmsnorm.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/t5_model.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/gpt_model.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/bert_model.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/multiple_choice.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/model/realm_model.py -> build/bdist.linux-x86_64/egg/megatron/model
copying build/lib/megatron/__init__.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/arguments.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/text_generation_utils.py -> build/bdist.linux-x86_64/egg/megatron
creating build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/scaled_softmax.cpp -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/scaled_masked_softmax.cpp -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
creating build/bdist.linux-x86_64/egg/megatron/fused_kernels/tests
copying build/lib/megatron/fused_kernels/tests/test_fused_kernels.py -> build/bdist.linux-x86_64/egg/megatron/fused_kernels/tests
copying build/lib/megatron/fused_kernels/tests/__init__.py -> build/bdist.linux-x86_64/egg/megatron/fused_kernels/tests
copying build/lib/megatron/fused_kernels/scaled_masked_softmax_cuda.cu -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/scaled_upper_triang_masked_softmax.h -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/type_shim.h -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/scaled_softmax_cuda.cu -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/scaled_masked_softmax.h -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/__init__.py -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/compat.h -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
copying build/lib/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -> build/bdist.linux-x86_64/egg/megatron/fused_kernels
creating build/bdist.linux-x86_64/egg/megatron/core
copying build/lib/megatron/core/utils.py -> build/bdist.linux-x86_64/egg/megatron/core
creating build/bdist.linux-x86_64/egg/megatron/core/sequence_parallel
copying build/lib/megatron/core/sequence_parallel/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core/sequence_parallel
copying build/lib/megatron/core/sequence_parallel/cross_entropy.py -> build/bdist.linux-x86_64/egg/megatron/core/sequence_parallel
creating build/bdist.linux-x86_64/egg/megatron/core/models
copying build/lib/megatron/core/models/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core/models
creating build/bdist.linux-x86_64/egg/megatron/core/models/gpt
copying build/lib/megatron/core/models/gpt/gpt_embedding.py -> build/bdist.linux-x86_64/egg/megatron/core/models/gpt
copying build/lib/megatron/core/models/gpt/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core/models/gpt
copying build/lib/megatron/core/models/gpt/gpt_model.py -> build/bdist.linux-x86_64/egg/megatron/core/models/gpt
creating build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/utils.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/mlp.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/transformer_layer.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/attention.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/core_attention.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/enums.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/module.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/transformer_block.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
copying build/lib/megatron/core/transformer/transformer_config.py -> build/bdist.linux-x86_64/egg/megatron/core/transformer
creating build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/utils.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/random.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/layers.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/weight_grad_store.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/data.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel
copying build/lib/megatron/core/enums.py -> build/bdist.linux-x86_64/egg/megatron/core
creating build/bdist.linux-x86_64/egg/megatron/core/fusions
copying build/lib/megatron/core/fusions/fused_softmax.py -> build/bdist.linux-x86_64/egg/megatron/core/fusions
copying build/lib/megatron/core/fusions/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/megatron/core/fusions
copying build/lib/megatron/core/fusions/fused_bias_dropout.py -> build/bdist.linux-x86_64/egg/megatron/core/fusions
copying build/lib/megatron/core/fusions/fused_bias_gelu.py -> build/bdist.linux-x86_64/egg/megatron/core/fusions
copying build/lib/megatron/core/fusions/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core/fusions
copying build/lib/megatron/core/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core
copying build/lib/megatron/core/package_info.py -> build/bdist.linux-x86_64/egg/megatron/core
copying build/lib/megatron/core/parallel_state.py -> build/bdist.linux-x86_64/egg/megatron/core
copying build/lib/megatron/core/model_parallel_config.py -> build/bdist.linux-x86_64/egg/megatron/core
creating build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel
copying build/lib/megatron/core/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel
copying build/lib/megatron/core/pipeline_parallel/schedules.py -> build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel
copying build/lib/megatron/core/pipeline_parallel/deepspeed_zbh1_engine.py -> build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel
copying build/lib/megatron/core/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel
copying build/lib/megatron/core/pipeline_parallel/deepspeed_zbh1_schedule.py -> build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel
copying build/lib/megatron/optimizer_param_scheduler.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/memory.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/text_generation_server.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/timers.py -> build/bdist.linux-x86_64/egg/megatron
copying build/lib/megatron/training.py -> build/bdist.linux-x86_64/egg/megatron
creating build/bdist.linux-x86_64/egg/tools
creating build/bdist.linux-x86_64/egg/tools/retro
creating build/bdist.linux-x86_64/egg/tools/retro/db
copying build/lib/tools/retro/db/utils.py -> build/bdist.linux-x86_64/egg/tools/retro/db
copying build/lib/tools/retro/db/build.py -> build/bdist.linux-x86_64/egg/tools/retro/db
copying build/lib/tools/retro/db/__init__.py -> build/bdist.linux-x86_64/egg/tools/retro/db
copying build/lib/tools/retro/db/dataset.py -> build/bdist.linux-x86_64/egg/tools/retro/db
copying build/lib/tools/retro/utils.py -> build/bdist.linux-x86_64/egg/tools/retro
creating build/bdist.linux-x86_64/egg/tools/retro/query
copying build/lib/tools/retro/query/utils.py -> build/bdist.linux-x86_64/egg/tools/retro/query
copying build/lib/tools/retro/query/chunk_dataset.py -> build/bdist.linux-x86_64/egg/tools/retro/query
copying build/lib/tools/retro/query/__init__.py -> build/bdist.linux-x86_64/egg/tools/retro/query
copying build/lib/tools/retro/query/query.py -> build/bdist.linux-x86_64/egg/tools/retro/query
copying build/lib/tools/retro/query/retro_dataset.py -> build/bdist.linux-x86_64/egg/tools/retro/query
creating build/bdist.linux-x86_64/egg/tools/retro/index
copying build/lib/tools/retro/index/utils.py -> build/bdist.linux-x86_64/egg/tools/retro/index
creating build/bdist.linux-x86_64/egg/tools/retro/index/indexes
copying build/lib/tools/retro/index/indexes/faiss_base.py -> build/bdist.linux-x86_64/egg/tools/retro/index/indexes
copying build/lib/tools/retro/index/indexes/__init__.py -> build/bdist.linux-x86_64/egg/tools/retro/index/indexes
copying build/lib/tools/retro/index/indexes/faiss_par_add.py -> build/bdist.linux-x86_64/egg/tools/retro/index/indexes
copying build/lib/tools/retro/index/build.py -> build/bdist.linux-x86_64/egg/tools/retro/index
copying build/lib/tools/retro/index/__init__.py -> build/bdist.linux-x86_64/egg/tools/retro/index
copying build/lib/tools/retro/index/index.py -> build/bdist.linux-x86_64/egg/tools/retro/index
copying build/lib/tools/retro/index/factory.py -> build/bdist.linux-x86_64/egg/tools/retro/index
copying build/lib/tools/retro/__init__.py -> build/bdist.linux-x86_64/egg/tools/retro
copying build/lib/tools/retro/external_libs.py -> build/bdist.linux-x86_64/egg/tools/retro
creating build/bdist.linux-x86_64/egg/tools/retro/cli
copying build/lib/tools/retro/cli/__main__.py -> build/bdist.linux-x86_64/egg/tools/retro/cli
copying build/lib/tools/retro/cli/__init__.py -> build/bdist.linux-x86_64/egg/tools/retro/cli
copying build/lib/tools/retro/cli/cli.py -> build/bdist.linux-x86_64/egg/tools/retro/cli
copying build/lib/tools/retro/main.py -> build/bdist.linux-x86_64/egg/tools/retro
copying build/lib/tools/hf2megads_weight_converter.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/merge_datasets.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/run_text_generation_server.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/linter.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/preprocess_data.py -> build/bdist.linux-x86_64/egg/tools
creating build/bdist.linux-x86_64/egg/tools/bert_embedding
copying build/lib/tools/bert_embedding/embed.py -> build/bdist.linux-x86_64/egg/tools/bert_embedding
copying build/lib/tools/bert_embedding/utils.py -> build/bdist.linux-x86_64/egg/tools/bert_embedding
copying build/lib/tools/bert_embedding/__init__.py -> build/bdist.linux-x86_64/egg/tools/bert_embedding
copying build/lib/tools/bert_embedding/huggingface.py -> build/bdist.linux-x86_64/egg/tools/bert_embedding
copying build/lib/tools/bert_embedding/external_libs.py -> build/bdist.linux-x86_64/egg/tools/bert_embedding
copying build/lib/tools/bert_embedding/dataset.py -> build/bdist.linux-x86_64/egg/tools/bert_embedding
copying build/lib/tools/checkpoint_loader_megatron.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/checkpoint_saver_megatron.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/generate_samples_gpt.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/preprocess_data_nmt.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/__init__.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/text_generation_cli.py -> build/bdist.linux-x86_64/egg/tools
copying build/lib/tools/checkpoint_util.py -> build/bdist.linux-x86_64/egg/tools
byte-compiling build/bdist.linux-x86_64/egg/tests/test_megatron.py to test_megatron.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils/check_slurm_job_completion.py to check_slurm_job_completion.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils/test_ci_pipeline.py to test_ci_pipeline.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils/test_resume_checkpoint_pipeline.py to test_resume_checkpoint_pipeline.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/functional_tests/python_test_utils/get_test_results_from_tensorboard_logs.py to get_test_results_from_tensorboard_logs.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/functional_tests/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/unit_tests/test_utilities.py to test_utilities.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/unit_tests/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/unit_tests/test_utils.py to test_utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/unit_tests/test_basic.py to test_basic.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/unit_tests/test_parallel_state.py to test_parallel_state.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/models/test_gpt_embedding.py to test_gpt_embedding.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/models/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/models/test_gpt_model.py to test_gpt_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/test_transformer_config.py to test_transformer_config.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/test_core_attention.py to test_core_attention.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/test_module.py to test_module.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/test_parallel_mlp.py to test_parallel_mlp.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/test_parallel_attention.py to test_parallel_attention.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/test_parallel_transformer_block.py to test_parallel_transformer_block.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/transformer/test_parallel_transformer_layer.py to test_parallel_transformer_layer.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/conftest.py to conftest.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/run_megatron.py to run_megatron.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/pipeline_parallel/test_schedules.py to test_schedules.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tests/pipeline_parallel/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/communication.py to communication.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/tokenization.py to tokenization.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/forward_step.py to forward_step.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/sampling.py to sampling.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/api.py to api.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/generation.py to generation.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation/beam_utils.py to beam_utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/p2p_communication.py to p2p_communication.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/initialize.py to initialize.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/global_vars.py to global_vars.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/checkpointing.py to checkpointing.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/dist_signal_handler.py to dist_signal_handler.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/profiler.py to profiler.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/indexer.py to indexer.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/blendable_dataset.py to blendable_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/image_folder.py to image_folder.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/prompt_dataset.py to prompt_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/gpt_dataset.py to gpt_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/t5_dataset.py to t5_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/data_samplers.py to data_samplers.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/dataset_utils.py to dataset_utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/bert_dataset.py to bert_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/realm_index.py to realm_index.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/vit_dataset.py to vit_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/orqa_wiki_dataset.py to orqa_wiki_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/realm_dataset_utils.py to realm_dataset_utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/ict_dataset.py to ict_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/indexed_dataset.py to indexed_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/biencoder_dataset_utils.py to biencoder_dataset_utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/data/autoaugment.py to autoaugment.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/tokenizer/bert_tokenization.py to bert_tokenization.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/tokenizer/gpt2_tokenization.py to gpt2_tokenization.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/tokenizer/tokenizer.py to tokenizer.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/tokenizer/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/microbatches.py to microbatches.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/optimizer/optimizer.py to optimizer.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/optimizer/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/optimizer/clip_grads.py to clip_grads.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/optimizer/distrib_optimizer.py to distrib_optimizer.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/optimizer/grad_scaler.py to grad_scaler.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/enums.py to enums.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/biencoder_model.py to biencoder_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/rmsnorm.py to rmsnorm.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/language_model.py to language_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/transformer.py to transformer.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/fused_softmax.py to fused_softmax.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/inpainting.py to inpainting.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/knn_monitor.py to knn_monitor.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/esvit_swin_backbone.py to esvit_swin_backbone.cpython-39.pyc
build/bdist.linux-x86_64/egg/megatron/model/vision/esvit_swin_backbone.py:729: SyntaxWarning: "is" with a literal. Did you mean "=="?
  or pretrained_layers[0] is '*'
build/bdist.linux-x86_64/egg/megatron/model/vision/esvit_swin_backbone.py:788: SyntaxWarning: "is" with a literal. Did you mean "=="?
  or (len(frozen_layers) > 0 and frozen_layers[0] is '*')
build/bdist.linux-x86_64/egg/megatron/model/vision/esvit_swin_backbone.py:799: SyntaxWarning: "is" with a literal. Did you mean "=="?
  or (len(frozen_layers) > 0 and frozen_layers[0] is '*')
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/vit_backbone.py to vit_backbone.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/swin_backbone.py to swin_backbone.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/mit_backbone.py to mit_backbone.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/classification.py to classification.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/vision/dino.py to dino.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/rotary_pos_embedding.py to rotary_pos_embedding.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/fused_layer_norm.py to fused_layer_norm.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/distributed.py to distributed.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/fused_bias_gelu.py to fused_bias_gelu.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/enums.py to enums.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/module.py to module.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/classification.py to classification.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/fused_rmsnorm.py to fused_rmsnorm.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/t5_model.py to t5_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/gpt_model.py to gpt_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/bert_model.py to bert_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/multiple_choice.py to multiple_choice.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/model/realm_model.py to realm_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/arguments.py to arguments.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation_utils.py to text_generation_utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/fused_kernels/tests/test_fused_kernels.py to test_fused_kernels.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/fused_kernels/tests/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/fused_kernels/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/sequence_parallel/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/sequence_parallel/cross_entropy.py to cross_entropy.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/models/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/models/gpt/gpt_embedding.py to gpt_embedding.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/models/gpt/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/models/gpt/gpt_model.py to gpt_model.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/mlp.py to mlp.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/transformer_layer.py to transformer_layer.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/attention.py to attention.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/core_attention.py to core_attention.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/enums.py to enums.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/module.py to module.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/transformer_block.py to transformer_block.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/transformer/transformer_config.py to transformer_config.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/mappings.py to mappings.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/random.py to random.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/layers.py to layers.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/weight_grad_store.py to weight_grad_store.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/data.py to data.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/tensor_parallel/cross_entropy.py to cross_entropy.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/enums.py to enums.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/fusions/fused_softmax.py to fused_softmax.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/fusions/fused_layer_norm.py to fused_layer_norm.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/fusions/fused_bias_dropout.py to fused_bias_dropout.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/fusions/fused_bias_gelu.py to fused_bias_gelu.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/fusions/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/package_info.py to package_info.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/parallel_state.py to parallel_state.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/model_parallel_config.py to model_parallel_config.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel/schedules.py to schedules.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel/deepspeed_zbh1_engine.py to deepspeed_zbh1_engine.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/core/pipeline_parallel/deepspeed_zbh1_schedule.py to deepspeed_zbh1_schedule.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/optimizer_param_scheduler.py to optimizer_param_scheduler.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/memory.py to memory.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/text_generation_server.py to text_generation_server.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/timers.py to timers.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/megatron/training.py to training.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/db/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/db/build.py to build.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/db/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/db/dataset.py to dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/query/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/query/chunk_dataset.py to chunk_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/query/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/query/query.py to query.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/query/retro_dataset.py to retro_dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/indexes/faiss_base.py to faiss_base.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/indexes/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/indexes/faiss_par_add.py to faiss_par_add.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/build.py to build.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/index.py to index.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/index/factory.py to factory.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/external_libs.py to external_libs.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/cli/__main__.py to __main__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/cli/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/cli/cli.py to cli.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/retro/main.py to main.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/hf2megads_weight_converter.py to hf2megads_weight_converter.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/merge_datasets.py to merge_datasets.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/run_text_generation_server.py to run_text_generation_server.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/linter.py to linter.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/preprocess_data.py to preprocess_data.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/bert_embedding/embed.py to embed.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/bert_embedding/utils.py to utils.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/bert_embedding/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/bert_embedding/huggingface.py to huggingface.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/bert_embedding/external_libs.py to external_libs.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/bert_embedding/dataset.py to dataset.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/checkpoint_loader_megatron.py to checkpoint_loader_megatron.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/checkpoint_saver_megatron.py to checkpoint_saver_megatron.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/generate_samples_gpt.py to generate_samples_gpt.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/preprocess_data_nmt.py to preprocess_data_nmt.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/__init__.py to __init__.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/text_generation_cli.py to text_generation_cli.cpython-39.pyc
byte-compiling build/bdist.linux-x86_64/egg/tools/checkpoint_util.py to checkpoint_util.cpython-39.pyc
creating build/bdist.linux-x86_64/egg/EGG-INFO
copying megatron_core.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO
copying megatron_core.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying megatron_core.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying megatron_core.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
copying megatron_core.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO
zip_safe flag not set; analyzing archive contents...
megatron.data.__pycache__.dataset_utils.cpython-39: module references __file__
megatron.fused_kernels.__pycache__.__init__.cpython-39: module references __file__
tools.__pycache__.checkpoint_loader_megatron.cpython-39: module references __file__
tools.__pycache__.checkpoint_saver_megatron.cpython-39: module references __file__
tools.__pycache__.generate_samples_gpt.cpython-39: module references __file__
tools.__pycache__.hf2megads_weight_converter.cpython-39: module references __file__
tools.__pycache__.linter.cpython-39: module references __file__
tools.__pycache__.merge_datasets.cpython-39: module references __file__
tools.__pycache__.preprocess_data.cpython-39: module references __file__
tools.__pycache__.preprocess_data_nmt.cpython-39: module references __file__
tools.__pycache__.run_text_generation_server.cpython-39: module references __file__
creating dist
creating 'dist/megatron_core-0.2.0-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it
removing 'build/bdist.linux-x86_64/egg' (and everything under it)
Processing megatron_core-0.2.0-py3.9.egg
creating /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/megatron_core-0.2.0-py3.9.egg
Extracting megatron_core-0.2.0-py3.9.egg to /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
/work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/megatron_core-0.2.0-py3.9.egg/megatron/model/vision/esvit_swin_backbone.py:729: SyntaxWarning: "is" with a literal. Did you mean "=="?
  or pretrained_layers[0] is '*'
/work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/megatron_core-0.2.0-py3.9.egg/megatron/model/vision/esvit_swin_backbone.py:788: SyntaxWarning: "is" with a literal. Did you mean "=="?
  or (len(frozen_layers) > 0 and frozen_layers[0] is '*')
/work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/megatron_core-0.2.0-py3.9.egg/megatron/model/vision/esvit_swin_backbone.py:799: SyntaxWarning: "is" with a literal. Did you mean "=="?
  or (len(frozen_layers) > 0 and frozen_layers[0] is '*')
Adding megatron-core 0.2.0 to easy-install.pth file

Installed /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/megatron_core-0.2.0-py3.9.egg
Processing dependencies for megatron-core==0.2.0
Searching for regex==2024.7.24
Best match: regex 2024.7.24
Adding regex 2024.7.24 to easy-install.pth file
detected new path './megatron_core-0.2.0-py3.9.egg'

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for torch==2.1.0+cu118
Best match: torch 2.1.0+cu118
Adding torch 2.1.0+cu118 to easy-install.pth file
Installing convert-caffe2-to-onnx script to /work/gb20/b20048/miniconda3/envs/deep/bin
Installing convert-onnx-to-caffe2 script to /work/gb20/b20048/miniconda3/envs/deep/bin
Installing torchrun script to /work/gb20/b20048/miniconda3/envs/deep/bin

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for pybind11==2.13.5
Best match: pybind11 2.13.5
Adding pybind11 2.13.5 to easy-install.pth file
Installing pybind11-config script to /work/gb20/b20048/miniconda3/envs/deep/bin

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for triton==2.1.0
Best match: triton 2.1.0
Adding triton 2.1.0 to easy-install.pth file

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for fsspec==2024.2.0
Best match: fsspec 2024.2.0
Adding fsspec 2024.2.0 to easy-install.pth file

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for Jinja2==3.1.3
Best match: Jinja2 3.1.3
Adding Jinja2 3.1.3 to easy-install.pth file

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for networkx==3.2.1
Best match: networkx 3.2.1
Adding networkx 3.2.1 to easy-install.pth file

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for sympy==1.12
Best match: sympy 1.12
Adding sympy 1.12 to easy-install.pth file
Installing isympy script to /work/gb20/b20048/miniconda3/envs/deep/bin

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for typing-extensions==4.12.2
Best match: typing-extensions 4.12.2
Adding typing-extensions 4.12.2 to easy-install.pth file

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages/setuptools/_vendor
Searching for filelock==3.13.1
Best match: filelock 3.13.1
Adding filelock 3.13.1 to easy-install.pth file
detected new path './setuptools/_vendor'

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for MarkupSafe==2.1.5
Best match: MarkupSafe 2.1.5
Adding MarkupSafe 2.1.5 to easy-install.pth file

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Searching for mpmath==1.3.0
Best match: mpmath 1.3.0
Adding mpmath 1.3.0 to easy-install.pth file

Using /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages
Finished processing dependencies for megatron-core==0.2.0
Collecting flash-attn==2.5.0
  Downloading flash_attn-2.5.0.tar.gz (2.5 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.5/2.5 MB 208.9 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: torch in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from flash-attn==2.5.0) (2.1.0+cu118)
Requirement already satisfied: einops in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from flash-attn==2.5.0) (0.8.0)
Requirement already satisfied: packaging in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from flash-attn==2.5.0) (24.1)
Requirement already satisfied: ninja in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from flash-attn==2.5.0) (1.11.1)
Requirement already satisfied: filelock in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->flash-attn==2.5.0) (3.13.1)
Requirement already satisfied: typing-extensions in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->flash-attn==2.5.0) (4.9.0)
Requirement already satisfied: sympy in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->flash-attn==2.5.0) (1.12)
Requirement already satisfied: networkx in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->flash-attn==2.5.0) (3.2.1)
Requirement already satisfied: jinja2 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->flash-attn==2.5.0) (3.1.3)
Requirement already satisfied: fsspec in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->flash-attn==2.5.0) (2024.2.0)
Requirement already satisfied: triton==2.1.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from torch->flash-attn==2.5.0) (2.1.0)
Requirement already satisfied: MarkupSafe>=2.0 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from jinja2->torch->flash-attn==2.5.0) (2.1.5)
Requirement already satisfied: mpmath>=0.19 in /work/02/gb20/b20048/miniconda3/envs/deep/lib/python3.9/site-packages (from sympy->torch->flash-attn==2.5.0) (1.3.0)
Building wheels for collected packages: flash-attn
  Building wheel for flash-attn (setup.py): started
  Building wheel for flash-attn (setup.py): finished with status 'done'
  Created wheel for flash-attn: filename=flash_attn-2.5.0-cp39-cp39-linux_x86_64.whl size=121826792 sha256=9bab7532eec56c017e5575fccf900b50d9a9f6e210f191593a83f6514b2c7420
  Stored in directory: /tmp/pip-ephem-wheel-cache-ffpelobe/wheels/ae/90/c0/4bffd5e6ae890c722c6a4f745393baedde6e2ba75f384fab76
Successfully built flash-attn
Installing collected packages: flash-attn
Successfully installed flash-attn-2.5.0
* Confirming packages
Package                 Version
----------------------- -------------------
absl-py                 2.1.0
accelerate              0.33.0
aiohappyeyeballs        2.4.0
aiohttp                 3.10.5
aiosignal               1.3.1
annotated-types         0.7.0
apex                    0.1
async-timeout           4.0.3
attrs                   24.2.0
autocommand             2.2.2
backports.tarfile       1.2.0
bitsandbytes            0.43.3
certifi                 2022.12.7
chardet                 5.2.0
charset-normalizer      2.1.1
click                   8.1.7
cmake                   3.30.2
datasets                2.21.0
deepspeed               0.12.4
deepspeed-kernels       0.0.1.dev1698255861
dill                    0.3.8
docker-pycreds          0.4.0
docstring_parser        0.16
einops                  0.8.0
eval_type_backport      0.2.0
filelock                3.13.1
flash-attn              2.5.0
frozenlist              1.4.1
fsspec                  2024.2.0
gitdb                   4.0.11
GitPython               3.1.43
grpcio                  1.66.1
hjson                   3.1.0
huggingface-hub         0.24.6
idna                    3.4
importlib_metadata      8.4.0
importlib_resources     6.4.0
inflect                 7.3.1
jaraco.context          5.3.0
jaraco.functools        4.0.1
jaraco.text             3.12.1
Jinja2                  3.1.3
joblib                  1.4.2
Markdown                3.7
markdown-it-py          3.0.0
MarkupSafe              2.1.5
mdurl                   0.1.2
megatron_core           0.2.0
more-itertools          10.3.0
mpmath                  1.3.0
multidict               6.0.5
multiprocess            0.70.16
networkx                3.2.1
ninja                   1.11.1
nltk                    3.9.1
numpy                   1.26.3
ordered-set             4.1.0
packaging               24.1
pandas                  2.2.2
peft                    0.12.0
pillow                  10.2.0
pip                     24.2
platformdirs            4.2.2
protobuf                3.20.3
psutil                  6.0.0
py-cpuinfo              9.0.0
pyarrow                 17.0.0
pybind11                2.13.5
pydantic                2.8.2
pydantic_core           2.20.1
Pygments                2.18.0
pynvml                  11.5.3
python-dateutil         2.9.0.post0
pytz                    2024.1
PyYAML                  6.0.2
regex                   2024.7.24
requests                2.32.3
rich                    13.8.0
safetensors             0.4.4
sentencepiece           0.2.0
sentry-sdk              2.13.0
setproctitle            1.3.3
setuptools              72.1.0
shtab                   1.7.1
six                     1.16.0
smmap                   5.0.1
sympy                   1.12
tensorboard             2.17.1
tensorboard-data-server 0.7.2
tokenizers              0.19.1
tomli                   2.0.1
torch                   2.1.0+cu118
torchaudio              2.1.0+cu118
torchvision             0.16.0+cu118
tqdm                    4.66.5
transformers            4.44.2
triton                  2.1.0
trl                     0.10.1
typeguard               4.3.0
typing_extensions       4.9.0
tyro                    0.8.10
tzdata                  2024.1
urllib3                 1.26.13
wandb                   0.17.8
Werkzeug                3.0.4
wheel                   0.43.0
xxhash                  3.5.0
yarl                    1.9.7
zipp                    3.20.1
