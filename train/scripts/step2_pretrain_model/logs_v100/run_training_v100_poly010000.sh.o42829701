
ssh_config_file = /home/acf16449gb/.ssh/config

SSH configuration has been updated.
Host g0156
    HostName g0156
    Port 2222
    StrictHostKeyChecking no

Host g0159
    HostName g0159
    Port 2222
    StrictHostKeyChecking no

Host g0161
    HostName g0161
    Port 2222
    StrictHostKeyChecking no

Host g0163
    HostName g0163
    Port 2222
    StrictHostKeyChecking no

Host g0164
    HostName g0164
    Port 2222
    StrictHostKeyChecking no

Host g0165
    HostName g0165
    Port 2222
    StrictHostKeyChecking no

Host g0166
    HostName g0166
    Port 2222
    StrictHostKeyChecking no

Host g0167
    HostName g0167
    Port 2222
    StrictHostKeyChecking no



ucllm_nedo_dev_train_dir = /home/acf16449gb/ucllm_nedo_prod/train
megatron_deepspeed_dir = /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed

input_tokenizer_file = /groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_poly_010000_1234_True.model
output_model_dir = /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True
save_interval = 1000
wandb_entity = yohei-kobashi
wandb_project = encrypted_data_LLM
wandb_tag = other_gpu

Number of GPUs per node: 4
Both /groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_010000_1234_True_text_document.bin and /groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_010000_1234_True_text_document.idx already exist.

hostfile = ./abci_node-8_gpu-32-v100/hostfile_jobid-42829701
g0156 slots=4
g0159 slots=4
g0161 slots=4
g0163 slots=4
g0164 slots=4
g0165 slots=4
g0166 slots=4
g0167 slots=4

[2024-08-12 02:21:15,423] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 02:21:21,141] [INFO] [runner.py:463:main] Using IP address of 10.1.5.20 for node g0156
[2024-08-12 02:21:21,143] [INFO] [multinode_runner.py:72:get_cmd] Running on the following workers: g0156,g0159,g0161,g0163,g0164,g0165,g0166,g0167
[2024-08-12 02:21:21,144] [INFO] [runner.py:570:main] cmd = pdsh -S -f 1024 -w g0156,g0159,g0161,g0163,g0164,g0165,g0166,g0167 export PYTHONPATH=/home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model;  cd /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model; /home/acf16449gb/crypto_llm/train/.venv_train/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJnMDE1NiI6IFswLCAxLCAyLCAzXSwgImcwMTU5IjogWzAsIDEsIDIsIDNdLCAiZzAxNjEiOiBbMCwgMSwgMiwgM10sICJnMDE2MyI6IFswLCAxLCAyLCAzXSwgImcwMTY0IjogWzAsIDEsIDIsIDNdLCAiZzAxNjUiOiBbMCwgMSwgMiwgM10sICJnMDE2NiI6IFswLCAxLCAyLCAzXSwgImcwMTY3IjogWzAsIDEsIDIsIDNdfQ== --node_rank=%n --master_addr=10.1.5.20 --master_port=29500 /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/pretrain_gpt.py --override-opt_param-scheduler --optimizer 'adam' --adam-beta1 '0.9' --adam-beta2 '0.95' --tensor-model-parallel-size '1' --init-method-std '0.013' --lr-decay-tokens '300000000000' --lr-warmup-tokens '3000000000' --micro-batch-size '1' --exit-duration-in-mins '30000000' --global-batch-size '128' --num-layers '22' --hidden-size '2048' --ffn-hidden-size '5632' --num-attention-heads '16' --num-key-value-heads '4' --no-query-key-layer-scaling --attention-dropout '0' --hidden-dropout '0' --use-rotary-position-embeddings --untie-embeddings-and-output-weights --swiglu --normalization 'rmsnorm' --disable-bias-linear --seq-length '2048' --max-position-embeddings '2048' --train-tokens '13631488000' --train-samples '6656000' --train-data-exact-num-epochs '1' --lr '2.0e-4' --min-lr '1.0e-5' --lr-decay-style 'cosine' --split '949,50,1' --log-interval '10' --eval-interval '1000' --eval-iters '100' --save-interval '1000' --weight-decay '0.1' --clip-grad '1.0' --hysteresis '2' --num-workers '0' --seed '1234' --load '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase' --save '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase' --no-async-tensor-model-parallel-allreduce --tensorboard-queue-size '1' --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --tensorboard-dir '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/tensorboard/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase_0.latin_wikipedia_poly_010000_1234_True' --log-optimizer-states-to-tensorboard --tokenizer-type 'SentencePieceTokenizer' --tokenizer-model '/groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_poly_010000_1234_True.model' --data-path '/groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_010000_1234_True_text_document' --data-impl 'mmap' --deepspeed --deepspeed_config '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/deepspeed_config/ds_config_gbs128_mbs1_log10_zero0.json' --zero-stage '0' --pipeline-model-parallel-size '8' --use_wandb --wandb_entity 'yohei-kobashi' --wandb_project 'encrypted_data_LLM' --wandb_group 'pretrain_gpt_1.1B_0.latin_wikipedia_poly_010000_1234_True' --wandb_tag 'other_gpu'
g0156: [2024-08-12 02:21:24,575] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0156: [2024-08-12 02:21:26,733] [INFO] [launch.py:138:main] 0 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0156: [2024-08-12 02:21:26,733] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0156: [2024-08-12 02:21:26,733] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=0
g0156: [2024-08-12 02:21:26,733] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0156: [2024-08-12 02:21:26,733] [INFO] [launch.py:163:main] dist_world_size=32
g0156: [2024-08-12 02:21:26,733] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0156: [2024-08-12 02:21:29,805] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0156: [2024-08-12 02:21:29,868] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0156: [2024-08-12 02:21:29,928] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0156: [2024-08-12 02:21:30,098] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0164: [2024-08-12 02:21:31,527] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0161: [2024-08-12 02:21:31,625] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0159: [2024-08-12 02:21:31,710] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0163: [2024-08-12 02:21:31,724] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0165: [2024-08-12 02:21:32,029] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0166: [2024-08-12 02:21:32,561] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0167: [2024-08-12 02:21:33,097] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0156: --------------------------------------------------
g0156: DeepSpeed C++/CUDA extension op report
g0156: --------------------------------------------------
g0156: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0156:       runtime if needed. Op compatibility means that your system
g0156:       meet the required dependencies to JIT install the op.
g0156: --------------------------------------------------
g0156: JIT compiled ops requires ninja
g0156: --------------------------------------------------
g0156: DeepSpeed C++/CUDA extension op report
g0156: --------------------------------------------------
g0156: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0156:       runtime if needed. Op compatibility means that your system
g0156:       meet the required dependencies to JIT install the op.
g0156: --------------------------------------------------
g0156: JIT compiled ops requires ninja
g0156: --------------------------------------------------
g0156: DeepSpeed C++/CUDA extension op report
g0156: --------------------------------------------------
g0156: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0156:       runtime if needed. Op compatibility means that your system
g0156:       meet the required dependencies to JIT install the op.
g0156: --------------------------------------------------
g0156: JIT compiled ops requires ninja
g0156: --------------------------------------------------
g0156: DeepSpeed C++/CUDA extension op report
g0156: --------------------------------------------------
g0156: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0156:       runtime if needed. Op compatibility means that your system
g0156:       meet the required dependencies to JIT install the op.
g0156: --------------------------------------------------
g0156: JIT compiled ops requires ninja
g0156: ninja .................. ninjaninja[92m[OKAY][0mninja
g0156:    ....................................--------------------------------------------------.................. 
g0156:   [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m
g0156: op name
g0156: 
g0156:  --------------------------------------------------................
g0156: -------------------------------------------------- --------------------------------------------------
g0156: installedop name
g0156:  op name .. op name................................   ................installedcompatible  
g0156:  installedinstalled--------------------------------------------------..  
g0156: ..  ..compatiblecompatible 
g0156: 
g0156: compatible----------------------------------------------------------------------------------------------------
g0156: 
g0156: 
g0156: --------------------------------------------------
g0156: async_io ...............async_io [92m[YES][0m  .....................  [92m[YES][0m[92m[OKAY][0m ......
g0156:  [92m[OKAY][0m
g0156: fused_adam ............. fused_adam[92m[YES][0m  ...................  [92m[YES][0m[92m[OKAY][0m 
g0156: ...... [92m[OKAY][0m
g0156: cpu_adam ...............cpu_adam  [92m[YES][0m...............  ......[92m[YES][0m  [92m[OKAY][0m......
g0156:  [92m[OKAY][0m
g0156: cpu_adagrad ............cpu_adagrad  [92m[YES][0m............  ......[92m[YES][0m  [92m[OKAY][0m......
g0156:  [92m[OKAY][0m
g0156: cpu_lion ...............cpu_lion  [92m[YES][0m...............  ......[92m[YES][0m async_io [92m[OKAY][0m...... 
g0156:  ...............[92m[OKAY][0m 
g0156: [92m[YES][0m ...... [92m[OKAY][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0156: 
g0156: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0156: evoformer_attn evoformer_attn.........  fused_adam.........[93m[NO][0m   ....................[93m[NO][0m   [92m[YES][0m[93m[NO][0m....... 
g0156:  ......[93m[NO][0m fused_lamb
g0156: [92m[OKAY][0m 
g0156: .............fused_lamb  [92m[YES][0m.............  cpu_adam[92m[YES][0m......   ...............[92m[OKAY][0m...... 
g0156:  [92m[YES][0m[92m[OKAY][0m 
g0156: ...... [92m[OKAY][0m
g0156: fused_lioncpu_adagrad fused_lion.............   .........................[92m[YES][0m   [92m[YES][0m[92m[YES][0m......   ............[92m[OKAY][0m  
g0156: [92m[OKAY][0m[92m[OKAY][0m
g0156: 
g0156: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0156: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0156: async_ioevoformer_attn  ........................  [93m[NO][0m[92m[YES][0m  .............  [93m[NO][0m[92m[OKAY][0m
g0156: 
g0156: fused_lamb ............. [92m[YES][0mfused_adam  ...................  [92m[OKAY][0m[92m[YES][0m
g0156:  ...... [92m[OKAY][0m
g0156: cpu_adam ...............fused_lion  [92m[YES][0m.............  ......[92m[YES][0m  [92m[OKAY][0m......
g0156:  [92m[OKAY][0m
g0156: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0156: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0156: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0156: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0156: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0156: inference_core_ops ..... [92m[YES][0m ......inference_core_ops  [92m[OKAY][0m.....
g0156:  [92m[YES][0m ...... [92m[OKAY][0m
g0156: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0156: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0156: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: cutlass_ops ............ [92m[YES][0m ...... cutlass_ops[92m[OKAY][0m 
g0156: ............ [92m[YES][0m quantizer......  ..............[92m[OKAY][0m 
g0156: [92m[YES][0m ...... quantizer[92m[OKAY][0m 
g0156: .............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0156: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0156: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0156: ragged_device_opsragged_device_ops  ............  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0156: 
g0156: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0156: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0156: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0156: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0156: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0156: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0156: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0156: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0156: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0156: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0156: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0156: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0156: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0156: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0156: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0156: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0156: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0156: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0156: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0156: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0156: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0156: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0156: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0156: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0156: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0156: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0156: --------------------------------------------------
g0156: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0156: --------------------------------------------------
g0156: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0156: --------------------------------------------------
g0156: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0156: --------------------------------------------------
g0156: DeepSpeed general environment info:
g0156: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0156: torch version .................... 2.0.1+cu118
g0156: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0156: deepspeed info ................... 0.12.4, unknown, unknown
g0156: torch cuda version ............... 11.8
g0156: torch hip version ................ None
g0156: nvcc version ..................... 11.8
g0156: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0156: shared memory (/dev/shm) size .... 188.13 GB
g0156: DeepSpeed general environment info:
g0156: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0156: torch version .................... 2.0.1+cu118
g0156: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0156: deepspeed info ................... 0.12.4, unknown, unknown
g0156: torch cuda version ............... 11.8
g0156: torch hip version ................ None
g0156: nvcc version ..................... 11.8
g0156: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0156: shared memory (/dev/shm) size .... 188.13 GB
g0156: DeepSpeed general environment info:
g0156: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0156: torch version .................... 2.0.1+cu118
g0156: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0156: deepspeed info ................... 0.12.4, unknown, unknown
g0156: torch cuda version ............... 11.8
g0156: torch hip version ................ None
g0156: nvcc version ..................... 11.8
g0156: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0156: shared memory (/dev/shm) size .... 188.13 GB
g0156: DeepSpeed general environment info:
g0156: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0156: torch version .................... 2.0.1+cu118
g0156: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0156: deepspeed info ................... 0.12.4, unknown, unknown
g0156: torch cuda version ............... 11.8
g0156: torch hip version ................ None
g0156: nvcc version ..................... 11.8
g0156: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0156: shared memory (/dev/shm) size .... 188.13 GB
g0156: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0156: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0156: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0156: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0156: using world size: 32, data-parallel-size: 4, sequence-parallel size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 8 
g0156: WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:SentencePieceTokenizer
g0156: using torch.float32 for parameters ...
g0156: ------------------------ arguments ------------------------
g0156:   accumulate_allreduce_grads_in_fp32 .............. False
g0156:   adam_beta1 ...................................... 0.9
g0156:   adam_beta2 ...................................... 0.95
g0156:   adam_eps ........................................ 1e-08
g0156:   add_bias_linear ................................. False
g0156:   add_position_embedding .......................... False
g0156:   adlr_autoresume ................................. False
g0156:   adlr_autoresume_interval ........................ 1000
g0156:   aml_data_download_path .......................... None
g0156:   apply_layernorm_1p .............................. False
g0156:   apply_query_key_layer_scaling ................... False
g0156:   apply_residual_connection_post_layernorm ........ False
g0156:   async_tensor_model_parallel_allreduce ........... False
g0156:   attention_dropout ............................... 0.0
g0156:   attention_softmax_in_fp32 ....................... False
g0156:   barrier_with_L1_time ............................ True
g0156:   bert_binary_head ................................ True
g0156:   bert_embedder_type .............................. megatron
g0156:   bert_load ....................................... None
g0156:   bf16 ............................................ False
g0156:   bias_dropout_fusion ............................. True
g0156:   bias_gelu_fusion ................................ False
g0156:   biencoder_projection_dim ........................ 0
g0156:   biencoder_shared_query_context_model ............ False
g0156:   block_data_path ................................. None
g0156:   checkpoint_activations .......................... False
g0156:   checkpoint_in_cpu ............................... False
g0156:   checkpoint_num_layers ........................... 1
g0156:   classes_fraction ................................ 1.0
g0156:   clip_grad ....................................... 1.0
g0156:   compression_training ............................ False
g0156:   consumed_train_samples .......................... 0
g0156:   consumed_train_tokens ........................... 0
g0156:   consumed_valid_samples .......................... 0
g0156:   contigious_checkpointing ........................ False
g0156:   cpu_optimizer ................................... False
g0156:   cpu_torch_adam .................................. False
g0156:   create_moe_param_group .......................... False
g0156:   curriculum_learning_legacy ...................... False
g0156:   data_cache_path ................................. None
g0156:   data_efficiency_curriculum_learning ............. False
g0156:   data_impl ....................................... mmap
g0156:   data_parallel_random_init ....................... False
g0156:   data_parallel_size .............................. 4
g0156:   data_path ....................................... ['/groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_010000_1234_True_text_document']
g0156:   data_per_class_fraction ......................... 1.0
g0156:   data_sharding ................................... True
g0156:   dataloader_type ................................. single
g0156:   DDP_impl ........................................ local
g0156:   decoder_num_layers .............................. None
g0156:   decoder_seq_length .............................. None
g0156:   deepscale ....................................... False
g0156:   deepscale_config ................................ None
g0156:   deepspeed ....................................... True
g0156:   deepspeed_activation_checkpointing .............. False
g0156:   deepspeed_config ................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/deepspeed_config/ds_config_gbs128_mbs1_log10_zero0.json
g0156:   deepspeed_mpi ................................... False
g0156:   dino_bottleneck_size ............................ 256
g0156:   dino_freeze_last_layer .......................... 1
g0156:   dino_head_hidden_size ........................... 2048
g0156:   dino_local_crops_number ......................... 10
g0156:   dino_local_img_size ............................. 96
g0156:   dino_norm_last_layer ............................ False
g0156:   dino_teacher_temp ............................... 0.07
g0156:   dino_warmup_teacher_temp ........................ 0.04
g0156:   dino_warmup_teacher_temp_epochs ................. 30
g0156:   distribute_checkpointed_activations ............. False
g0156:   distribute_saved_activations .................... False
g0156:   distributed_backend ............................. nccl
g0156:   distributed_timeout_minutes ..................... 10
g0156:   ds_fused_adam ................................... False
g0156:   ds_inference .................................... False
g0156:   ds_pipeline_enabled ............................. True
g0156:   ds_sequence_parallel_size ....................... 1
g0156:   embedding_path .................................. None
g0156:   embedding_weights_in_fp32 ....................... False
g0156:   empty_unused_memory_level ....................... 0
g0156:   enable_expert_tensor_parallelism ................ False
g0156:   encoder_num_layers .............................. 22
g0156:   encoder_seq_length .............................. 2048
g0156:   end_weight_decay ................................ 0.1
g0156:   eod_mask_loss ................................... False
g0156:   eval_interval ................................... 1000
g0156:   eval_iters ...................................... 100
g0156:   evidence_data_path .............................. None
g0156:   exit_duration_in_mins ........................... 30000000
g0156:   exit_interval ................................... None
g0156:   exit_on_missing_checkpoint ...................... False
g0156:   exit_signal_handler ............................. False
g0156:   expert_interval ................................. 2
g0156:   ffn_hidden_size ................................. 5632
g0156:   finetune ........................................ False
g0156:   force_ds_sequence_parallel ...................... False
g0156:   fp16 ............................................ False
g0156:   fp16_lm_cross_entropy ........................... False
g0156:   fp32_residual_connection ........................ False
g0156:   fp8_amax_compute_algo ........................... most_recent
g0156:   fp8_amax_history_len ............................ 1
g0156:   fp8_e4m3 ........................................ False
g0156:   fp8_hybrid ...................................... False
g0156:   fp8_interval .................................... 1
g0156:   fp8_margin ...................................... 0
g0156:   fp8_wgrad ....................................... True
g0156:   global_batch_size ............................... 128
g0156:   gradient_accumulation_fusion .................... True
g0156:   head_lr_mult .................................... 1.0
g0156:   hidden_dropout .................................. 0.0
g0156:   hidden_size ..................................... 2048
g0156:   hidden_size_teacher ............................. None
g0156:   hysteresis ...................................... 2
g0156:   ict_head_size ................................... None
g0156:   ict_load ........................................ None
g0156:   img_h ........................................... 224
g0156:   img_w ........................................... 224
g0156:   indexer_batch_size .............................. 128
g0156:   indexer_log_interval ............................ 1000
g0156:   inference ....................................... False
g0156:   inference_batch_times_seqlen_threshold .......... 512
g0156:   init_method_std ................................. 0.013
g0156:   init_method_xavier_uniform ...................... False
g0156:   initial_loss_scale .............................. 4294967296
g0156:   iter_per_epoch .................................. 1250
g0156:   kd .............................................. False
g0156:   kd_alpha_ce ..................................... 1
g0156:   kd_beta_ce ...................................... 1
g0156:   kd_temp ......................................... 1.0
g0156:   kv_channels ..................................... 128
g0156:   layernorm_epsilon ............................... 1e-05
g0156:   lazy_mpu_init ................................... None
g0156:   load ............................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase
g0156:   load_teacher .................................... None
g0156:   local_rank ...................................... 0
g0156:   log_batch_size_to_tensorboard ................... True
g0156:   log_interval .................................... 10
g0156:   log_learning_rate_to_tensorboard ................ True
g0156:   log_loss_scale_to_tensorboard ................... True
g0156:   log_memory_to_tensorboard ....................... False
g0156:   log_num_zeros_in_grad ........................... False
g0156:   log_optimizer_states_to_tensorboard ............. True
g0156:   log_params_norm ................................. False
g0156:   log_timers_to_tensorboard ....................... True
g0156:   log_validation_ppl_to_tensorboard ............... True
g0156:   log_world_size_to_tensorboard ................... False
g0156:   loss_scale ...................................... None
g0156:   loss_scale_window ............................... 1000
g0156:   lr .............................................. 0.0002
g0156:   lr_decay_iters .................................. None
g0156:   lr_decay_samples ................................ None
g0156:   lr_decay_style .................................. cosine
g0156:   lr_decay_tokens ................................. 300000000000
g0156:   lr_warmup_fraction .............................. None
g0156:   lr_warmup_iters ................................. 0
g0156:   lr_warmup_samples ............................... 0
g0156:   lr_warmup_tokens ................................ 3000000000
g0156:   make_vocab_size_divisible_by .................... 128
g0156:   mask_factor ..................................... 1.0
g0156:   mask_prob ....................................... 0.15
g0156:   mask_type ....................................... random
g0156:   masked_softmax_fusion ........................... True
g0156:   max_position_embeddings ......................... 2048
g0156:   max_tokens_to_oom ............................... 12000
g0156:   mem_efficient_ln ................................ True
g0156:   memory_centric_tiled_linear ..................... False
g0156:   merge_file ...................................... None
g0156:   micro_batch_size ................................ 1
g0156:   min_loss_scale .................................. 1.0
g0156:   min_lr .......................................... 1e-05
g0156:   mlp_type ........................................ standard
g0156:   mmap_warmup ..................................... False
g0156:   moe_eval_capacity_factor ........................ 1.0
g0156:   moe_expert_parallel_size ........................ 1
g0156:   moe_loss_coeff .................................. 0.1
g0156:   moe_min_capacity ................................ 4
g0156:   moe_token_dropping .............................. True
g0156:   moe_train_capacity_factor ....................... 1.0
g0156:   mos ............................................. False
g0156:   no_load_lr_state ................................ False
g0156:   no_load_optim ................................... None
g0156:   no_load_rng ..................................... None
g0156:   no_persist_layer_norm ........................... False
g0156:   no_pipeline_parallel ............................ False
g0156:   no_save_optim ................................... None
g0156:   no_save_rng ..................................... None
g0156:   normalization ................................... rmsnorm
g0156:   num_attention_heads ............................. 16
g0156:   num_attention_heads_teacher ..................... None
g0156:   num_channels .................................... 3
g0156:   num_classes ..................................... 1000
g0156:   num_experts ..................................... [1]
g0156:   num_experts_switch .............................. None
g0156:   num_experts_teacher ............................. [1]
g0156:   num_key_value_heads ............................. 4
g0156:   num_layers ...................................... 22
g0156:   num_layers_per_virtual_pipeline_stage ........... None
g0156:   num_layers_teacher .............................. None
g0156:   num_workers ..................................... 0
g0156:   onnx_safe ....................................... None
g0156:   openai_gelu ..................................... False
g0156:   optimizer ....................................... adam
g0156:   output_bert_embeddings .......................... False
g0156:   overlap_p2p_comm ................................ False
g0156:   override_opt_param_scheduler .................... True
g0156:   params_dtype .................................... torch.float32
g0156:   partition_activations ........................... False
g0156:   patch_dim ....................................... 16
g0156:   perform_initialization .......................... True
g0156:   pipeline_model_parallel_size .................... 8
g0156:   pipeline_model_parallel_split_rank .............. None
g0156:   profile_backward ................................ False
g0156:   query_in_block_prob ............................. 0.1
g0156:   rampup_batch_size ............................... None
g0156:   random_ltd ...................................... False
g0156:   rank ............................................ 0
g0156:   recompute_granularity ........................... None
g0156:   recompute_method ................................ None
g0156:   recompute_num_layers ............................ 1
g0156:   remote_device ................................... none
g0156:   repeated_dataloader ............................. False
g0156:   reset_attention_mask ............................ False
g0156:   reset_iteration ................................. False
g0156:   reset_position_ids .............................. False
g0156:   retriever_report_topk_accuracies ................ []
g0156:   retriever_score_scaling ......................... False
g0156:   retriever_seq_length ............................ 256
g0156:   retro_add_retriever ............................. False
g0156:   retro_cyclic_train_iters ........................ None
g0156:   retro_encoder_attention_dropout ................. 0.1
g0156:   retro_encoder_hidden_dropout .................... 0.1
g0156:   retro_encoder_layers ............................ 2
g0156:   retro_num_neighbors ............................. 2
g0156:   retro_num_retrieved_chunks ...................... 2
g0156:   retro_return_doc_ids ............................ False
g0156:   retro_workdir ................................... None
g0156:   return_data_index ............................... False
g0156:   rotary_percent .................................. 1.0
g0156:   sample_rate ..................................... 1.0
g0156:   save ............................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase
g0156:   save_interval ................................... 1000
g0156:   scatter_gather_tensors_in_pipeline .............. True
g0156:   scattered_embeddings ............................ False
g0156:   seed ............................................ 1234
g0156:   seq_length ...................................... 2048
g0156:   sequence_parallel ............................... False
g0156:   sgd_momentum .................................... 0.9
g0156:   short_seq_prob .................................. 0.1
g0156:   skip_train ...................................... False
g0156:   split ........................................... 949,50,1
g0156:   split_transformers .............................. False
g0156:   squared_relu .................................... False
g0156:   standalone_embedding_stage ...................... False
g0156:   start_weight_decay .............................. 0.1
g0156:   swiglu .......................................... True
g0156:   swin_backbone_type .............................. tiny
g0156:   synchronize_each_layer .......................... False
g0156:   tensor_model_parallel_size ...................... 1
g0156:   tensorboard_dir ................................. /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/tensorboard/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase_0.latin_wikipedia_poly_010000_1234_True
g0156:   tensorboard_log_interval ........................ 1
g0156:   tensorboard_queue_size .......................... 1
g0156:   test_data_path .................................. None
g0156:   tf32 ............................................ False
g0156:   tile_factor ..................................... 1
g0156:   timing_log_level ................................ 0
g0156:   timing_log_option ............................... minmax
g0156:   titles_data_path ................................ None
g0156:   tokenizer_model ................................. /groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_poly_010000_1234_True.model
g0156:   tokenizer_type .................................. SentencePieceTokenizer
g0156:   topk ............................................ 1
g0156:   train_data_exact_num_epochs ..................... 1
g0156:   train_data_path ................................. None
g0156:   train_desc_path ................................. None
g0156:   train_doc_idx_path .............................. None
g0156:   train_idx_path .................................. None
g0156:   train_iters ..................................... None
g0156:   train_sample_idx_path ........................... None
g0156:   train_samples ................................... 6656000
g0156:   train_shuffle_idx_path .......................... None
g0156:   train_tokens .................................... 13631488000
g0156:   transformer_impl ................................ local
g0156:   transformer_pipeline_model_parallel_size ........ 8
g0156:   universal_checkpoint ............................ False
g0156:   untie_embeddings_and_output_weights ............. True
g0156:   use_checkpoint_args ............................. False
g0156:   use_checkpoint_opt_param_scheduler .............. False
g0156:   use_contiguous_buffers_in_local_ddp ............. True
g0156:   use_cpu_initialization .......................... None
g0156:   use_dataset_only ................................ False
g0156:   use_distributed_optimizer ....................... False
g0156:   use_flash_attn .................................. False
g0156:   use_flash_attn_triton ........................... False
g0156:   use_flash_attn_v1 ............................... False
g0156:   use_flash_attn_v2 ............................... False
g0156:   use_one_sent_docs ............................... False
g0156:   use_pin_memory .................................. False
g0156:   use_ring_exchange_p2p ........................... False
g0156:   use_rotary_position_embeddings .................. True
g0156:   use_tutel ....................................... False
g0156:   use_wandb ....................................... True
g0156:   valid_data_path ................................. None
g0156:   variable_seq_lengths ............................ False
g0156:   virtual_pipeline_model_parallel_size ............ None
g0156:   vision_backbone_type ............................ vit
g0156:   vision_pretraining .............................. False
g0156:   vision_pretraining_type ......................... classify
g0156:   vocab_extra_ids ................................. 0
g0156:   vocab_file ...................................... None
g0156:   vocab_size ...................................... None
g0156:   wandb_entity .................................... yohei-kobashi
g0156:   wandb_group ..................................... pretrain_gpt_1.1B_0.latin_wikipedia_poly_010000_1234_True
g0156:   wandb_project ................................... encrypted_data_LLM
g0156:   wandb_tag ....................................... other_gpu
g0156:   weight_decay .................................... 0.1
g0156:   weight_decay_incr_style ......................... constant
g0156:   world_size ...................................... 32
g0156:   zero_allgather_bucket_size ...................... 0.0
g0156:   zero_contigious_gradients ....................... False
g0156:   zero_reduce_bucket_size ......................... 0.0
g0156:   zero_reduce_scatter ............................. False
g0156:   zero_stage ...................................... 0
g0156: -------------------- end of arguments ---------------------
g0156: setting number of micro-batches to constant 32
g0156: > building SentencePieceTokenizer tokenizer ...
g0156: [2024-08-12 02:21:34,311] [INFO] [comm.py:637:init_distributed] cdb=None
g0156:  > padded vocab (size: 32003) with 125 dummy tokens (new size: 32128)
g0156: > initializing torch distributed ...
g0156: [2024-08-12 02:21:34,313] [INFO] [comm.py:637:init_distributed] cdb=None
g0156: [2024-08-12 02:21:34,313] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
g0156: [2024-08-12 02:21:34,316] [INFO] [comm.py:637:init_distributed] cdb=None
g0156: [2024-08-12 02:21:34,316] [INFO] [comm.py:637:init_distributed] cdb=None
g0156: [W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [2024-08-12 02:21:35,523] [INFO] [launch.py:138:main] 4 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0164: [2024-08-12 02:21:35,523] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0164: [2024-08-12 02:21:35,523] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=4
g0164: [2024-08-12 02:21:35,523] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0164: [2024-08-12 02:21:35,523] [INFO] [launch.py:163:main] dist_world_size=32
g0164: [2024-08-12 02:21:35,523] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0161: [2024-08-12 02:21:35,607] [INFO] [launch.py:138:main] 2 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0161: [2024-08-12 02:21:35,607] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0161: [2024-08-12 02:21:35,607] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=2
g0161: [2024-08-12 02:21:35,607] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0161: [2024-08-12 02:21:35,607] [INFO] [launch.py:163:main] dist_world_size=32
g0161: [2024-08-12 02:21:35,607] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0163: [2024-08-12 02:21:35,708] [INFO] [launch.py:138:main] 3 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0163: [2024-08-12 02:21:35,708] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0163: [2024-08-12 02:21:35,708] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=3
g0163: [2024-08-12 02:21:35,708] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0163: [2024-08-12 02:21:35,708] [INFO] [launch.py:163:main] dist_world_size=32
g0163: [2024-08-12 02:21:35,708] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0159: [2024-08-12 02:21:35,762] [INFO] [launch.py:138:main] 1 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0159: [2024-08-12 02:21:35,762] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0159: [2024-08-12 02:21:35,762] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=1
g0159: [2024-08-12 02:21:35,762] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0159: [2024-08-12 02:21:35,762] [INFO] [launch.py:163:main] dist_world_size=32
g0159: [2024-08-12 02:21:35,762] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0165: [2024-08-12 02:21:35,806] [INFO] [launch.py:138:main] 5 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0165: [2024-08-12 02:21:35,806] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0165: [2024-08-12 02:21:35,806] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=5
g0165: [2024-08-12 02:21:35,806] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0165: [2024-08-12 02:21:35,806] [INFO] [launch.py:163:main] dist_world_size=32
g0165: [2024-08-12 02:21:35,806] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0166: [2024-08-12 02:21:36,577] [INFO] [launch.py:138:main] 6 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0166: [2024-08-12 02:21:36,577] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0166: [2024-08-12 02:21:36,577] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=6
g0166: [2024-08-12 02:21:36,577] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0166: [2024-08-12 02:21:36,577] [INFO] [launch.py:163:main] dist_world_size=32
g0166: [2024-08-12 02:21:36,577] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0167: [2024-08-12 02:21:37,195] [INFO] [launch.py:138:main] 7 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0167: [2024-08-12 02:21:37,195] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0156': [0, 1, 2, 3], 'g0159': [0, 1, 2, 3], 'g0161': [0, 1, 2, 3], 'g0163': [0, 1, 2, 3], 'g0164': [0, 1, 2, 3], 'g0165': [0, 1, 2, 3], 'g0166': [0, 1, 2, 3], 'g0167': [0, 1, 2, 3]}
g0167: [2024-08-12 02:21:37,195] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=7
g0167: [2024-08-12 02:21:37,195] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0156': [0, 1, 2, 3], 'g0159': [4, 5, 6, 7], 'g0161': [8, 9, 10, 11], 'g0163': [12, 13, 14, 15], 'g0164': [16, 17, 18, 19], 'g0165': [20, 21, 22, 23], 'g0166': [24, 25, 26, 27], 'g0167': [28, 29, 30, 31]})
g0167: [2024-08-12 02:21:37,195] [INFO] [launch.py:163:main] dist_world_size=32
g0167: [2024-08-12 02:21:37,195] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0164: [2024-08-12 02:21:38,627] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0164: [2024-08-12 02:21:38,628] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0164: [2024-08-12 02:21:38,653] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0164: [2024-08-12 02:21:38,686] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0161: [2024-08-12 02:21:38,719] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0161: [2024-08-12 02:21:38,719] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0161: [2024-08-12 02:21:38,719] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0163: [2024-08-12 02:21:38,861] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0163: [2024-08-12 02:21:38,862] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0163: [2024-08-12 02:21:38,867] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0165: [2024-08-12 02:21:38,879] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0165: [2024-08-12 02:21:38,879] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0165: [2024-08-12 02:21:38,880] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0161: [2024-08-12 02:21:38,885] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0159: [2024-08-12 02:21:38,906] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0159: [2024-08-12 02:21:38,906] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0159: [2024-08-12 02:21:38,990] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0159: [2024-08-12 02:21:39,003] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0163: [2024-08-12 02:21:39,065] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0165: [2024-08-12 02:21:39,187] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0166: [2024-08-12 02:21:39,656] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0166: [2024-08-12 02:21:39,656] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0166: [2024-08-12 02:21:39,656] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0166: [2024-08-12 02:21:39,828] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0167: [2024-08-12 02:21:40,288] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0167: [2024-08-12 02:21:40,288] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0167: [2024-08-12 02:21:40,342] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0167: [2024-08-12 02:21:40,365] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0165: --------------------------------------------------
g0165: DeepSpeed C++/CUDA extension op report
g0165: --------------------------------------------------
g0165: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0165:       runtime if needed. Op compatibility means that your system
g0165:       meet the required dependencies to JIT install the op.
g0165: --------------------------------------------------
g0165: JIT compiled ops requires ninja
g0165: --------------------------------------------------
g0165: --------------------------------------------------
g0165: DeepSpeed C++/CUDA extension op report
g0165: DeepSpeed C++/CUDA extension op report--------------------------------------------------
g0165: 
g0165: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0165:       runtime if needed. Op compatibility means that your system
g0165:       meet the required dependencies to JIT install the op.--------------------------------------------------
g0165: 
g0165: --------------------------------------------------NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0165:       runtime if needed. Op compatibility means that your system
g0165:       meet the required dependencies to JIT install the op.
g0165: 
g0165: JIT compiled ops requires ninja--------------------------------------------------
g0165: 
g0165: JIT compiled ops requires ninja
g0165: --------------------------------------------------
g0165: DeepSpeed C++/CUDA extension op report
g0165: --------------------------------------------------
g0165: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0165:       runtime if needed. Op compatibility means that your system
g0165:       meet the required dependencies to JIT install the op.
g0165: --------------------------------------------------
g0165: JIT compiled ops requires ninja
g0165: ninjaninjaninja   ......................................................   [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m
g0165: 
g0165: 
g0165: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0165: 
g0165: 
g0165: op nameop nameop name   ................................................   installedinstalledinstalled   ......   compatiblecompatiblecompatible
g0165: 
g0165: 
g0165: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0165: 
g0165: 
g0165: ninja .................. [92m[OKAY][0m
g0165: --------------------------------------------------
g0165: op name ................ installed .. compatible
g0165: --------------------------------------------------
g0161: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0161: 
g0161: 
g0161: DeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op report
g0161: 
g0161: 
g0161: ----------------------------------------------------------------------------------------------------
g0161: --------------------------------------------------
g0161: 
g0161: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0161:       runtime if needed. Op compatibility means that your system
g0161:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0161:       runtime if needed. Op compatibility means that your system
g0161:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0161:       runtime if needed. Op compatibility means that your system
g0161:       meet the required dependencies to JIT install the op.
g0161: 
g0161: 
g0161: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0161: 
g0161: 
g0161: JIT compiled ops requires ninjaJIT compiled ops requires ninjaJIT compiled ops requires ninja
g0161: 
g0161: 
g0161: --------------------------------------------------
g0161: DeepSpeed C++/CUDA extension op report
g0161: --------------------------------------------------
g0161: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0161:       runtime if needed. Op compatibility means that your system
g0161:       meet the required dependencies to JIT install the op.
g0161: --------------------------------------------------
g0161: JIT compiled ops requires ninja
g0161: ninjaninjaninja  ninja.................. ..................  .................. [92m[OKAY][0m.................. [92m[OKAY][0m
g0161:  [92m[OKAY][0m
g0161: [92m[OKAY][0m
g0161: ----------------------------------------------------------------------------------------------------
g0161: 
g0161: 
g0161: ----------------------------------------------------------------------------------------------------op name
g0161: op name
g0161:   ................op name................op name    installed................installed................    ..installed.. installed  compatible ..compatible
g0161: .. 
g0161:  --------------------------------------------------compatiblecompatible--------------------------------------------------
g0161: 
g0161: 
g0161: 
g0161: ----------------------------------------------------------------------------------------------------
g0161: 
g0165: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0165: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0165: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0165: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0165: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0165: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0165: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0165: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0165: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: --------------------------------------------------
g0164: DeepSpeed C++/CUDA extension op report
g0164: --------------------------------------------------
g0164: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0164:       runtime if needed. Op compatibility means that your system
g0164:       meet the required dependencies to JIT install the op.
g0164: --------------------------------------------------
g0164: JIT compiled ops requires ninja
g0164: --------------------------------------------------
g0164: DeepSpeed C++/CUDA extension op report
g0164: --------------------------------------------------
g0164: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0164:       runtime if needed. Op compatibility means that your system
g0164:       meet the required dependencies to JIT install the op.
g0164: --------------------------------------------------
g0164: JIT compiled ops requires ninja
g0164: --------------------------------------------------
g0164: DeepSpeed C++/CUDA extension op report
g0164: --------------------------------------------------
g0164: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0164:       runtime if needed. Op compatibility means that your system
g0164:       meet the required dependencies to JIT install the op.
g0164: --------------------------------------------------
g0164: JIT compiled ops requires ninja
g0164: --------------------------------------------------
g0164: DeepSpeed C++/CUDA extension op report
g0164: --------------------------------------------------
g0164: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0164:       runtime if needed. Op compatibility means that your system
g0164:       meet the required dependencies to JIT install the op.
g0164: --------------------------------------------------
g0164: JIT compiled ops requires ninja
g0164: ninjaninjaninjaninja    ........................................................................    [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m
g0164: 
g0164: 
g0164: 
g0164: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0164: 
g0164: --------------------------------------------------
g0164: op nameop name
g0164: op name   ................................op name................    installedinstalledinstalled ................ .. ..   ..compatiblecompatibleinstalled
g0164:  
g0164:  compatible----------------------------------------------------------------------------------------------------
g0164: 
g0164: ..
g0164: -------------------------------------------------- 
g0164: compatible
g0164: --------------------------------------------------
g0161: async_io ............... async_io[92m[YES][0m  .....................  [92m[OKAY][0m[92m[YES][0m
g0161:  ...... [92m[OKAY][0m
g0161: fused_adam ............. [92m[YES][0m fused_adam......  .............[92m[OKAY][0m 
g0161: [92m[YES][0m ...... cpu_adam[92m[OKAY][0m 
g0161: ............... [92m[YES][0m cpu_adam......  ...............[92m[OKAY][0m 
g0161: [92m[YES][0m ......cpu_adagrad  [92m[OKAY][0m............
g0161:  [92m[YES][0m cpu_adagrad......  ............[92m[OKAY][0m 
g0161: [92m[YES][0m ......cpu_lion  [92m[OKAY][0m...............
g0161:  [92m[YES][0m ......cpu_lion  [92m[OKAY][0m...............
g0161:  [92m[YES][0m ...... [92m[OKAY][0m
g0161: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0161: evoformer_attn ......... [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[93m[NO][0m
g0161:  .......evoformer_attn  [93m[NO][0m.........
g0161:  [93m[NO][0m fused_lamb.......  .............[93m[NO][0m 
g0161: [92m[YES][0m ......fused_lamb  [92m[OKAY][0m.............
g0161:  [92m[YES][0m ...... [92m[OKAY][0m
g0161: fused_lion ............. [92m[YES][0m fused_lion......  .............[92m[OKAY][0m 
g0161: [92m[YES][0m ...... [92m[OKAY][0m
g0161: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0161: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0161: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0161: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0161: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0161: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0161: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0161: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0161: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0161: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0161: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0165: inference_core_opsinference_core_ops  ..........  [92m[YES][0m [92m[YES][0m......  ......[92m[OKAY][0m 
g0165: [92m[OKAY][0m
g0165: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0165: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: quantizer .............. cutlass_ops[92m[YES][0m  ..................  [92m[YES][0m[92m[OKAY][0m 
g0165: ...... [92m[OKAY][0m
g0165: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0161: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0minference_core_ops
g0161:  ..... [92m[YES][0m ...... [92m[OKAY][0m
g0161: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0165: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0165: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0165: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0165: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0165: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0165: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0165: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0random_ltd
g0165:  ............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0165: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0165: 
g0165: sparse_attnsparse_attn  ........................  [93m[NO][0m[93m[NO][0m  ..............  [93m[NO][0m[93m[NO][0m
g0165: 
g0161: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: cutlass_ops ............cutlass_ops  [92m[YES][0m............  ......[92m[YES][0m  [92m[OKAY][0m......
g0161:  [92m[OKAY][0m
g0161: quantizer ..............quantizer  [92m[YES][0m..............  ......[92m[YES][0m  [92m[OKAY][0m......
g0161:  [92m[OKAY][0m
g0161: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0165: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0165: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0161: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0165: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0165: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0165: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0165: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0165: --------------------------------------------------
g0165: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0165: --------------------------------------------------
g0161: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0161: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0161: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0161: ragged_ops ............. [92m[YES][0m ...... ragged_ops[92m[OKAY][0m 
g0161: ............. [92m[YES][0mrandom_ltd  ...................  [92m[OKAY][0m[92m[YES][0m
g0161:  ...... [92m[OKAY][0mrandom_ltd
g0161:  ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0161: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0161: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0161: 
g0161: sparse_attnsparse_attn  ........................  [93m[NO][0m[93m[NO][0m  ..............  [93m[NO][0m[93m[NO][0m
g0161: 
g0161: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0161: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0161: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0161: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0165: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0165: --------------------------------------------------
g0165: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0165: --------------------------------------------------
g0165: DeepSpeed general environment info:
g0165: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0165: torch version .................... 2.0.1+cu118
g0165: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0165: deepspeed info ................... 0.12.4, unknown, unknown
g0165: torch cuda version ............... 11.8
g0165: torch hip version ................ None
g0165: nvcc version ..................... 11.8
g0165: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0165: shared memory (/dev/shm) size .... 188.13 GB
g0165: DeepSpeed general environment info:
g0165: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0165: torch version .................... 2.0.1+cu118
g0165: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0165: deepspeed info ................... 0.12.4, unknown, unknown
g0165: torch cuda version ............... 11.8
g0165: torch hip version ................ None
g0165: nvcc version ..................... 11.8
g0165: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0165: shared memory (/dev/shm) size .... 188.13 GB
g0161: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0161: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0161: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0161: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0161: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0161: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0165: DeepSpeed general environment info:
g0165: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0165: torch version .................... 2.0.1+cu118
g0165: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0165: deepspeed info ................... 0.12.4, unknown, unknown
g0165: torch cuda version ............... 11.8
g0165: torch hip version ................ None
g0165: nvcc version ..................... 11.8
g0165: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0165: shared memory (/dev/shm) size .... 188.13 GB
g0165: DeepSpeed general environment info:
g0165: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0165: torch version .................... 2.0.1+cu118
g0165: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0165: deepspeed info ................... 0.12.4, unknown, unknown
g0165: torch cuda version ............... 11.8
g0165: torch hip version ................ None
g0165: nvcc version ..................... 11.8
g0165: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0165: shared memory (/dev/shm) size .... 188.13 GB
g0161: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0161: --------------------------------------------------
g0161: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0161: --------------------------------------------------
g0161: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0161: --------------------------------------------------
g0161: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0161: --------------------------------------------------
g0161: DeepSpeed general environment info:
g0161: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0161: torch version .................... 2.0.1+cu118
g0161: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0161: deepspeed info ................... 0.12.4, unknown, unknown
g0161: torch cuda version ............... 11.8
g0161: torch hip version ................ None
g0161: nvcc version ..................... 11.8
g0161: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0161: shared memory (/dev/shm) size .... 188.13 GB
g0161: DeepSpeed general environment info:
g0161: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0161: torch version .................... 2.0.1+cu118
g0161: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0161: deepspeed info ................... 0.12.4, unknown, unknown
g0161: torch cuda versionDeepSpeed general environment info: 
g0161: ............... 11.8torch install path
g0161:  ...............torch hip version  ................ ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']None
g0161: 
g0161: torch versionnvcc version  .................... .....................2.0.1+cu118 
g0161: 11.8
g0161: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']deepspeed wheel compiled w.
g0161:  deepspeed info......  ...................torch 2.0, cuda 11.8 
g0161: 0.12.4, unknown, unknown
g0161: shared memory (/dev/shm) sizetorch cuda version  ...................  188.13 GB11.8
g0161: 
g0161: torch hip version ................ None
g0161: nvcc version ..................... 11.8
g0161: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0161: shared memory (/dev/shm) size .... 188.13 GB
g0161: DeepSpeed general environment info:
g0161: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0161: torch version .................... 2.0.1+cu118
g0161: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0161: deepspeed info ................... 0.12.4, unknown, unknown
g0161: torch cuda version ............... 11.8
g0161: torch hip version ................ None
g0161: nvcc version ..................... 11.8
g0161: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0161: shared memory (/dev/shm) size .... 188.13 GB
g0163: --------------------------------------------------
g0163: DeepSpeed C++/CUDA extension op report
g0163: ----------------------------------------------------------------------------------------------------
g0163: 
g0163: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0163:       runtime if needed. Op compatibility means that your system
g0163:       meet the required dependencies to JIT install the op.
g0163: DeepSpeed C++/CUDA extension op report
g0163: --------------------------------------------------
g0163: --------------------------------------------------JIT compiled ops requires ninja
g0163: 
g0163: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0163:       runtime if needed. Op compatibility means that your system
g0163:       meet the required dependencies to JIT install the op.
g0163: --------------------------------------------------
g0163: JIT compiled ops requires ninja
g0163: --------------------------------------------------
g0163: DeepSpeed C++/CUDA extension op report
g0163: --------------------------------------------------
g0163: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0163:       runtime if needed. Op compatibility means that your system
g0163:       meet the required dependencies to JIT install the op.
g0163: --------------------------------------------------
g0163: JIT compiled ops requires ninja
g0163: --------------------------------------------------
g0163: DeepSpeed C++/CUDA extension op report
g0163: --------------------------------------------------
g0163: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0163:       runtime if needed. Op compatibility means that your system
g0163:       meet the required dependencies to JIT install the op.
g0163: --------------------------------------------------
g0163: JIT compiled ops requires ninja
g0163: ninjaninjaninja  ninja....................................    ..................[92m[OKAY][0m..................[92m[OKAY][0m 
g0163:  
g0163: [92m[OKAY][0m[92m[OKAY][0m--------------------------------------------------
g0163: --------------------------------------------------
g0163: 
g0163: 
g0163: ----------------------------------------------------------------------------------------------------op nameop name
g0163: 
g0163:   ................op name................op name    installed................installed................    ..installed..installed    compatible..compatible.. 
g0163: 
g0163:  compatiblecompatible
g0163: ----------------------------------------------------------------------------------------------------
g0163: 
g0163: --------------------------------------------------
g0163: 
g0163: --------------------------------------------------
g0165: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0165: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0165: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0165: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0161: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0161: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0161: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0161: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0159: --------------------------------------------------
g0159: DeepSpeed C++/CUDA extension op report
g0159: --------------------------------------------------
g0159: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0159:       runtime if needed. Op compatibility means that your system
g0159:       meet the required dependencies to JIT install the op.
g0159: --------------------------------------------------
g0159: JIT compiled ops requires ninja
g0159: --------------------------------------------------
g0159: DeepSpeed C++/CUDA extension op report
g0159: --------------------------------------------------
g0159: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0159:       runtime if needed. Op compatibility means that your system
g0159:       meet the required dependencies to JIT install the op.
g0159: --------------------------------------------------
g0159: JIT compiled ops requires ninja
g0159: --------------------------------------------------
g0159: DeepSpeed C++/CUDA extension op report
g0159: --------------------------------------------------
g0159: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0159:       runtime if needed. Op compatibility means that your system
g0159:       meet the required dependencies to JIT install the op.
g0159: --------------------------------------------------
g0159: JIT compiled ops requires ninja
g0159: --------------------------------------------------
g0159: DeepSpeed C++/CUDA extension op report
g0159: --------------------------------------------------
g0159: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0159:       runtime if needed. Op compatibility means that your system
g0159:       meet the required dependencies to JIT install the op.
g0159: --------------------------------------------------
g0159: JIT compiled ops requires ninja
g0159: ninjaninja  ....................................  [92m[OKAY][0m[92m[OKAY][0m
g0159: 
g0159: ninja----------------------------------------------------------------------------------------------------
g0159: 
g0159:  op nameop name..................   ................................[92m[OKAY][0m  installed
g0159: installed  .... -------------------------------------------------- compatible
g0159: compatible
g0159: 
g0159: --------------------------------------------------op name--------------------------------------------------
g0159:  
g0159: ................ installed .. compatible
g0159: --------------------------------------------------
g0159: ninja .................. [92m[OKAY][0m
g0159: --------------------------------------------------
g0159: op name ................ installed .. compatible
g0159: --------------------------------------------------
g0163: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0163: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0163: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0163: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0163: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0163: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0163: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0163: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0163: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0163: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0163: fused_lamb ............. async_io[92m[YES][0m  .....................  [92m[OKAY][0m[92m[YES][0m
g0163:  ...... [92m[OKAY][0m
g0163: fused_lion .............fused_adam  [92m[YES][0m.............  ......[92m[YES][0m  [92m[OKAY][0m......
g0163:  [92m[OKAY][0m
g0163: cpu_adam async_io...............  [92m[YES][0m...............  ......[92m[YES][0m  [92m[OKAY][0m......
g0163:  [92m[OKAY][0mcpu_adagrad
g0163:  ............ [92m[YES][0m ...... fused_adam[92m[OKAY][0m 
g0163: ............. [92m[YES][0m cpu_lion......  ...............[92m[OKAY][0m 
g0163: [92m[YES][0m ...... cpu_adam[92m[OKAY][0m 
g0163: ............... [92m[YES][0m ...... [92m[OKAY][0m
g0163: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0163: cpu_adagrad evoformer_attn............  .........[92m[YES][0m  [93m[NO][0m......  .......[92m[OKAY][0m 
g0163: [93m[NO][0m
g0163: cpu_lion ...............fused_lamb  [92m[YES][0m.............  ......[92m[YES][0m  [92m[OKAY][0m......
g0163:  [92m[OKAY][0m
g0163: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0163: fused_lionevoformer_attn  ......................  [92m[YES][0m[93m[NO][0m  .............  [92m[OKAY][0m[93m[NO][0m
g0163: 
g0163: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0163: inference_core_ops ..... inference_core_ops[92m[YES][0m  ...........  [92m[OKAY][0m[92m[YES][0m
g0163:  ...... [92m[OKAY][0m
g0163: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0163: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: quantizer ..............cutlass_ops [92m[YES][0m  ..................  [92m[YES][0m[92m[OKAY][0m 
g0163: ...... [92m[OKAY][0m
g0163: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0163: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0163: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0163: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0163: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0163: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0163: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0163: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: random_ltd ............. [92m[YES][0m ...... [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible[92m[OKAY][0m
g0163: 
g0163: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0163: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0163: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0163: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0163: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0163: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0163: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0163: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0163: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0163: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0163: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0163: --------------------------------------------------
g0163: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0163: --------------------------------------------------
g0163: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0163: transformer_inference-------------------------------------------------- 
g0163: .. [92m[YES][0m ...... [92m[OKAY][0m
g0163: --------------------------------------------------
g0163: DeepSpeed general environment info:
g0163: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0163: torch version .................... 2.0.1+cu118
g0163: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0163: deepspeed info ................... 0.12.4, unknown, unknown
g0163: torch cuda version ............... 11.8
g0163: torch hip version ................ None
g0163: nvcc version ..................... 11.8
g0163: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0163: shared memory (/dev/shm) size .... 188.13 GB
g0163: DeepSpeed general environment info:
g0163: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0163: torch version .................... 2.0.1+cu118
g0163: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0163: deepspeed info ................... 0.12.4, unknown, unknown
g0163: torch cuda version ............... 11.8
g0163: torch hip version ................ None
g0163: nvcc version ..................... 11.8
g0163: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0163: shared memory (/dev/shm) size .... 188.13 GB
g0163: DeepSpeed general environment info:
g0163: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0163: torch version .................... 2.0.1+cu118
g0163: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0163: deepspeed info ................... 0.12.4, unknown, unknown
g0163: torch cuda version ............... 11.8
g0163: torch hip version ................ None
g0163: nvcc version ..................... 11.8
g0163: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0163: shared memory (/dev/shm) size .... 188.13 GB
g0163: DeepSpeed general environment info:
g0163: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0163: torch version .................... 2.0.1+cu118
g0163: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0163: deepspeed info ................... 0.12.4, unknown, unknown
g0163: torch cuda version ............... 11.8
g0163: torch hip version ................ None
g0163: nvcc version ..................... 11.8
g0163: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0163: shared memory (/dev/shm) size .... 188.13 GB
g0165: [2024-08-12 02:21:43,307] [INFO] [comm.py:637:init_distributed] cdb=None
g0165: [2024-08-12 02:21:43,311] [INFO] [comm.py:637:init_distributed] cdb=None
g0165: [2024-08-12 02:21:43,311] [INFO] [comm.py:637:init_distributed] cdb=None
g0165: [2024-08-12 02:21:43,312] [INFO] [comm.py:637:init_distributed] cdb=None
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [2024-08-12 02:21:43,313] [INFO] [comm.py:637:init_distributed] cdb=None
g0161: [2024-08-12 02:21:43,313] [INFO] [comm.py:637:init_distributed] cdb=None
g0161: [2024-08-12 02:21:43,314] [INFO] [comm.py:637:init_distributed] cdb=None
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [2024-08-12 02:21:43,314] [INFO] [comm.py:637:init_distributed] cdb=None
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0165: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0161: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0164: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0164: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0164: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0164: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0164: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0164: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: cpu_adam ............... [92m[YES][0m ...... async_io[92m[OKAY][0m
g0164:  ............... cpu_adagrad[92m[YES][0m  ..................  [92m[YES][0m[92m[OKAY][0m ......
g0164:  [92m[OKAY][0m
g0164: fused_adamcpu_lion  ............................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0164: 
g0164: cpu_adam ............... [92m[YES][0m async_io......  [92m[OKAY][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0164: ...............
g0164:  [92m[YES][0mevoformer_attn cpu_adagrad ...... ......... ............ [92m[OKAY][0m [93m[NO][0m
g0164: [92m[YES][0m  .............  [93m[NO][0m[92m[OKAY][0m
g0164: 
g0164: fused_adam .............cpu_lionfused_lamb   [92m[YES][0m............................   ......[92m[YES][0m[92m[YES][0m   [92m[OKAY][0m............
g0164:   [92m[OKAY][0m[92m[OKAY][0m
g0164: 
g0164: cpu_adam ............... [92m[YES][0m ...... [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[OKAY][0m
g0164: 
g0164: fused_lion evoformer_attn............. cpu_adagrad ......... [92m[YES][0m ............ [93m[NO][0m ...... [92m[YES][0m ....... [92m[OKAY][0m ......
g0164: [93m[NO][0m 
g0164: [92m[OKAY][0m
g0164: fused_lamb cpu_lion.............  ...............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0164: [92m[OKAY][0m
g0164: fused_lion .............[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0164: [92m[YES][0m evoformer_attn......  .........[92m[OKAY][0m 
g0164: [93m[NO][0m ....... [93m[NO][0m
g0164: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0159: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0159: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0159: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0159: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0159: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0159: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0159: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: async_iocpu_lion  ..............................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0159: 
g0159: fused_adam[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0159: ............. [92m[YES][0mevoformer_attn  ...............  [92m[OKAY][0m[93m[NO][0m
g0159:  ....... [93m[NO][0m
g0159: cpu_adam ...............fused_lamb  [92m[YES][0m.............  ......[92m[YES][0m  [92m[OKAY][0m......
g0159:  [92m[OKAY][0m
g0159: cpu_adagrad ............ [92m[YES][0m ......async_io [92m[OKAY][0mfused_lion 
g0159:  ............................ cpu_lion[92m[YES][0m   [92m[YES][0m.....................   ......[92m[YES][0m[92m[OKAY][0m 
g0159:  [92m[OKAY][0m...... 
g0159: [92m[OKAY][0m
g0159: fused_adam [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH.............
g0159:  [92m[YES][0mevoformer_attn  ...............  [93m[NO][0m[92m[OKAY][0m .......
g0159:  [93m[NO][0m
g0159: cpu_adamfused_lamb  ............................  [92m[YES][0m[92m[YES][0m  ...... ......[92m[OKAY][0m 
g0159: [92m[OKAY][0m
g0159: cpu_adagrad fused_lion............  .............[92m[YES][0m [92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0159: 
g0159: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0159: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0159: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0159: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0163: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0163: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0163: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0163: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0164: inference_core_opsinference_core_ops  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0164: 
g0164: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0164: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0164: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0164: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0164: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0164: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0164: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0164: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0164: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatiblesparse_attn
g0164:  ............sparse_attn  ............ [93m[NO][0m[93m[NO][0m  ....... [93m[NO][0m
g0164: ....... [93m[NO][0m
g0164: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0164: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0164: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0159: inference_core_opsinference_core_ops  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0159: 
g0159: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0159: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0164: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0164: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0164: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0164: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0164: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0159: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: cutlass_opsquantizer  .......................... [92m[YES][0m  [92m[YES][0m......  [92m[OKAY][0m......
g0159:  [92m[OKAY][0m
g0159: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0164: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0164: --------------------------------------------------
g0164: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0164: --------------------------------------------------
g0164: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0164: --------------------------------------------------
g0164: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0164: --------------------------------------------------
g0159: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0159: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0159: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0159: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0164: DeepSpeed general environment info:
g0164: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0164: torch version .................... 2.0.1+cu118
g0164: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0164: deepspeed info ................... 0.12.4, unknown, unknown
g0164: torch cuda version ............... 11.8
g0164: torch hip version ................ None
g0164: nvcc version ..................... 11.8
g0164: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0164: shared memory (/dev/shm) size .... 188.13 GB
g0164: DeepSpeed general environment info:
g0164: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0164: torch version .................... 2.0.1+cu118
g0164: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0164: deepspeed info ................... 0.12.4, unknown, unknown
g0164: torch cuda version ............... 11.8
g0164: torch hip version ................ None
g0164: nvcc version ..................... 11.8
g0164: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0164: shared memory (/dev/shm) size .... 188.13 GB
g0164: DeepSpeed general environment info:
g0164: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0164: torch version .................... 2.0.1+cu118
g0164: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0164: deepspeed info ................... 0.12.4, unknown, unknown
g0164: torch cuda version ............... 11.8
g0164: torch hip version ................ None
g0164: nvcc version ..................... 11.8
g0164: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0164: shared memory (/dev/shm) size .... 188.13 GB
g0164: DeepSpeed general environment info:
g0164: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0164: torch version .................... 2.0.1+cu118
g0164: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0164: deepspeed info ................... 0.12.4, unknown, unknown
g0164: torch cuda version ............... 11.8
g0164: torch hip version ................ None
g0164: nvcc version ..................... 11.8
g0164: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0164: shared memory (/dev/shm) size .... 188.13 GB
g0159: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0159: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0159: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0159: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0159: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0159: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0159: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0159: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0159: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0159: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0159: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0159: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0159: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0159: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0159: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0159: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0159: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0159: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0159: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0159: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0159: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0159: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0159: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0159: --------------------------------------------------
g0159: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0159: --------------------------------------------------
g0159: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0159: --------------------------------------------------
g0159: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0159: --------------------------------------------------
g0159: DeepSpeed general environment info:
g0159: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0159: torch version .................... 2.0.1+cu118
g0159: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0159: deepspeed info ................... 0.12.4, unknown, unknown
g0159: torch cuda version ............... 11.8
g0159: torch hip version ................ None
g0159: nvcc version ..................... 11.8
g0159: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0159: shared memory (/dev/shm) size .... 188.13 GB
g0159: DeepSpeed general environment info:
g0159: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0159: torch version .................... 2.0.1+cu118
g0159: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0159: deepspeed info ................... 0.12.4, unknown, unknown
g0159: torch cuda version ............... 11.8
g0159: torch hip version ................ None
g0159: nvcc version ..................... 11.8
g0159: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0159: shared memory (/dev/shm) size .... 188.13 GB
g0159: DeepSpeed general environment info:
g0159: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0159: torch version .................... 2.0.1+cu118
g0159: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0159: deepspeed info ................... 0.12.4, unknown, unknown
g0159: torch cuda version ............... 11.8
g0159: torch hip version ................ None
g0159: nvcc version ..................... 11.8
g0159: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0159: shared memory (/dev/shm) size .... 188.13 GB
g0159: DeepSpeed general environment info:
g0159: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0159: torch version .................... 2.0.1+cu118
g0159: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0159: deepspeed info ................... 0.12.4, unknown, unknown
g0159: torch cuda version ............... 11.8
g0159: torch hip version ................ None
g0159: nvcc version ..................... 11.8
g0159: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0159: shared memory (/dev/shm) size .... 188.13 GB
g0164: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0164: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0164: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0164: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0159: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0159: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0159: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0159: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0163: [2024-08-12 02:21:43,433] [INFO] [comm.py:637:init_distributed] cdb=None
g0163: [2024-08-12 02:21:43,434] [INFO] [comm.py:637:init_distributed] cdb=None
g0163: [2024-08-12 02:21:43,434] [INFO] [comm.py:637:init_distributed] cdb=None
g0163: [2024-08-12 02:21:43,434] [INFO] [comm.py:637:init_distributed] cdb=None
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0163: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [2024-08-12 02:21:43,504] [INFO] [comm.py:637:init_distributed] cdb=None
g0164: [2024-08-12 02:21:43,504] [INFO] [comm.py:637:init_distributed] cdb=None
g0164: [2024-08-12 02:21:43,505] [INFO] [comm.py:637:init_distributed] cdb=None
g0164: [2024-08-12 02:21:43,506] [INFO] [comm.py:637:init_distributed] cdb=None
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0164: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [2024-08-12 02:21:43,515] [INFO] [comm.py:637:init_distributed] cdb=None
g0159: [2024-08-12 02:21:43,516] [INFO] [comm.py:637:init_distributed] cdb=None
g0159: [2024-08-12 02:21:43,516] [INFO] [comm.py:637:init_distributed] cdb=None
g0159: [2024-08-12 02:21:43,521] [INFO] [comm.py:637:init_distributed] cdb=None
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0159: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: ----------------------------------------------------------------------------------------------------
g0166: 
g0166: DeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op report
g0166: 
g0166: ----------------------------------------------------------------------------------------------------
g0166: 
g0166: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0166:       runtime if needed. Op compatibility means that your system
g0166:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0166:       runtime if needed. Op compatibility means that your system
g0166:       meet the required dependencies to JIT install the op.
g0166: 
g0166: ----------------------------------------------------------------------------------------------------
g0166: 
g0166: JIT compiled ops requires ninjaJIT compiled ops requires ninja
g0166: 
g0166: --------------------------------------------------
g0166: DeepSpeed C++/CUDA extension op report
g0166: --------------------------------------------------
g0166: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0166:       runtime if needed. Op compatibility means that your system
g0166:       meet the required dependencies to JIT install the op.
g0166: --------------------------------------------------
g0166: JIT compiled ops requires ninja
g0166: --------------------------------------------------
g0166: DeepSpeed C++/CUDA extension op report
g0166: --------------------------------------------------
g0166: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0166:       runtime if needed. Op compatibility means that your system
g0166:       meet the required dependencies to JIT install the op.
g0166: --------------------------------------------------
g0166: JIT compiled ops requires ninja
g0166: ninjaninjaninja   ..................ninja....................................    [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m..................
g0166: 
g0166: 
g0166:  [92m[OKAY][0m------------------------------------------------------------------------------------------------------------------------------------------------------
g0166: 
g0166: 
g0166: 
g0166: op name--------------------------------------------------op nameop name 
g0166:   ................................................ op name  installed installedinstalled ................  .. .... installed  compatible compatiblecompatible
g0166: ..
g0166: 
g0166:  ----------------------------------------------------------------------------------------------------compatible
g0166: --------------------------------------------------
g0166: 
g0166: 
g0166: --------------------------------------------------
g0166: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0166: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: cpu_adam async_io...............  [92m[YES][0m...............  ......[92m[YES][0m [92m[OKAY][0m 
g0166: ...... [92m[OKAY][0mcpu_adagrad
g0166:  ............async_io [92m[YES][0m  .....................fused_adam   [92m[OKAY][0m[92m[YES][0m.............
g0166:   ......[92m[YES][0m  cpu_lion[92m[OKAY][0m......  
g0166: ...............[92m[OKAY][0m 
g0166: [92m[YES][0m ...... [92m[OKAY][0mcpu_adam
g0166:  fused_adam...............  .............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0166: [92m[OKAY][0m
g0166: 
g0166: cpu_adagradevoformer_attn  .....................cpu_adam   [92m[YES][0m[93m[NO][0m...............   .............  [92m[YES][0m[92m[OKAY][0m[93m[NO][0m 
g0166: 
g0166: ...... [92m[OKAY][0mcpu_lion
g0166: fused_lamb  ............................  cpu_adagrad[92m[YES][0m[92m[YES][0m   ........................   [92m[YES][0m[92m[OKAY][0m[92m[OKAY][0m 
g0166: 
g0166: ...... [92m[OKAY][0m
g0166: async_iocpu_lion  [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH...............fused_lion............... 
g0166:  [92m[YES][0m ............. evoformer_attn[92m[YES][0m......    [92m[YES][0m...............[92m[OKAY][0m   
g0166: ......[93m[NO][0m[92m[OKAY][0m  
g0166: [92m[OKAY][0m.......
g0166:  [93m[NO][0m
g0166: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATHfused_lambfused_adam 
g0166:  .......................... evoformer_attn [92m[YES][0m [92m[YES][0m ......... ...... ...... [93m[NO][0m [92m[OKAY][0m [92m[OKAY][0m
g0166: 
g0166: ....... [93m[NO][0m
g0166: cpu_adam ............... fused_lamb[92m[YES][0m  fused_lion...................   .............[92m[YES][0m[92m[OKAY][0m  
g0166: [92m[YES][0m......  ......cpu_adagrad [92m[OKAY][0m [92m[OKAY][0m
g0166: ............
g0166:  [92m[YES][0m ...... [92m[OKAY][0m
g0166: fused_lion cpu_lion.............  ...............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0166: [92m[OKAY][0m
g0166: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0166: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0166: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0166: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0166: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0166: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0166: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0166: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0166: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0166: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0166: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0166: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0166: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0166: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0166: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0166: sparse_attn [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0............
g0166:  [93m[NO][0m ....... [93m[NO][0m
g0166: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0166: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0166: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0166: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0166: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0166: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0166: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0166: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0166: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0166: --------------------------------------------------
g0166: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0166: --------------------------------------------------
g0166: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0166: --------------------------------------------------
g0166: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0166: --------------------------------------------------
g0166: DeepSpeed general environment info:
g0166: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0166: torch version .................... 2.0.1+cu118
g0166: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0166: deepspeed info ................... 0.12.4, unknown, unknown
g0166: torch cuda version ............... 11.8
g0166: torch hip version ................ None
g0166: nvcc version ..................... 11.8
g0166: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0166: shared memory (/dev/shm) size .... 188.13 GB
g0166: DeepSpeed general environment info:
g0166: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0166: torch version .................... 2.0.1+cu118
g0166: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0166: deepspeed info ................... 0.12.4, unknown, unknown
g0166: torch cuda version ............... 11.8
g0166: torch hip version ................DeepSpeed general environment info: 
g0166: None
g0166: nvcc versiontorch install path  ....................................  11.8
g0166: ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0166: deepspeed wheel compiled w. torch version......  ....................torch 2.0, cuda 11.8 
g0166: 2.0.1+cu118shared memory (/dev/shm) size
g0166:  deepspeed install path....  ...........188.13 GB 
g0166: ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0166: deepspeed info ................... 0.12.4, unknown, unknown
g0166: torch cuda version ............... 11.8
g0166: torch hip version ................ None
g0166: nvcc version ..................... 11.8
g0166: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0166: shared memory (/dev/shm) size .... 188.13 GB
g0166: DeepSpeed general environment info:
g0166: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0166: torch version .................... 2.0.1+cu118
g0166: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0166: deepspeed info ................... 0.12.4, unknown, unknown
g0166: torch cuda version ............... 11.8
g0166: torch hip version ................ None
g0166: nvcc version ..................... 11.8
g0166: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0166: shared memory (/dev/shm) size .... 188.13 GB
g0166: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0166: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0166: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0166: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0166: [2024-08-12 02:21:44,360] [INFO] [comm.py:637:init_distributed] cdb=None
g0166: [2024-08-12 02:21:44,361] [INFO] [comm.py:637:init_distributed] cdb=None
g0166: [2024-08-12 02:21:44,361] [INFO] [comm.py:637:init_distributed] cdb=None
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: [2024-08-12 02:21:44,371] [INFO] [comm.py:637:init_distributed] cdb=None
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0166: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: --------------------------------------------------
g0167: DeepSpeed C++/CUDA extension op report
g0167: --------------------------------------------------
g0167: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0167:       runtime if needed. Op compatibility means that your system
g0167:       meet the required dependencies to JIT install the op.
g0167: --------------------------------------------------
g0167: JIT compiled ops requires ninja
g0167: --------------------------------------------------
g0167: DeepSpeed C++/CUDA extension op report
g0167: --------------------------------------------------
g0167: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0167:       runtime if needed. Op compatibility means that your system
g0167:       meet the required dependencies to JIT install the op.
g0167: --------------------------------------------------
g0167: JIT compiled ops requires ninja
g0167: --------------------------------------------------
g0167: DeepSpeed C++/CUDA extension op report
g0167: --------------------------------------------------
g0167: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0167:       runtime if needed. Op compatibility means that your system
g0167:       meet the required dependencies to JIT install the op.
g0167: --------------------------------------------------
g0167: JIT compiled ops requires ninja
g0167: --------------------------------------------------
g0167: DeepSpeed C++/CUDA extension op report
g0167: --------------------------------------------------
g0167: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0167:       runtime if needed. Op compatibility means that your system
g0167:       meet the required dependencies to JIT install the op.
g0167: --------------------------------------------------
g0167: JIT compiled ops requires ninja
g0167: ninjaninjaninja  ninja....................................   ..................[92m[OKAY][0m .................. 
g0167: [92m[OKAY][0m[92m[OKAY][0m 
g0167: --------------------------------------------------
g0167: [92m[OKAY][0m
g0167: --------------------------------------------------
g0167: --------------------------------------------------op name
g0167: 
g0167:  --------------------------------------------------op name................
g0167: op name   ................installedop name ................ installed  .. ................installed ..  compatible installed..
g0167: compatible  --------------------------------------------------
g0167: ..compatible
g0167:  
g0167: --------------------------------------------------compatible
g0167: --------------------------------------------------
g0167: 
g0167: --------------------------------------------------
g0167: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0167: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0167: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0167: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0167: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0167: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: fused_lion ............. [92m[YES][0m ...... async_io[92m[OKAY][0m
g0167:  ............... [92m[YES][0m ...... [92m[OKAY][0m
g0167: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0masync_io
g0167:  ...............cpu_adam  [92m[YES][0m...............  ......[92m[YES][0m  [92m[OKAY][0m......
g0167:  [92m[OKAY][0m
g0167: cpu_adagrad fused_adam............  .............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0167: [92m[OKAY][0m
g0167: cpu_lionasync_io cpu_adam...............   ..............................[92m[YES][0m   [92m[YES][0m[92m[YES][0m......   ............[92m[OKAY][0m  
g0167: [92m[OKAY][0m[92m[OKAY][0m
g0167: 
g0167: cpu_adagrad ............ [92m[YES][0mfused_adam  ...................  [92m[OKAY][0m[92m[YES][0m
g0167:  ...... cpu_lion[92m[OKAY][0m 
g0167: ............... [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[YES][0mcpu_adam
g0167:   .....................evoformer_attn   [92m[YES][0m[92m[OKAY][0m......... 
g0167:  ......[93m[NO][0m  [92m[OKAY][0m.......
g0167:  [93m[NO][0m
g0167: cpu_adagrad [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATHfused_lamb............
g0167:   .............[92m[YES][0mevoformer_attn   [92m[YES][0m...............   ......[92m[OKAY][0m[93m[NO][0m 
g0167:  [92m[OKAY][0m.......
g0167:  cpu_lion[93m[NO][0m 
g0167: ............... [92m[YES][0m fused_lamb......  .............[92m[OKAY][0mfused_lion 
g0167:  [92m[YES][0m.............  ......[92m[YES][0m  [92m[OKAY][0m......
g0167:  [92m[OKAY][0m
g0167: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0167: evoformer_attn .........fused_lion  [93m[NO][0m.............  .......[92m[YES][0m  [93m[NO][0m......
g0167:  [92m[OKAY][0m
g0167: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0167: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0167: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0167: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0167: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0167: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0167: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0167: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0167: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0167: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0167: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatiblerandom_ltd
g0167:  ............. sparse_attn[92m[YES][0m  ..................  [93m[NO][0m[92m[OKAY][0m 
g0167: ....... [93m[NO][0m
g0167: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0167: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0167: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0167: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0167: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0167: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0167: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0167: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0167: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0167: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0167: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0167: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0167: --------------------------------------------------
g0167: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0167: --------------------------------------------------
g0167: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0167: --------------------------------------------------
g0167: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0167: --------------------------------------------------
g0167: DeepSpeed general environment info:
g0167: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0167: torch version .................... 2.0.1+cu118
g0167: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0167: deepspeed info ................... 0.12.4, unknown, unknown
g0167: torch cuda version ............... 11.8
g0167: torch hip version ................ None
g0167: nvcc version ..................... 11.8
g0167: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0167: shared memory (/dev/shm) size .... 188.13 GB
g0167: DeepSpeed general environment info:
g0167: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0167: torch version .................... 2.0.1+cu118
g0167: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0167: deepspeed info ................... 0.12.4, unknown, unknown
g0167: torch cuda version ............... 11.8
g0167: torch hip version ................ None
g0167: nvcc version ..................... 11.8
g0167: DeepSpeed general environment info:deepspeed wheel compiled w. 
g0167: ...... torch 2.0, cuda 11.8torch install path
g0167:  shared memory (/dev/shm) size...............  .... 188.13 GB
g0167: ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0167: torch version .................... 2.0.1+cu118
g0167: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0167: deepspeed info ................... 0.12.4, unknown, unknown
g0167: torch cuda version ............... 11.8
g0167: torch hip version ................ None
g0167: nvcc version ..................... 11.8
g0167: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0167: shared memory (/dev/shm) size .... 188.13 GB
g0167: DeepSpeed general environment info:
g0167: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0167: torch version .................... 2.0.1+cu118
g0167: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0167: deepspeed info ................... 0.12.4, unknown, unknown
g0167: torch cuda version ............... 11.8
g0167: torch hip version ................ None
g0167: nvcc version ..................... 11.8
g0167: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0167: shared memory (/dev/shm) size .... 188.13 GB
g0167: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0167: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0167: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0167: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0167: [2024-08-12 02:21:44,871] [INFO] [comm.py:637:init_distributed] cdb=None
g0167: [2024-08-12 02:21:44,871] [INFO] [comm.py:637:init_distributed] cdb=None
g0167: [2024-08-12 02:21:44,875] [INFO] [comm.py:637:init_distributed] cdb=None
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: > setting tensorboard ...
g0167: [2024-08-12 02:21:45,278] [INFO] [comm.py:637:init_distributed] cdb=None
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0167: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0156-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0156: > initialized tensor model parallel with size 1
g0156: > initialized pipeline model parallel with size 8
g0156: > setting random seeds to 1234 ...
g0156: > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
g0156: > compiling dataset index builder ...
g0156: make: Entering directory '/home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/data'
g0156: make: Nothing to be done for 'default'.
g0156: make: Leaving directory '/home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/data'
g0156: >>> done with dataset index builder. Compilation time: 0.082 seconds
g0156: WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
g0156: > compiling and loading fused kernels ...
g0156: Detected CUDA files, patching ldflags
g0156: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0156: Building extension module scaled_upper_triang_masked_softmax_cuda...
g0156: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0156: ninja: no work to do.
g0156: Loading extension module scaled_upper_triang_masked_softmax_cuda...
g0156: Detected CUDA files, patching ldflags
g0156: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0156: Building extension module scaled_masked_softmax_cuda...
g0156: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0156: ninja: no work to do.
g0156: Loading extension module scaled_masked_softmax_cuda...
g0156: Detected CUDA files, patching ldflags
g0156: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0156: Building extension module scaled_softmax_cuda...
g0156: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0156: ninja: no work to do.
g0156: Loading extension module scaled_softmax_cuda...
g0156: >>> done with compiling and loading fused kernels. Compilation time: 7.364 seconds
g0156: time to initialize megatron (seconds): 22.879
g0156: [after megatron is initialized] datetime: 2024-08-12 02:21:55 
g0159: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0165: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0167: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0161: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0166: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0156: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0164: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0163: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0166: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0166: wandb:  $ pip install wandb --upgrade
g0166: wandb: Tracking run with wandb version 0.17.5
g0166: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-0js4a868
g0166: wandb: Run `wandb offline` to turn off syncing.
g0166: wandb: Syncing run g0166.abci.local
g0166: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0166: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/0js4a868
g0161: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0161: wandb:  $ pip install wandb --upgrade
g0161: wandb: Tracking run with wandb version 0.17.5
g0161: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-axtuai8q
g0161: wandb: Run `wandb offline` to turn off syncing.
g0161: wandb: Syncing run g0161.abci.local
g0161: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0161: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/axtuai8q
g0165: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0165: wandb:  $ pip install wandb --upgrade
g0165: wandb: Tracking run with wandb version 0.17.5
g0165: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-uatl2tie
g0165: wandb: Run `wandb offline` to turn off syncing.
g0167: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0167: wandb:  $ pip install wandb --upgrade
g0167: wandb: Tracking run with wandb version 0.17.5
g0167: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-c147v76z
g0167: wandb: Run `wandb offline` to turn off syncing.
g0165: wandb: Syncing run g0165.abci.local
g0165: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0165: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/uatl2tie
g0167: wandb: Syncing run g0167.abci.local
g0167: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0167: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/c147v76z
g0159: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0159: wandb:  $ pip install wandb --upgrade
g0159: wandb: Tracking run with wandb version 0.17.5
g0159: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-j7fdi1qo
g0159: wandb: Run `wandb offline` to turn off syncing.
g0159: wandb: Syncing run g0159.abci.local
g0159: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0159: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/j7fdi1qo
g0156: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0156: wandb:  $ pip install wandb --upgrade
g0156: wandb: Tracking run with wandb version 0.17.5
g0156: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-j9nrt97m
g0156: wandb: Run `wandb offline` to turn off syncing.
g0164: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0164: wandb:  $ pip install wandb --upgrade
g0164: wandb: Tracking run with wandb version 0.17.5
g0164: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-0j69xjyn
g0164: wandb: Run `wandb offline` to turn off syncing.
g0156: wandb: Syncing run g0156.abci.local
g0156: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0156: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/j9nrt97m
g0164: wandb: Syncing run g0164.abci.local
g0164: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0164: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/0j69xjyn
g0163: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0163: wandb:  $ pip install wandb --upgrade
g0163: wandb: Tracking run with wandb version 0.17.5
g0163: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_022156-bfw8s5u8
g0163: wandb: Run `wandb offline` to turn off syncing.
g0163: wandb: Syncing run g0163.abci.local
g0163: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0163: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/bfw8s5u8
g0156: building GPT model ...
g0156: [2024-08-12 02:21:57,833] [INFO] [utils.py:795:see_memory_usage] Before Building Model
g0156: [2024-08-12 02:21:57,834] [INFO] [utils.py:796:see_memory_usage] MA 0.0 GB         Max_MA 0.73 GB         CA 0.0 GB         Max_CA 1 GB 
g0156: [2024-08-12 02:21:57,834] [INFO] [utils.py:803:see_memory_usage] CPU Virtual Memory:  used = 56.77 GB, percent = 15.1%
g0156: SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
g0156: Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=1, model=0): 1, ProcessCoord(pipe=0, data=2, model=0): 2, ProcessCoord(pipe=0, data=3, model=0): 3, ProcessCoord(pipe=1, data=0, model=0): 4, ProcessCoord(pipe=1, data=1, model=0): 5, ProcessCoord(pipe=1, data=2, model=0): 6, ProcessCoord(pipe=1, data=3, model=0): 7, ProcessCoord(pipe=2, data=0, model=0): 8, ProcessCoord(pipe=2, data=1, model=0): 9, ProcessCoord(pipe=2, data=2, model=0): 10, ProcessCoord(pipe=2, data=3, model=0): 11, ProcessCoord(pipe=3, data=0, model=0): 12, ProcessCoord(pipe=3, data=1, model=0): 13, ProcessCoord(pipe=3, data=2, model=0): 14, ProcessCoord(pipe=3, data=3, model=0): 15, ProcessCoord(pipe=4, data=0, model=0): 16, ProcessCoord(pipe=4, data=1, model=0): 17, ProcessCoord(pipe=4, data=2, model=0): 18, ProcessCoord(pipe=4, data=3, model=0): 19, ProcessCoord(pipe=5, data=0, model=0): 20, ProcessCoord(pipe=5, data=1, model=0): 21, ProcessCoord(pipe=5, data=2, model=0): 22, ProcessCoord(pipe=5, data=3, model=0): 23, ProcessCoord(pipe=6, data=0, model=0): 24, ProcessCoord(pipe=6, data=1, model=0): 25, ProcessCoord(pipe=6, data=2, model=0): 26, ProcessCoord(pipe=6, data=3, model=0): 27, ProcessCoord(pipe=7, data=0, model=0): 28, ProcessCoord(pipe=7, data=1, model=0): 29, ProcessCoord(pipe=7, data=2, model=0): 30, ProcessCoord(pipe=7, data=3, model=0): 31}
g0156: [2024-08-12 02:21:58,344] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer
g0156: stage=0 layers=5
g0156:      0: _to_float16
g0156:      1: EmbeddingPipe
g0156:      2: ParallelTransformerLayerPipe
g0156:      3: ParallelTransformerLayerPipe
g0156:      4: ParallelTransformerLayerPipe
g0156: stage=1 layers=3
g0156:      5: ParallelTransformerLayerPipe
g0156:      6: ParallelTransformerLayerPipe
g0156:      7: ParallelTransformerLayerPipe
g0156: stage=2 layers=3
g0156:      8: ParallelTransformerLayerPipe
g0156:      9: ParallelTransformerLayerPipe
g0156:     10: ParallelTransformerLayerPipe
g0156: stage=3 layers=3
g0156:     11: ParallelTransformerLayerPipe
g0156:     12: ParallelTransformerLayerPipe
g0156:     13: ParallelTransformerLayerPipe
g0156: stage=4 layers=3
g0156:     14: ParallelTransformerLayerPipe
g0156:     15: ParallelTransformerLayerPipe
g0156:     16: ParallelTransformerLayerPipe
g0156: stage=5 layers=3
g0156:     17: ParallelTransformerLayerPipe
g0156:     18: ParallelTransformerLayerPipe
g0156:     19: ParallelTransformerLayerPipe
g0156: stage=6 layers=3
g0156:     20: ParallelTransformerLayerPipe
g0156:     21: ParallelTransformerLayerPipe
g0156:     22: ParallelTransformerLayerPipe
g0156: stage=7 layers=3
g0156:     23: ParallelTransformerLayerPipe
g0156:     24: MixedFusedRMSNorm
g0156:     25: LMHeadPipe
g0156:   loss: CrossEntropy
g0167:  > number of parameters on (tensor, pipeline) model parallel rank (0, 7): 110893056
g0163:  > number of parameters on (tensor, pipeline) model parallel rank (0, 3): 135278592
g0166:  > number of parameters on (tensor, pipeline) model parallel rank (0, 6): 135278592
g0159:  > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 135278592
g0165:  > number of parameters on (tensor, pipeline) model parallel rank (0, 5): 135278592
g0161:  > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 135278592
g0164:  > number of parameters on (tensor, pipeline) model parallel rank (0, 4): 135278592
g0156: [2024-08-12 02:21:58,908] [INFO] [utils.py:795:see_memory_usage] After Building Model
g0156: [2024-08-12 02:21:58,909] [INFO] [utils.py:796:see_memory_usage] MA 0.75 GB         Max_MA 0.78 GB         CA 0.78 GB         Max_CA 1 GB 
g0156: [2024-08-12 02:21:58,909] [INFO] [utils.py:803:see_memory_usage] CPU Virtual Memory:  used = 56.82 GB, percent = 15.1%
g0156:  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 201076736
g0156: setting training iterations to 52000
g0156: > learning rate decay style: cosine
g0156: DeepSpeed is enabled.
g0156: [2024-08-12 02:21:58,912] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4, git-hash=unknown, git-branch=unknown
g0167: [2024-08-12 02:21:58,962] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0167: [2024-08-12 02:21:58,962] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0167: [2024-08-12 02:21:58,962] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0167: [2024-08-12 02:21:58,964] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0166: [2024-08-12 02:21:58,978] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0166: [2024-08-12 02:21:58,979] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0166: [2024-08-12 02:21:58,979] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0166: [2024-08-12 02:21:58,979] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0165: [2024-08-12 02:21:58,981] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0165: [2024-08-12 02:21:58,982] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0165: [2024-08-12 02:21:58,982] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0165: [2024-08-12 02:21:58,982] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0163: [2024-08-12 02:21:58,990] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0163: [2024-08-12 02:21:58,990] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0163: [2024-08-12 02:21:58,990] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0163: [2024-08-12 02:21:58,990] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0159: [2024-08-12 02:21:59,007] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0159: [2024-08-12 02:21:59,007] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0159: [2024-08-12 02:21:59,007] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0159: [2024-08-12 02:21:59,007] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0164: [2024-08-12 02:21:59,014] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0164: [2024-08-12 02:21:59,014] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0164: [2024-08-12 02:21:59,014] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0164: [2024-08-12 02:21:59,014] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0161: [2024-08-12 02:21:59,022] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0161: [2024-08-12 02:21:59,022] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0161: [2024-08-12 02:21:59,022] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0161: [2024-08-12 02:21:59,022] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0156: [2024-08-12 02:21:59,103] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
g0156: [2024-08-12 02:21:59,104] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
g0156: [2024-08-12 02:21:59,104] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
g0156: [2024-08-12 02:21:59,105] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
g0156: [2024-08-12 02:21:59,105] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
g0156: [2024-08-12 02:21:59,140] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
g0156: [2024-08-12 02:21:59,140] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
g0156: [2024-08-12 02:21:59,140] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x7fb946ce2a10>
g0156: [2024-08-12 02:21:59,140] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0156: [2024-08-12 02:21:59,141] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: [2024-08-12 02:21:59,141] [INFO] [config.py:979:print] DeepSpeedEngine configuration:
g0156: [2024-08-12 02:21:59,141] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0156: [2024-08-12 02:21:59,141] [INFO] [config.py:983:print]   activation_checkpointing_config  {
g0156:     "partition_activations": false, 
g0156:     "contiguous_memory_optimization": false, 
g0156:     "cpu_checkpointing": false, 
g0156:     "number_checkpoints": null, 
g0156:     "synchronize_checkpoint_boundary": false, 
g0156:     "profile": false
g0156: }
g0156: [2024-08-12 02:21:59,141] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0156: [2024-08-12 02:21:59,142] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
g0156: [2024-08-12 02:21:59,142] [INFO] [config.py:983:print]   amp_enabled .................. False
g0156: [2024-08-12 02:21:59,142] [INFO] [config.py:983:print]   amp_params ................... False
g0156: [2024-08-12 02:21:59,142] [INFO] [config.py:983:print]   autotuning_config ............ {
g0156:     "enabled": false, 
g0156:     "start_step": null, 
g0156:     "end_step": null, 
g0156:     "metric_path": null, 
g0156:     "arg_mappings": null, 
g0156:     "metric": "throughput", 
g0156:     "model_info": null, 
g0156:     "results_dir": "autotuning_results", 
g0156:     "exps_dir": "autotuning_exps", 
g0156:     "overwrite": true, 
g0156:     "fast": true, 
g0156:     "start_profile_step": 3, 
g0156:     "end_profile_step": 5, 
g0156:     "tuner_type": "gridsearch", 
g0156:     "tuner_early_stopping": 5, 
g0156:     "tuner_num_trials": 50, 
g0156:     "model_info_path": null, 
g0156:     "mp_size": 1, 
g0156:     "max_train_batch_size": null, 
g0156:     "min_train_batch_size": 1, 
g0156:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
g0156:     "min_train_micro_batch_size_per_gpu": 1, 
g0156:     "num_tuning_micro_batch_sizes": 3
g0156: }
g0156: [2024-08-12 02:21:59,142] [INFO] [config.py:983:print]   bfloat16_enabled ............. False
g0156: [2024-08-12 02:21:59,142] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb92c13f250>
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   communication_data_type ...... None
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
g0156: [2024-08-12 02:21:59,143] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   dataloader_drop_last ......... False
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   disable_allgather ............ False
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   dump_state ................... False
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 500, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer
g0156: [2024-08-12 02:21:59,144] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   elasticity_enabled ........... False
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   flops_profiler_config ........ {
g0156:     "enabled": false, 
g0156:     "recompute_fwd_factor": 0.0, 
g0156:     "profile_step": 1, 
g0156:     "module_depth": -1, 
g0156:     "top_modules": 1, 
g0156:     "detailed": true, 
g0156:     "output_file": null
g0156: }
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   fp16_auto_cast ............... False
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   fp16_enabled ................. True
g0156: [2024-08-12 02:21:59,145] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   global_rank .................. 0
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   grad_accum_dtype ............. None
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 32
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   gradient_clipping ............ 1.0
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 2048
g0156: [2024-08-12 02:21:59,146] [INFO] [config.py:983:print]   load_universal_checkpoint .... False
g0156: [2024-08-12 02:21:59,147] [INFO] [config.py:983:print]   loss_scale ................... 0
g0156: [2024-08-12 02:21:59,147] [INFO] [config.py:983:print]   memory_breakdown ............. False
g0156: [2024-08-12 02:21:59,147] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False
g0156: [2024-08-12 02:21:59,147] [INFO] [config.py:983:print]   mics_shard_size .............. -1
g0156: [2024-08-12 02:21:59,147] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
g0156: [2024-08-12 02:21:59,147] [INFO] [config.py:983:print]   nebula_config ................ {
g0156:     "enabled": false, 
g0156:     "persistent_storage_path": null, 
g0156:     "persistent_time_interval": 100, 
g0156:     "num_of_version_in_retention": 2, 
g0156:     "enable_nebula_load": true, 
g0156:     "load_path": null
g0156: }
g0156: [2024-08-12 02:21:59,147] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   optimizer_name ............... None
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   optimizer_params ............. None
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   pld_enabled .................. False
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   pld_params ................... False
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   prescale_gradients ........... True
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   scheduler_name ............... None
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   scheduler_params ............. None
g0156: [2024-08-12 02:21:59,148] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   sparse_attention ............. None
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   steps_per_print .............. 10
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   train_batch_size ............. 128
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  1
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   use_node_local_storage ....... False
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   wall_clock_breakdown ......... False
g0156: [2024-08-12 02:21:59,149] [INFO] [config.py:983:print]   weight_quantization_config ... None
g0156: [2024-08-12 02:21:59,150] [INFO] [config.py:983:print]   world_size ................... 4
g0156: [2024-08-12 02:21:59,150] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False
g0156: [2024-08-12 02:21:59,150] [INFO] [config.py:983:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
g0156: [2024-08-12 02:21:59,150] [INFO] [config.py:983:print]   zero_enabled ................. False
g0156: [2024-08-12 02:21:59,150] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True
g0156: [2024-08-12 02:21:59,150] [INFO] [config.py:983:print]   zero_optimization_stage ...... 0
g0156: [2024-08-12 02:21:59,150] [INFO] [config.py:969:print_user_config]   json = {
g0156:     "train_batch_size": 128, 
g0156:     "train_micro_batch_size_per_gpu": 1, 
g0156:     "steps_per_print": 10, 
g0156:     "zero_optimization": {
g0156:         "stage": 0
g0156:     }, 
g0156:     "gradient_clipping": 1.0, 
g0156:     "prescale_gradients": true, 
g0156:     "fp16": {
g0156:         "enabled": true, 
g0156:         "loss_scale": 0, 
g0156:         "loss_scale_window": 500, 
g0156:         "hysteresis": 2, 
g0156:         "min_loss_scale": 1, 
g0156:         "initial_scale_power": 11
g0156:     }, 
g0156:     "wall_clock_breakdown": false
g0156: }
g0156: [2024-08-12 02:21:59,151] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=32 micro_batch_size=1
g0156: [2024-08-12 02:21:59,151] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0156: [2024-08-12 02:21:59,862] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=5 [0, 5) STAGE_PARAMS=201076736 (201.077M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0164: [2024-08-12 02:21:59,862] [INFO] [engine.py:158:__init__] RANK=16 STAGE=4 LAYERS=3 [14, 17) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0161: [2024-08-12 02:21:59,863] [INFO] [engine.py:158:__init__] RANK=8 STAGE=2 LAYERS=3 [8, 11) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0166: [2024-08-12 02:21:59,863] [INFO] [engine.py:158:__init__] RANK=24 STAGE=6 LAYERS=3 [20, 23) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0159: [2024-08-12 02:21:59,863] [INFO] [engine.py:158:__init__] RANK=4 STAGE=1 LAYERS=3 [5, 8) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0163: [2024-08-12 02:21:59,863] [INFO] [engine.py:158:__init__] RANK=12 STAGE=3 LAYERS=3 [11, 14) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0165: [2024-08-12 02:21:59,863] [INFO] [engine.py:158:__init__] RANK=20 STAGE=5 LAYERS=3 [17, 20) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0167: [2024-08-12 02:21:59,863] [INFO] [engine.py:158:__init__] RANK=28 STAGE=7 LAYERS=3 [23, 26) STAGE_PARAMS=110893056 (110.893M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0166: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0164: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0166: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0166: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0159: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0156: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0159: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0156: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0159: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0167: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0167: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0167: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0163: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0163: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0163: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0165: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0165: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0156: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0161: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0161: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0161: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0165: [2024-08-12 02:22:00,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0161: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0165: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0156: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0164: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0164: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0164: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0166: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0167: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0163: [2024-08-12 02:22:00,597] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0159: [2024-08-12 02:22:00,603] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0166: [2024-08-12 02:22:03,317] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0166: [2024-08-12 02:22:03,317] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0166: [2024-08-12 02:22:03,317] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0166: [2024-08-12 02:22:03,318] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0166: [2024-08-12 02:22:03,326] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0166: [2024-08-12 02:22:03,326] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0166: [2024-08-12 02:22:03,326] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0166: [2024-08-12 02:22:03,326] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0161: [2024-08-12 02:22:03,343] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0161: [2024-08-12 02:22:03,343] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0161: [2024-08-12 02:22:03,343] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0161: [2024-08-12 02:22:03,344] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0161: [2024-08-12 02:22:03,352] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0161: [2024-08-12 02:22:03,352] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0161: [2024-08-12 02:22:03,352] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0161: [2024-08-12 02:22:03,352] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0163: [2024-08-12 02:22:03,458] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0163: [2024-08-12 02:22:03,458] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0163: [2024-08-12 02:22:03,459] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0163: [2024-08-12 02:22:03,466] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0163: [2024-08-12 02:22:03,467] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0163: [2024-08-12 02:22:03,467] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0156: [2024-08-12 02:22:03,499] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:03,501] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:03,501] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:03,501] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0159: [2024-08-12 02:22:03,502] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0159: [2024-08-12 02:22:03,502] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0159: [2024-08-12 02:22:03,502] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0159: [2024-08-12 02:22:03,502] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0165: [2024-08-12 02:22:03,503] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0165: [2024-08-12 02:22:03,503] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0165: [2024-08-12 02:22:03,503] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0165: [2024-08-12 02:22:03,503] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:03,507] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0163: [2024-08-12 02:22:03,507] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:03,508] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0156: [2024-08-12 02:22:03,509] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0156: [2024-08-12 02:22:03,509] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0159: [2024-08-12 02:22:03,510] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0159: [2024-08-12 02:22:03,511] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0159: [2024-08-12 02:22:03,511] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0165: [2024-08-12 02:22:03,511] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0165: [2024-08-12 02:22:03,511] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0159: [2024-08-12 02:22:03,512] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0165: [2024-08-12 02:22:03,512] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0165: [2024-08-12 02:22:03,512] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0163: [2024-08-12 02:22:03,512] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0167: [2024-08-12 02:22:03,528] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0167: [2024-08-12 02:22:03,528] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0167: [2024-08-12 02:22:03,528] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0167: [2024-08-12 02:22:03,530] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0167: [2024-08-12 02:22:03,536] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0167: [2024-08-12 02:22:03,536] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0167: [2024-08-12 02:22:03,536] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0167: [2024-08-12 02:22:03,537] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0164: [2024-08-12 02:22:03,671] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0164: [2024-08-12 02:22:03,671] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0164: [2024-08-12 02:22:03,671] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0164: [2024-08-12 02:22:03,673] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0164: [2024-08-12 02:22:03,679] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0164: [2024-08-12 02:22:03,679] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0164: [2024-08-12 02:22:03,679] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0164: [2024-08-12 02:22:03,680] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0156: [2024-08-12 02:22:04,799] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:04,799] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:04,800] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:04,800] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,037] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,037] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,037] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,038] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,058] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:05,059] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0156: [2024-08-12 02:22:05,059] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,059] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,081] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,081] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,097] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,110] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,110] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,111] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,111] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,111] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0163: [2024-08-12 02:22:05,156] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0163: [2024-08-12 02:22:05,157] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0163: [2024-08-12 02:22:05,157] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0163: [2024-08-12 02:22:05,157] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0163: [2024-08-12 02:22:05,157] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0163: [2024-08-12 02:22:05,158] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0163: [2024-08-12 02:22:05,160] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0163: [2024-08-12 02:22:05,161] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,163] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,163] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,174] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0161: [2024-08-12 02:22:05,174] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0161: [2024-08-12 02:22:05,175] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,175] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,176] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0161: [2024-08-12 02:22:05,176] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0161: [2024-08-12 02:22:05,177] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,177] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,191] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,192] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,271] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0165: [2024-08-12 02:22:05,271] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0165: [2024-08-12 02:22:05,271] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0165: [2024-08-12 02:22:05,272] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,272] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,272] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,272] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0165: [2024-08-12 02:22:05,273] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0159: [2024-08-12 02:22:05,308] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0159: [2024-08-12 02:22:05,308] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0159: [2024-08-12 02:22:05,308] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0159: [2024-08-12 02:22:05,309] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0159: [2024-08-12 02:22:05,309] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0159: [2024-08-12 02:22:05,309] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0159: [2024-08-12 02:22:05,310] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0159: [2024-08-12 02:22:05,311] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,383] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,383] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,383] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,383] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,384] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,384] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,384] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,384] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,416] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,417] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,421] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,421] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,430] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,438] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,442] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,443] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,536] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,536] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,536] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,537] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,537] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,537] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,537] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,538] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,572] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,572] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,573] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,573] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,573] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,574] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,574] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,574] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,574] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,574] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,575] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,575] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,579] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0166: [2024-08-12 02:22:05,579] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0166: [2024-08-12 02:22:05,579] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0166: [2024-08-12 02:22:05,580] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0166: [2024-08-12 02:22:05,580] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,580] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,580] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,580] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,589] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,594] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,594] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,596] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,609] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,609] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,612] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,613] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,626] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,627] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,632] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,632] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,643] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0164: [2024-08-12 02:22:05,644] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0164: [2024-08-12 02:22:05,644] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0164: [2024-08-12 02:22:05,644] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,644] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,645] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,645] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0164: [2024-08-12 02:22:05,646] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,763] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,763] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,763] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,764] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,764] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,764] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,764] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,764] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,795] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,795] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,798] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,798] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0156: [2024-08-12 02:22:05,808] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,816] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,819] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0156: [2024-08-12 02:22:05,819] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,828] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,828] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,828] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,828] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,828] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,828] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,828] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,829] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,860] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,861] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,863] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,864] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0165: [2024-08-12 02:22:05,879] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,881] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,882] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0165: [2024-08-12 02:22:05,885] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,913] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,913] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,913] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,913] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,914] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,914] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,914] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,914] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,924] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,924] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,924] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,924] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,924] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,925] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,925] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,925] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,948] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,949] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,949] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,950] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,957] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,957] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,960] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0161: [2024-08-12 02:22:05,960] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0166: [2024-08-12 02:22:05,964] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,971] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,971] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0166: [2024-08-12 02:22:05,971] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,974] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,974] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,978] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0161: [2024-08-12 02:22:05,979] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,985] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:05,985] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,986] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:05,986] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:05,986] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:05,986] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,987] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0164: [2024-08-12 02:22:05,987] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,019] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,019] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,023] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,023] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,039] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,040] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,041] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,041] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0165: [2024-08-12 02:22:06,067] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0165: [2024-08-12 02:22:06,067] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0165: [2024-08-12 02:22:06,067] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0165: [2024-08-12 02:22:06,067] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0165: [2024-08-12 02:22:06,067] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0165: [2024-08-12 02:22:06,067] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0165: [2024-08-12 02:22:06,068] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0165: [2024-08-12 02:22:06,068] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0165: [2024-08-12 02:22:06,100] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0165: [2024-08-12 02:22:06,100] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0165: [2024-08-12 02:22:06,102] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0165: [2024-08-12 02:22:06,102] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,199] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,200] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0161: [2024-08-12 02:22:06,201] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,201] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,201] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,201] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0161: [2024-08-12 02:22:06,201] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0161: [2024-08-12 02:22:06,201] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,228] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,228] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,228] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,229] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,229] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,229] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,229] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,229] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0161: [2024-08-12 02:22:06,233] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,233] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,237] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0161: [2024-08-12 02:22:06,237] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,262] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,262] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,262] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,263] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,276] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,283] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,283] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,285] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,307] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,307] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,307] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,307] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,307] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,308] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,308] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,308] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,338] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,338] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,341] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,341] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,357] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,358] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,359] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,359] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,513] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0167: [2024-08-12 02:22:06,513] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0167: [2024-08-12 02:22:06,513] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0167: [2024-08-12 02:22:06,513] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0167: [2024-08-12 02:22:06,514] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,514] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,514] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,514] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,526] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,526] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,526] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,527] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,527] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,527] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,527] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,527] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0166: [2024-08-12 02:22:06,560] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,563] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,563] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0166: [2024-08-12 02:22:06,563] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,655] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,655] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,655] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,655] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,655] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,656] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,656] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,656] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0164: [2024-08-12 02:22:06,686] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,686] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,689] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0164: [2024-08-12 02:22:06,689] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0159: [2024-08-12 02:22:06,819] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:06,819] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0159: [2024-08-12 02:22:06,820] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:06,820] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:06,820] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:06,820] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0159: [2024-08-12 02:22:06,820] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0159: [2024-08-12 02:22:06,821] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,824] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,824] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,824] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,824] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,824] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,824] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,824] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,825] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,858] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,859] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,859] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,861] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,874] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,880] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,881] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,883] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,897] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,898] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,898] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,898] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0167: [2024-08-12 02:22:06,898] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,898] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,898] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:06,899] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:07,095] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0167: [2024-08-12 02:22:07,096] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:07,096] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0167: [2024-08-12 02:22:07,096] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0167: [2024-08-12 02:22:07,097] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0167: [2024-08-12 02:22:07,097] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:07,097] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:07,097] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0167: [2024-08-12 02:22:07,140] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0167: [2024-08-12 02:22:07,140] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0167: [2024-08-12 02:22:07,140] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0167: [2024-08-12 02:22:07,145] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,176] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,176] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,176] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,177] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,192] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,199] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,199] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,199] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0156: [2024-08-12 02:22:07,352] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0156: [2024-08-12 02:22:07,353] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0156: [2024-08-12 02:22:07,353] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0156: [2024-08-12 02:22:07,353] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0156: [2024-08-12 02:22:07,353] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0156: [2024-08-12 02:22:07,353] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0156: [2024-08-12 02:22:07,353] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0156: [2024-08-12 02:22:07,354] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0156: [2024-08-12 02:22:07,385] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0156: [2024-08-12 02:22:07,385] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0156: [2024-08-12 02:22:07,386] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0156: [2024-08-12 02:22:07,386] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,552] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,552] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,552] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,552] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,552] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0163: [2024-08-12 02:22:07,553] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0163: [2024-08-12 02:22:07,553] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0163: [2024-08-12 02:22:07,553] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,759] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,759] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,759] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,759] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,759] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,759] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,759] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,760] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,791] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,791] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,791] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,791] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0159: [2024-08-12 02:22:07,806] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,812] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,812] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0159: [2024-08-12 02:22:07,813] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0163: [2024-08-12 02:22:07,934] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,934] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,936] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,936] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0163: [2024-08-12 02:22:07,951] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0163: [2024-08-12 02:22:07,951] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0163: [2024-08-12 02:22:07,956] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0163: [2024-08-12 02:22:07,956] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,226] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,227] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,227] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,227] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,227] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,227] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,227] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,228] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0159: [2024-08-12 02:22:08,254] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0159: [2024-08-12 02:22:08,254] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0159: [2024-08-12 02:22:08,254] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0159: [2024-08-12 02:22:08,254] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0159: [2024-08-12 02:22:08,255] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0159: [2024-08-12 02:22:08,255] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0159: [2024-08-12 02:22:08,255] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0159: [2024-08-12 02:22:08,255] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,260] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,261] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,262] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,262] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,276] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,277] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,281] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,284] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0159: [2024-08-12 02:22:08,289] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0159: [2024-08-12 02:22:08,292] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0159: [2024-08-12 02:22:08,292] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0159: [2024-08-12 02:22:08,292] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,588] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,588] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,588] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,588] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,588] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,588] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,588] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,589] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0163: [2024-08-12 02:22:08,623] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,623] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,624] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0163: [2024-08-12 02:22:08,624] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0156:  > overriding learning rate value to 0.0002
g0156:  > overriding minimum learning rate value to 1e-05
g0156:  > overriding warmup iterations value to 0
g0156:  > overriding warmup tokens value to 3000000000
g0156:  > overriding total number of iterations value to 6656000
g0156:  > overriding decay tokens value to 300000000000
g0156:  > overriding learning rate decay style value to cosine
g0156:  > overriding start weight decay value to 0.1
g0156:  > overriding end weight decay value to 0.1
g0156:  > overriding total number of weight decay iterations value to 6656000
g0156:  > overriding weight decay incr style value to constant
g0156:  checkpoint version 3.0
g0156:   successfully loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_010000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase at iteration 42000
g0167: (min, max) time across ranks (ms):
g0167:     load-checkpoint ................................: (9089.48, 9090.55)
g0156: [after model, optimizer, and learning rate scheduler are built] datetime: 2024-08-12 02:22:09 
g0156: > building train, validation, and test datasets ...
g0156:  > datasets target sizes (minimum size):
g0156:     train:      6656000
g0156:     validation: 678400
g0156:     test:       12800
g0156: > building train, validation, and test datasets for GPT ...
g0156: Single data path provided for train, valid & test
g0156:  > building dataset index ...
g0156:     reading sizes...
g0156:     reading pointers...
g0156:     reading document index...
g0156:     creating numpy buffer of mmap...
g0156:     creating memory view of numpy buffer...
g0156:  > finished creating indexed dataset in 0.075381 seconds
g0156:     number of documents: 2237032
g0156:  > dataset split:
g0156:     train:
g0156:      document indices in [0, 2122943) total of 2122943 documents
g0156:     validation:
g0156:      document indices in [2122943, 2234795) total of 111852 documents
g0156:     test:
g0156:      document indices in [2234795, 2237032) total of 2237 documents
g0156:  > WARNING: could not find index map files, building the indices on rank 0 ...
g0156:  > only one epoch required, setting separate_last_epoch to False
g0156:  > elasped time to build and save doc-idx mapping (seconds): 0.084940
g0156:     using:
g0156:      number of documents:       2122943
g0156:      number of epochs:          1
g0156:      sequence length:           2048
g0156:      total number of samples:   10738038
g0156:  > elasped time to build and save sample-idx mapping (seconds): 0.276418
g0156:  > building shuffle index with split [0, 10738038) and [10738038, 10738038) ...
g0156:  > elasped time to build and save shuffle-idx mapping (seconds): 0.458739
g0156:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/6d7fe219b10fbd3645a75db7927956d7_doc_idx.npy
g0156:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/6d7fe219b10fbd3645a75db7927956d7_sample_idx.npy
g0156:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/6d7fe219b10fbd3645a75db7927956d7_shuffle_idx.npy
g0156:     loaded indexed file in 0.075 seconds
g0156:     total number of samples: 10738039
g0156:     total number of epochs: 1
g0156:  > WARNING: could not find index map files, building the indices on rank 0 ...
g0156:  > last epoch number of samples (115281) is smaller than 80% of number of samples per epoch (563119), setting separate_last_epoch to True
g0156:  > elasped time to build and save doc-idx mapping (seconds): 0.008596
g0156:     using:
g0156:      number of documents:       111852
g0156:      number of epochs:          2
g0156:      sequence length:           2048
g0156:      total number of samples:   1126239
g0156:  > elasped time to build and save sample-idx mapping (seconds): 0.021298
g0156:  > building shuffle index with split [0, 563119) and [563119, 1126239) ...
g0156:  > elasped time to build and save shuffle-idx mapping (seconds): 0.048535
g0156:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2f9321b6b0ac3b4b7e4d772c7b9ef9a2_doc_idx.npy
g0156:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2f9321b6b0ac3b4b7e4d772c7b9ef9a2_sample_idx.npy
g0156:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2f9321b6b0ac3b4b7e4d772c7b9ef9a2_shuffle_idx.npy
g0156:     loaded indexed file in 0.008 seconds
g0156:     total number of samples: 1126240
g0156:     total number of epochs: 2
g0156:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/4287d16757d1b97e8079b6b58b70ad7b_doc_idx.npy
g0156:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/4287d16757d1b97e8079b6b58b70ad7b_sample_idx.npy
g0156:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/4287d16757d1b97e8079b6b58b70ad7b_shuffle_idx.npy
g0156:     loaded indexed file in 0.097 seconds
g0156:     total number of samples: 14458
g0156:     total number of epochs: 2
g0156: > finished creating GPT datasets ...
g0156: [after dataloaders are built] datetime: 2024-08-12 02:22:12 
g0156: done with setup ...
g0156: training ...
g0167: (min, max) time across ranks (ms):
g0167:     model-and-optimizer-setup ......................: (12005.42, 12009.01)
g0167:     train/valid/test-data-iterators-setup ..........: (2804.21, 2813.96)
g0156: [before the start of training step] datetime: 2024-08-12 02:22:12 
g0156: [2024-08-12 02:23:07,031] [INFO] [logging.py:96:log_dist] [Rank 0] step=42010, skipped=61, lr=[0.00019965900617800823, 0.00019965900617800823], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42010 loss: 0.7481 iter time (s): 5.404 samples/sec: 23.686
g0167:  iteration    42010/   52000 | consumed samples:      5377280 | consumed tokens:  11012669440 | elapsed time per iteration (ms): 5441.5 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.449225E-01 | loss scale: 65536.0 | grad norm: 0.163 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 23.523 | tokens per gpu per second (tgs): 1505.470 | TFLOPs: 12.11 |
g0165: [Rank 20] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 5159.57470703125 | reserved: 5434.0 | max reserved: 5434.0
g0166: [Rank 24] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 4273.52783203125 | reserved: 5182.0 | max reserved: 5182.0
g0167: [Rank 28] (after 42010 iterations) memory (MB) | allocated: 1924.90087890625 | max allocated: 2985.41162109375 | reserved: 3720.0 | max reserved: 3720.0
g0156: [Rank 0] (after 42010 iterations) memory (MB) | allocated: 2877.66943359375 | max allocated: 10557.68408203125 | reserved: 11010.0 | max reserved: 11010.0
g0164: [Rank 16] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 6045.62158203125 | reserved: 6456.0 | max reserved: 6456.0
g0163: [Rank 12] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 6931.66845703125 | reserved: 7222.0 | max reserved: 7222.0
g0159: [Rank 4] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 8703.76220703125 | reserved: 9010.0 | max reserved: 9010.0
g0161: [Rank 8] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 7817.71533203125 | reserved: 8116.0 | max reserved: 8116.0
g0156: [2024-08-12 02:23:48,488] [INFO] [logging.py:96:log_dist] [Rank 0] step=42020, skipped=61, lr=[0.00019965878314753572, 0.00019965878314753572], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42020 loss: 0.7468 iter time (s): 3.977 samples/sec: 32.187
g0167:  iteration    42020/   52000 | consumed samples:      5378560 | consumed tokens:  11015290880 | elapsed time per iteration (ms): 4145.6 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.462794E-01 | loss scale: 65536.0 | grad norm: 0.163 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.876 | tokens per gpu per second (tgs): 1976.067 | TFLOPs: 15.90 |
g0156: [2024-08-12 02:24:28,737] [INFO] [logging.py:96:log_dist] [Rank 0] step=42030, skipped=61, lr=[0.00019965856004428058, 0.00019965856004428058], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42030 loss: 0.7565 iter time (s): 3.992 samples/sec: 32.066
g0167:  iteration    42030/   52000 | consumed samples:      5379840 | consumed tokens:  11017912320 | elapsed time per iteration (ms): 4025.0 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.401948E-01 | loss scale: 65536.0 | grad norm: 0.157 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.802 | tokens per gpu per second (tgs): 2035.302 | TFLOPs: 16.38 |
g0156: [2024-08-12 02:25:08,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=42040, skipped=61, lr=[0.000199658336868243, 0.000199658336868243], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42040 loss: 0.7333 iter time (s): 3.988 samples/sec: 32.096
g0167:  iteration    42040/   52000 | consumed samples:      5381120 | consumed tokens:  11020533760 | elapsed time per iteration (ms): 4020.9 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.448466E-01 | loss scale: 65536.0 | grad norm: 0.173 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.833 | tokens per gpu per second (tgs): 2037.340 | TFLOPs: 16.39 |
g0156: [2024-08-12 02:25:49,360] [INFO] [logging.py:96:log_dist] [Rank 0] step=42050, skipped=61, lr=[0.0001996581136194232, 0.0001996581136194232], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42050 loss: 0.7344 iter time (s): 4.008 samples/sec: 31.934
g0167:  iteration    42050/   52000 | consumed samples:      5382400 | consumed tokens:  11023155200 | elapsed time per iteration (ms): 4041.3 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.409992E-01 | loss scale: 65536.0 | grad norm: 0.172 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.673 | tokens per gpu per second (tgs): 2027.081 | TFLOPs: 16.31 |
g0156: [2024-08-12 02:26:29,010] [INFO] [logging.py:96:log_dist] [Rank 0] step=42060, skipped=61, lr=[0.00019965789029782125, 0.00019965789029782125], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42060 loss: 0.7725 iter time (s): 3.932 samples/sec: 32.552
g0167:  iteration    42060/   52000 | consumed samples:      5383680 | consumed tokens:  11025776640 | elapsed time per iteration (ms): 3964.9 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.446918E-01 | loss scale: 65536.0 | grad norm: 0.159 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 32.283 | tokens per gpu per second (tgs): 2066.116 | TFLOPs: 16.63 |
g0156: [2024-08-12 02:27:10,039] [INFO] [logging.py:96:log_dist] [Rank 0] step=42070, skipped=61, lr=[0.00019965766690343742, 0.00019965766690343742], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42070 loss: 0.7465 iter time (s): 4.070 samples/sec: 31.449
g0167:  iteration    42070/   52000 | consumed samples:      5384960 | consumed tokens:  11028398080 | elapsed time per iteration (ms): 4102.9 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.403475E-01 | loss scale: 65536.0 | grad norm: 0.168 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.197 | tokens per gpu per second (tgs): 1996.624 | TFLOPs: 16.07 |
g0156: [2024-08-12 02:27:49,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=42080, skipped=61, lr=[0.00019965744343627184, 0.00019965744343627184], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42080 loss: 0.7537 iter time (s): 3.883 samples/sec: 32.961
g0167:  iteration    42080/   52000 | consumed samples:      5386240 | consumed tokens:  11031019520 | elapsed time per iteration (ms): 3916.2 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.381041E-01 | loss scale: 65536.0 | grad norm: 0.175 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 32.685 | tokens per gpu per second (tgs): 2091.841 | TFLOPs: 16.83 |
g0156: [2024-08-12 02:28:30,187] [INFO] [logging.py:96:log_dist] [Rank 0] step=42090, skipped=61, lr=[0.00019965721989632465, 0.00019965721989632465], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42090 loss: 0.7361 iter time (s): 4.066 samples/sec: 31.481
g0167:  iteration    42090/   52000 | consumed samples:      5387520 | consumed tokens:  11033640960 | elapsed time per iteration (ms): 4098.6 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.392531E-01 | loss scale: 65536.0 | grad norm: 0.154 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.230 | tokens per gpu per second (tgs): 1998.715 | TFLOPs: 16.08 |
g0156: [2024-08-12 02:29:11,199] [INFO] [logging.py:96:log_dist] [Rank 0] step=42100, skipped=61, lr=[0.00019965699628359606, 0.00019965699628359606], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42100 loss: 0.7101 iter time (s): 4.068 samples/sec: 31.462
g0167:  iteration    42100/   52000 | consumed samples:      5388800 | consumed tokens:  11036262400 | elapsed time per iteration (ms): 4101.2 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.416369E-01 | loss scale: 65536.0 | grad norm: 0.163 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.210 | tokens per gpu per second (tgs): 1997.469 | TFLOPs: 16.07 |
g0156: [2024-08-12 02:29:52,138] [INFO] [logging.py:96:log_dist] [Rank 0] step=42110, skipped=61, lr=[0.00019965677259808624, 0.00019965677259808624], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42110 loss: 0.7449 iter time (s): 4.061 samples/sec: 31.520
g0167:  iteration    42110/   52000 | consumed samples:      5390080 | consumed tokens:  11038883840 | elapsed time per iteration (ms): 4093.8 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.389735E-01 | loss scale: 65536.0 | grad norm: 0.163 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.267 | tokens per gpu per second (tgs): 2001.073 | TFLOPs: 16.10 |
g0156: [2024-08-12 02:30:33,458] [INFO] [logging.py:96:log_dist] [Rank 0] step=42120, skipped=61, lr=[0.00019965654883979538, 0.00019965654883979538], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42120 loss: 0.7521 iter time (s): 4.099 samples/sec: 31.225
g0167:  iteration    42120/   52000 | consumed samples:      5391360 | consumed tokens:  11041505280 | elapsed time per iteration (ms): 4132.1 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.401031E-01 | loss scale: 65536.0 | grad norm: 0.169 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.977 | tokens per gpu per second (tgs): 1982.536 | TFLOPs: 15.95 |
g0156: [2024-08-12 02:31:14,380] [INFO] [logging.py:96:log_dist] [Rank 0] step=42130, skipped=61, lr=[0.00019965632500872362, 0.00019965632500872362], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42130 loss: 0.7114 iter time (s): 4.059 samples/sec: 31.533
g0167:  iteration    42130/   52000 | consumed samples:      5392640 | consumed tokens:  11044126720 | elapsed time per iteration (ms): 4092.2 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.496433E-01 | loss scale: 65536.0 | grad norm: 0.163 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.279 | tokens per gpu per second (tgs): 2001.856 | TFLOPs: 16.11 |
g0156: [2024-08-12 02:31:55,901] [INFO] [logging.py:96:log_dist] [Rank 0] step=42140, skipped=61, lr=[0.00019965610110487113, 0.00019965610110487113], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42140 loss: 0.7478 iter time (s): 4.119 samples/sec: 31.073
g0167:  iteration    42140/   52000 | consumed samples:      5393920 | consumed tokens:  11046748160 | elapsed time per iteration (ms): 4152.1 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.489921E-01 | loss scale: 65536.0 | grad norm: 0.195 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.828 | tokens per gpu per second (tgs): 1972.987 | TFLOPs: 15.88 |
g0156: [2024-08-12 02:32:36,306] [INFO] [logging.py:96:log_dist] [Rank 0] step=42150, skipped=61, lr=[0.00019965587712823812, 0.00019965587712823812], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42150 loss: 0.7896 iter time (s): 4.006 samples/sec: 31.950
g0167:  iteration    42150/   52000 | consumed samples:      5395200 | consumed tokens:  11049369600 | elapsed time per iteration (ms): 4040.4 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.514023E-01 | loss scale: 65536.0 | grad norm: 0.166 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.680 | tokens per gpu per second (tgs): 2027.544 | TFLOPs: 16.32 |
g0156: [2024-08-12 02:33:17,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=42160, skipped=61, lr=[0.00019965565307882471, 0.00019965565307882471], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42160 loss: 0.7420 iter time (s): 4.084 samples/sec: 31.341
g0167:  iteration    42160/   52000 | consumed samples:      5396480 | consumed tokens:  11051991040 | elapsed time per iteration (ms): 4117.3 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.406173E-01 | loss scale: 65536.0 | grad norm: 0.173 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.088 | tokens per gpu per second (tgs): 1989.646 | TFLOPs: 16.01 |
g0156: [2024-08-12 02:33:59,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=42170, skipped=61, lr=[0.00019965542895663115, 0.00019965542895663115], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42170 loss: 0.7640 iter time (s): 4.219 samples/sec: 30.340
g0167:  iteration    42170/   52000 | consumed samples:      5397760 | consumed tokens:  11054612480 | elapsed time per iteration (ms): 4251.9 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.528980E-01 | loss scale: 65536.0 | grad norm: 0.175 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.104 | tokens per gpu per second (tgs): 1926.648 | TFLOPs: 15.50 |
g0156: [2024-08-12 02:34:42,194] [INFO] [logging.py:96:log_dist] [Rank 0] step=42180, skipped=61, lr=[0.0001996552047616575, 0.0001996552047616575], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42180 loss: 0.7562 iter time (s): 4.187 samples/sec: 30.570
g0167:  iteration    42180/   52000 | consumed samples:      5399040 | consumed tokens:  11057233920 | elapsed time per iteration (ms): 4219.6 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.436247E-01 | loss scale: 65536.0 | grad norm: 0.157 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.335 | tokens per gpu per second (tgs): 1941.417 | TFLOPs: 15.62 |
g0156: [2024-08-12 02:35:23,526] [INFO] [logging.py:96:log_dist] [Rank 0] step=42190, skipped=61, lr=[0.00019965498049390404, 0.00019965498049390404], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42190 loss: 0.7428 iter time (s): 4.100 samples/sec: 31.216
g0167:  iteration    42190/   52000 | consumed samples:      5400320 | consumed tokens:  11059855360 | elapsed time per iteration (ms): 4133.2 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.358980E-01 | loss scale: 65536.0 | grad norm: 0.220 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.969 | tokens per gpu per second (tgs): 1982.016 | TFLOPs: 15.95 |
g0156: [2024-08-12 02:36:04,832] [INFO] [logging.py:96:log_dist] [Rank 0] step=42200, skipped=61, lr=[0.00019965475615337086, 0.00019965475615337086], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42200 loss: 0.7547 iter time (s): 4.098 samples/sec: 31.236
g0167:  iteration    42200/   52000 | consumed samples:      5401600 | consumed tokens:  11062476800 | elapsed time per iteration (ms): 4130.6 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.348425E-01 | loss scale: 65536.0 | grad norm: 0.165 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.988 | tokens per gpu per second (tgs): 1983.226 | TFLOPs: 15.96 |
g0156: [2024-08-12 02:36:46,881] [INFO] [logging.py:96:log_dist] [Rank 0] step=42210, skipped=61, lr=[0.0001996545317400582, 0.0001996545317400582], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42210 loss: 0.7501 iter time (s): 4.172 samples/sec: 30.682
g0167:  iteration    42210/   52000 | consumed samples:      5402880 | consumed tokens:  11065098240 | elapsed time per iteration (ms): 4204.8 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.360065E-01 | loss scale: 65536.0 | grad norm: 0.172 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.441 | tokens per gpu per second (tgs): 1948.254 | TFLOPs: 15.68 |
g0156: [2024-08-12 02:37:29,067] [INFO] [logging.py:96:log_dist] [Rank 0] step=42220, skipped=61, lr=[0.00019965430725396618, 0.00019965430725396618], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42220 loss: 0.7017 iter time (s): 4.185 samples/sec: 30.582
g0167:  iteration    42220/   52000 | consumed samples:      5404160 | consumed tokens:  11067719680 | elapsed time per iteration (ms): 4218.6 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.422750E-01 | loss scale: 65536.0 | grad norm: 0.174 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.342 | tokens per gpu per second (tgs): 1941.867 | TFLOPs: 15.63 |
g0156: [2024-08-12 02:38:10,498] [INFO] [logging.py:96:log_dist] [Rank 0] step=42230, skipped=61, lr=[0.000199654082695095, 0.000199654082695095], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42230 loss: 0.7405 iter time (s): 4.110 samples/sec: 31.141
g0167:  iteration    42230/   52000 | consumed samples:      5405440 | consumed tokens:  11070341120 | elapsed time per iteration (ms): 4143.2 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.390486E-01 | loss scale: 65536.0 | grad norm: 0.178 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.894 | tokens per gpu per second (tgs): 1977.233 | TFLOPs: 15.91 |
g0156: [2024-08-12 02:38:52,827] [INFO] [logging.py:96:log_dist] [Rank 0] step=42240, skipped=61, lr=[0.00019965385806344484, 0.00019965385806344484], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42240 loss: 0.7547 iter time (s): 4.200 samples/sec: 30.478
g0167:  iteration    42240/   52000 | consumed samples:      5406720 | consumed tokens:  11072962560 | elapsed time per iteration (ms): 4232.9 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.482741E-01 | loss scale: 65536.0 | grad norm: 0.177 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.239 | tokens per gpu per second (tgs): 1935.325 | TFLOPs: 15.57 |
g0156: [2024-08-12 02:39:34,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=42250, skipped=61, lr=[0.00019965363335901584, 0.00019965363335901584], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42250 loss: 0.7660 iter time (s): 4.181 samples/sec: 30.613
g0167:  iteration    42250/   52000 | consumed samples:      5408000 | consumed tokens:  11075584000 | elapsed time per iteration (ms): 4214.4 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.405038E-01 | loss scale: 65536.0 | grad norm: 0.169 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.372 | tokens per gpu per second (tgs): 1943.821 | TFLOPs: 15.64 |
g0156: [2024-08-12 02:40:17,172] [INFO] [logging.py:96:log_dist] [Rank 0] step=42260, skipped=61, lr=[0.00019965340858180822, 0.00019965340858180822], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42260 loss: 0.7155 iter time (s): 4.187 samples/sec: 30.569
g0167:  iteration    42260/   52000 | consumed samples:      5409280 | consumed tokens:  11078205440 | elapsed time per iteration (ms): 4220.1 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.372299E-01 | loss scale: 65536.0 | grad norm: 0.181 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.331 | tokens per gpu per second (tgs): 1941.185 | TFLOPs: 15.62 |
g0156: [2024-08-12 02:40:59,580] [INFO] [logging.py:96:log_dist] [Rank 0] step=42270, skipped=61, lr=[0.0001996531837318221, 0.0001996531837318221], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42270 loss: 0.7813 iter time (s): 4.208 samples/sec: 30.419
g0167:  iteration    42270/   52000 | consumed samples:      5410560 | consumed tokens:  11080826880 | elapsed time per iteration (ms): 4240.7 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.512487E-01 | loss scale: 65536.0 | grad norm: 0.176 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.183 | tokens per gpu per second (tgs): 1931.741 | TFLOPs: 15.55 |
g0156: [2024-08-12 02:41:39,716] [INFO] [logging.py:96:log_dist] [Rank 0] step=42280, skipped=61, lr=[0.00019965295880905765, 0.00019965295880905765], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42280 loss: 0.7487 iter time (s): 3.981 samples/sec: 32.153
g0167:  iteration    42280/   52000 | consumed samples:      5411840 | consumed tokens:  11083448320 | elapsed time per iteration (ms): 4013.8 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.420327E-01 | loss scale: 65536.0 | grad norm: 0.189 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.890 | tokens per gpu per second (tgs): 2040.967 | TFLOPs: 16.42 |
g0156: [2024-08-12 02:42:21,365] [INFO] [logging.py:96:log_dist] [Rank 0] step=42290, skipped=61, lr=[0.00019965273381351514, 0.00019965273381351514], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42290 loss: 0.7449 iter time (s): 4.132 samples/sec: 30.978
g0167:  iteration    42290/   52000 | consumed samples:      5413120 | consumed tokens:  11086069760 | elapsed time per iteration (ms): 4164.9 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.493416E-01 | loss scale: 65536.0 | grad norm: 0.152 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.733 | tokens per gpu per second (tgs): 1966.895 | TFLOPs: 15.83 |
g0156: [2024-08-12 02:43:02,992] [INFO] [logging.py:96:log_dist] [Rank 0] step=42300, skipped=61, lr=[0.00019965250874519463, 0.00019965250874519463], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42300 loss: 0.7315 iter time (s): 4.129 samples/sec: 30.999
g0167:  iteration    42300/   52000 | consumed samples:      5414400 | consumed tokens:  11088691200 | elapsed time per iteration (ms): 4162.5 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.289525E-01 | loss scale: 65536.0 | grad norm: 0.168 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.751 | tokens per gpu per second (tgs): 1968.047 | TFLOPs: 15.84 |
g0156: [2024-08-12 02:43:44,730] [INFO] [logging.py:96:log_dist] [Rank 0] step=42310, skipped=61, lr=[0.00019965228360409635, 0.00019965228360409635], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42310 loss: 0.7625 iter time (s): 4.141 samples/sec: 30.911
g0167:  iteration    42310/   52000 | consumed samples:      5415680 | consumed tokens:  11091312640 | elapsed time per iteration (ms): 4174.0 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.411340E-01 | loss scale: 65536.0 | grad norm: 0.163 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.666 | tokens per gpu per second (tgs): 1962.648 | TFLOPs: 15.79 |
g0156: [2024-08-12 02:44:27,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=42320, skipped=61, lr=[0.00019965205839022045, 0.00019965205839022045], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42320 loss: 0.7419 iter time (s): 4.269 samples/sec: 29.985
g0167:  iteration    42320/   52000 | consumed samples:      5416960 | consumed tokens:  11093934080 | elapsed time per iteration (ms): 4301.7 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.475867E-01 | loss scale: 65536.0 | grad norm: 0.161 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 29.756 | tokens per gpu per second (tgs): 1904.380 | TFLOPs: 15.32 |
g0156: [2024-08-12 02:45:09,542] [INFO] [logging.py:96:log_dist] [Rank 0] step=42330, skipped=61, lr=[0.00019965183310356713, 0.00019965183310356713], mom=[(0.9, 0.95), (0.9, 0.95)]
g0156: steps: 42330 loss: 0.7847 iter time (s): 4.147 samples/sec: 30.868
g0167:  iteration    42330/   52000 | consumed samples:      5418240 | consumed tokens:  11096555520 | elapsed time per iteration (ms): 4179.4 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 7.470355E-01 | loss scale: 65536.0 | grad norm: 0.194 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.627 | tokens per gpu per second (tgs): 1960.111 | TFLOPs: 15.77 |
