
ssh_config_file = /home/acf16449gb/.ssh/config

SSH configuration has been updated.
Host g0108
    HostName g0108
    Port 2222
    StrictHostKeyChecking no

Host g0113
    HostName g0113
    Port 2222
    StrictHostKeyChecking no

Host g0120
    HostName g0120
    Port 2222
    StrictHostKeyChecking no

Host g0121
    HostName g0121
    Port 2222
    StrictHostKeyChecking no

Host g0123
    HostName g0123
    Port 2222
    StrictHostKeyChecking no

Host g0125
    HostName g0125
    Port 2222
    StrictHostKeyChecking no

Host g0126
    HostName g0126
    Port 2222
    StrictHostKeyChecking no

Host g0127
    HostName g0127
    Port 2222
    StrictHostKeyChecking no



ucllm_nedo_dev_train_dir = /home/acf16449gb/ucllm_nedo_prod/train
megatron_deepspeed_dir = /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed

input_tokenizer_file = /groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_poly_000000_1234_True.model
output_model_dir = /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True
save_interval = 1000
wandb_entity = yohei-kobashi
wandb_project = encrypted_data_LLM
wandb_tag = other_gpu

Number of GPUs per node: 4
Both /groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_000000_1234_True_text_document.bin and /groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_000000_1234_True_text_document.idx already exist.

hostfile = ./abci_node-8_gpu-32-v100/hostfile_jobid-42829703
g0108 slots=4
g0113 slots=4
g0120 slots=4
g0121 slots=4
g0123 slots=4
g0125 slots=4
g0126 slots=4
g0127 slots=4

[2024-08-12 02:42:29,224] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 02:42:33,121] [INFO] [runner.py:463:main] Using IP address of 10.1.4.6 for node g0108
[2024-08-12 02:42:33,124] [INFO] [multinode_runner.py:72:get_cmd] Running on the following workers: g0108,g0113,g0120,g0121,g0123,g0125,g0126,g0127
[2024-08-12 02:42:33,124] [INFO] [runner.py:570:main] cmd = pdsh -S -f 1024 -w g0108,g0113,g0120,g0121,g0123,g0125,g0126,g0127 export PYTHONPATH=/home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model;  cd /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model; /home/acf16449gb/crypto_llm/train/.venv_train/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJnMDEwOCI6IFswLCAxLCAyLCAzXSwgImcwMTEzIjogWzAsIDEsIDIsIDNdLCAiZzAxMjAiOiBbMCwgMSwgMiwgM10sICJnMDEyMSI6IFswLCAxLCAyLCAzXSwgImcwMTIzIjogWzAsIDEsIDIsIDNdLCAiZzAxMjUiOiBbMCwgMSwgMiwgM10sICJnMDEyNiI6IFswLCAxLCAyLCAzXSwgImcwMTI3IjogWzAsIDEsIDIsIDNdfQ== --node_rank=%n --master_addr=10.1.4.6 --master_port=29500 /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/pretrain_gpt.py --override-opt_param-scheduler --optimizer 'adam' --adam-beta1 '0.9' --adam-beta2 '0.95' --tensor-model-parallel-size '1' --init-method-std '0.013' --lr-decay-tokens '300000000000' --lr-warmup-tokens '3000000000' --micro-batch-size '1' --exit-duration-in-mins '30000000' --global-batch-size '128' --num-layers '22' --hidden-size '2048' --ffn-hidden-size '5632' --num-attention-heads '16' --num-key-value-heads '4' --no-query-key-layer-scaling --attention-dropout '0' --hidden-dropout '0' --use-rotary-position-embeddings --untie-embeddings-and-output-weights --swiglu --normalization 'rmsnorm' --disable-bias-linear --seq-length '2048' --max-position-embeddings '2048' --train-tokens '13631488000' --train-samples '6656000' --train-data-exact-num-epochs '1' --lr '2.0e-4' --min-lr '1.0e-5' --lr-decay-style 'cosine' --split '949,50,1' --log-interval '10' --eval-interval '1000' --eval-iters '100' --save-interval '1000' --weight-decay '0.1' --clip-grad '1.0' --hysteresis '2' --num-workers '0' --seed '1234' --load '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase' --save '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase' --no-async-tensor-model-parallel-allreduce --tensorboard-queue-size '1' --log-timers-to-tensorboard --log-batch-size-to-tensorboard --log-validation-ppl-to-tensorboard --tensorboard-dir '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/tensorboard/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase_0.latin_wikipedia_poly_000000_1234_True' --log-optimizer-states-to-tensorboard --tokenizer-type 'SentencePieceTokenizer' --tokenizer-model '/groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_poly_000000_1234_True.model' --data-path '/groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_000000_1234_True_text_document' --data-impl 'mmap' --deepspeed --deepspeed_config '/groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/deepspeed_config/ds_config_gbs128_mbs1_log10_zero0.json' --zero-stage '0' --pipeline-model-parallel-size '8' --use_wandb --wandb_entity 'yohei-kobashi' --wandb_project 'encrypted_data_LLM' --wandb_group 'pretrain_gpt_1.1B_0.latin_wikipedia_poly_000000_1234_True' --wandb_tag 'other_gpu'
g0108: [2024-08-12 02:42:36,594] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0108: [2024-08-12 02:42:38,819] [INFO] [launch.py:138:main] 0 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0108: [2024-08-12 02:42:38,819] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0108: [2024-08-12 02:42:38,819] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=0
g0108: [2024-08-12 02:42:38,819] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0108: [2024-08-12 02:42:38,819] [INFO] [launch.py:163:main] dist_world_size=32
g0108: [2024-08-12 02:42:38,819] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0108: [2024-08-12 02:42:41,923] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0108: [2024-08-12 02:42:41,923] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0108: [2024-08-12 02:42:41,923] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0108: [2024-08-12 02:42:42,122] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0120: [2024-08-12 02:42:43,582] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0125: [2024-08-12 02:42:43,619] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0123: [2024-08-12 02:42:43,653] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0127: [2024-08-12 02:42:43,715] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0126: [2024-08-12 02:42:43,751] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0121: [2024-08-12 02:42:44,087] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0113: [2024-08-12 02:42:45,051] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0108: --------------------------------------------------
g0108: DeepSpeed C++/CUDA extension op report
g0108: --------------------------------------------------
g0108: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0108:       runtime if needed. Op compatibility means that your system
g0108:       meet the required dependencies to JIT install the op.
g0108: --------------------------------------------------
g0108: JIT compiled ops requires ninja
g0108: ----------------------------------------------------------------------------------------------------
g0108: 
g0108: DeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op report
g0108: 
g0108: ----------------------------------------------------------------------------------------------------
g0108: 
g0108: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0108:       runtime if needed. Op compatibility means that your system
g0108:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0108:       runtime if needed. Op compatibility means that your system
g0108:       meet the required dependencies to JIT install the op.
g0108: 
g0108: ----------------------------------------------------------------------------------------------------
g0108: 
g0108: JIT compiled ops requires ninjaJIT compiled ops requires ninja
g0108: 
g0108: --------------------------------------------------
g0108: DeepSpeed C++/CUDA extension op report
g0108: --------------------------------------------------
g0108: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0108:       runtime if needed. Op compatibility means that your system
g0108:       meet the required dependencies to JIT install the op.
g0108: --------------------------------------------------
g0108: JIT compiled ops requires ninja
g0108: ninjaninja  ....................................  [92m[OKAY][0m[92m[OKAY][0m
g0108: 
g0108: ----------------------------------------------------------------------------------------------------
g0108: 
g0108: op nameop name  ................................  installedinstalled  ....  compatiblecompatible
g0108: 
g0108: ----------------------------------------------------------------------------------------------------
g0108: 
g0108: ninja .................. [92m[OKAY][0m
g0108: --------------------------------------------------
g0108: op name ................ installed .. compatible
g0108: --------------------------------------------------
g0108: ninja .................. [92m[OKAY][0m
g0108: --------------------------------------------------
g0108: op name ................ installed .. compatible
g0108: --------------------------------------------------
g0108: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0108: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0108: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0108: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0108: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0108: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0108: fused_adam ............. [92m[YES][0m ...... async_io[92m[OKAY][0m 
g0108: ............... [92m[YES][0mcpu_adam  .....................  [92m[OKAY][0m[92m[YES][0m
g0108:  ...... [92m[OKAY][0m
g0108: fused_adamcpu_adagrad  .........................  [92m[YES][0m [92m[YES][0m...... async_io ...... [92m[OKAY][0m ...............
g0108:  [92m[OKAY][0m[92m[YES][0m
g0108:  ......cpu_adamcpu_lion   [92m[OKAY][0m..............................
g0108:   [92m[YES][0m[92m[YES][0m  ............fused_adam   [92m[OKAY][0m[92m[OKAY][0m.............
g0108: 
g0108:  [92m[YES][0m ......cpu_adagrad  [92m[OKAY][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH............
g0108: 
g0108:  [92m[YES][0m evoformer_attncpu_adam......   ........................[92m[OKAY][0m  
g0108: [93m[NO][0m[92m[YES][0m cpu_lion ....... ...... ...............[93m[NO][0m  
g0108: [92m[OKAY][0m[92m[YES][0m
g0108:  fused_lamb......cpu_adagrad   .............[92m[OKAY][0m............ 
g0108:  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[OKAY][0m
g0108: 
g0108: 
g0108: evoformer_attn cpu_lion.........  ...............[93m[NO][0mfused_lion   [92m[YES][0m....................   ......[93m[NO][0m[92m[YES][0m 
g0108:  [92m[OKAY][0m......
g0108:  fused_lamb[92m[OKAY][0m 
g0108: ............. [92m[YES][0m ......[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0108: [92m[OKAY][0m
g0108: evoformer_attn ......... [93m[NO][0m .......fused_lion  [93m[NO][0m.............
g0108:  [92m[YES][0m ...... fused_lamb[92m[OKAY][0m 
g0108: ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: inference_core_ops ..... [92m[YES][0m ...... inference_core_ops[92m[OKAY][0minference_core_ops 
g0108:  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0108: 
g0108: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0108: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0108: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0108: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0108: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0108: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0108: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0108: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0108: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0108: sparse_attnragged_ops  .........................  [93m[NO][0m[92m[YES][0m  .............  [93m[NO][0m[92m[OKAY][0m
g0108: 
g0108: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0108: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0108: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0108: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0108: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0108: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0108: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0108: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0108: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0108: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0108: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0108: --------------------------------------------------
g0108: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0108: --------------------------------------------------
g0108: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0108: --------------------------------------------------
g0108: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0108: --------------------------------------------------
g0108: DeepSpeed general environment info:
g0108: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0108: torch version .................... 2.0.1+cu118
g0108: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0108: deepspeed info ................... 0.12.4, unknown, unknown
g0108: torch cuda version ............... 11.8
g0108: torch hip version ................ None
g0108: nvcc version ..................... 11.8
g0108: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0108: shared memory (/dev/shm) size .... 188.13 GB
g0108: DeepSpeed general environment info:
g0108: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0108: torch version .................... 2.0.1+cu118
g0108: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0108: deepspeed info ................... 0.12.4, unknown, unknown
g0108: torch cuda version ............... 11.8
g0108: torch hip version ................ None
g0108: nvcc version ..................... 11.8
g0108: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0108: shared memory (/dev/shm) size .... 188.13 GB
g0108: DeepSpeed general environment info:
g0108: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0108: torch version .................... 2.0.1+cu118
g0108: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0108: deepspeed info ................... 0.12.4, unknown, unknown
g0108: torch cuda version ............... 11.8
g0108: torch hip version ................ None
g0108: nvcc version ..................... 11.8
g0108: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0108: shared memory (/dev/shm) size .... 188.13 GB
g0108: DeepSpeed general environment info:
g0108: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0108: torch version .................... 2.0.1+cu118
g0108: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0108: deepspeed info ................... 0.12.4, unknown, unknown
g0108: torch cuda version ............... 11.8
g0108: torch hip version ................ None
g0108: nvcc version ..................... 11.8
g0108: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0108: shared memory (/dev/shm) size .... 188.13 GB
g0108: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0108: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0108: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0108: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0108: using world size: 32, data-parallel-size: 4, sequence-parallel size: 1, tensor-model-parallel size: 1, pipeline-model-parallel size: 8 
g0108: WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:SentencePieceTokenizer
g0108: using torch.float32 for parameters ...
g0108: ------------------------ arguments ------------------------
g0108:   accumulate_allreduce_grads_in_fp32 .............. False
g0108:   adam_beta1 ...................................... 0.9
g0108:   adam_beta2 ...................................... 0.95
g0108:   adam_eps ........................................ 1e-08
g0108:   add_bias_linear ................................. False
g0108:   add_position_embedding .......................... False
g0108:   adlr_autoresume ................................. False
g0108:   adlr_autoresume_interval ........................ 1000
g0108:   aml_data_download_path .......................... None
g0108:   apply_layernorm_1p .............................. False
g0108:   apply_query_key_layer_scaling ................... False
g0108:   apply_residual_connection_post_layernorm ........ False
g0108:   async_tensor_model_parallel_allreduce ........... False
g0108:   attention_dropout ............................... 0.0
g0108:   attention_softmax_in_fp32 ....................... False
g0108:   barrier_with_L1_time ............................ True
g0108:   bert_binary_head ................................ True
g0108:   bert_embedder_type .............................. megatron
g0108:   bert_load ....................................... None
g0108:   bf16 ............................................ False
g0108:   bias_dropout_fusion ............................. True
g0108:   bias_gelu_fusion ................................ False
g0108:   biencoder_projection_dim ........................ 0
g0108:   biencoder_shared_query_context_model ............ False
g0108:   block_data_path ................................. None
g0108:   checkpoint_activations .......................... False
g0108:   checkpoint_in_cpu ............................... False
g0108:   checkpoint_num_layers ........................... 1
g0108:   classes_fraction ................................ 1.0
g0108:   clip_grad ....................................... 1.0
g0108:   compression_training ............................ False
g0108:   consumed_train_samples .......................... 0
g0108:   consumed_train_tokens ........................... 0
g0108:   consumed_valid_samples .......................... 0
g0108:   contigious_checkpointing ........................ False
g0108:   cpu_optimizer ................................... False
g0108:   cpu_torch_adam .................................. False
g0108:   create_moe_param_group .......................... False
g0108:   curriculum_learning_legacy ...................... False
g0108:   data_cache_path ................................. None
g0108:   data_efficiency_curriculum_learning ............. False
g0108:   data_impl ....................................... mmap
g0108:   data_parallel_random_init ....................... False
g0108:   data_parallel_size .............................. 4
g0108:   data_path ....................................... ['/groups/gcf51099/crypto_llm/data/wikipedia_latin_poly_000000_1234_True_text_document']
g0108:   data_per_class_fraction ......................... 1.0
g0108:   data_sharding ................................... True
g0108:   dataloader_type ................................. single
g0108:   DDP_impl ........................................ local
g0108:   decoder_num_layers .............................. None
g0108:   decoder_seq_length .............................. None
g0108:   deepscale ....................................... False
g0108:   deepscale_config ................................ None
g0108:   deepspeed ....................................... True
g0108:   deepspeed_activation_checkpointing .............. False
g0108:   deepspeed_config ................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/deepspeed_config/ds_config_gbs128_mbs1_log10_zero0.json
g0108:   deepspeed_mpi ................................... False
g0108:   dino_bottleneck_size ............................ 256
g0108:   dino_freeze_last_layer .......................... 1
g0108:   dino_head_hidden_size ........................... 2048
g0108:   dino_local_crops_number ......................... 10
g0108:   dino_local_img_size ............................. 96
g0108:   dino_norm_last_layer ............................ False
g0108:   dino_teacher_temp ............................... 0.07
g0108:   dino_warmup_teacher_temp ........................ 0.04
g0108:   dino_warmup_teacher_temp_epochs ................. 30
g0108:   distribute_checkpointed_activations ............. False
g0108:   distribute_saved_activations .................... False
g0108:   distributed_backend ............................. nccl
g0108:   distributed_timeout_minutes ..................... 10
g0108:   ds_fused_adam ................................... False
g0108:   ds_inference .................................... False
g0108:   ds_pipeline_enabled ............................. True
g0108:   ds_sequence_parallel_size ....................... 1
g0108:   embedding_path .................................. None
g0108:   embedding_weights_in_fp32 ....................... False
g0108:   empty_unused_memory_level ....................... 0
g0108:   enable_expert_tensor_parallelism ................ False
g0108:   encoder_num_layers .............................. 22
g0108:   encoder_seq_length .............................. 2048
g0108:   end_weight_decay ................................ 0.1
g0108:   eod_mask_loss ................................... False
g0108:   eval_interval ................................... 1000
g0108:   eval_iters ...................................... 100
g0108:   evidence_data_path .............................. None
g0108:   exit_duration_in_mins ........................... 30000000
g0108:   exit_interval ................................... None
g0108:   exit_on_missing_checkpoint ...................... False
g0108:   exit_signal_handler ............................. False
g0108:   expert_interval ................................. 2
g0108:   ffn_hidden_size ................................. 5632
g0108:   finetune ........................................ False
g0108:   force_ds_sequence_parallel ...................... False
g0108:   fp16 ............................................ False
g0108:   fp16_lm_cross_entropy ........................... False
g0108:   fp32_residual_connection ........................ False
g0108:   fp8_amax_compute_algo ........................... most_recent
g0108:   fp8_amax_history_len ............................ 1
g0108:   fp8_e4m3 ........................................ False
g0108:   fp8_hybrid ...................................... False
g0108:   fp8_interval .................................... 1
g0108:   fp8_margin ...................................... 0
g0108:   fp8_wgrad ....................................... True
g0108:   global_batch_size ............................... 128
g0108:   gradient_accumulation_fusion .................... True
g0108:   head_lr_mult .................................... 1.0
g0108:   hidden_dropout .................................. 0.0
g0108:   hidden_size ..................................... 2048
g0108:   hidden_size_teacher ............................. None
g0108:   hysteresis ...................................... 2
g0108:   ict_head_size ................................... None
g0108:   ict_load ........................................ None
g0108:   img_h ........................................... 224
g0108:   img_w ........................................... 224
g0108:   indexer_batch_size .............................. 128
g0108:   indexer_log_interval ............................ 1000
g0108:   inference ....................................... False
g0108:   inference_batch_times_seqlen_threshold .......... 512
g0108:   init_method_std ................................. 0.013
g0108:   init_method_xavier_uniform ...................... False
g0108:   initial_loss_scale .............................. 4294967296
g0108:   iter_per_epoch .................................. 1250
g0108:   kd .............................................. False
g0108:   kd_alpha_ce ..................................... 1
g0108:   kd_beta_ce ...................................... 1
g0108:   kd_temp ......................................... 1.0
g0108:   kv_channels ..................................... 128
g0108:   layernorm_epsilon ............................... 1e-05
g0108:   lazy_mpu_init ................................... None
g0108:   load ............................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase
g0108:   load_teacher .................................... None
g0108:   local_rank ...................................... 0
g0108:   log_batch_size_to_tensorboard ................... True
g0108:   log_interval .................................... 10
g0108:   log_learning_rate_to_tensorboard ................ True
g0108:   log_loss_scale_to_tensorboard ................... True
g0108:   log_memory_to_tensorboard ....................... False
g0108:   log_num_zeros_in_grad ........................... False
g0108:   log_optimizer_states_to_tensorboard ............. True
g0108:   log_params_norm ................................. False
g0108:   log_timers_to_tensorboard ....................... True
g0108:   log_validation_ppl_to_tensorboard ............... True
g0108:   log_world_size_to_tensorboard ................... False
g0108:   loss_scale ...................................... None
g0108:   loss_scale_window ............................... 1000
g0108:   lr .............................................. 0.0002
g0108:   lr_decay_iters .................................. None
g0108:   lr_decay_samples ................................ None
g0108:   lr_decay_style .................................. cosine
g0108:   lr_decay_tokens ................................. 300000000000
g0108:   lr_warmup_fraction .............................. None
g0108:   lr_warmup_iters ................................. 0
g0108:   lr_warmup_samples ............................... 0
g0108:   lr_warmup_tokens ................................ 3000000000
g0108:   make_vocab_size_divisible_by .................... 128
g0108:   mask_factor ..................................... 1.0
g0108:   mask_prob ....................................... 0.15
g0108:   mask_type ....................................... random
g0108:   masked_softmax_fusion ........................... True
g0108:   max_position_embeddings ......................... 2048
g0108:   max_tokens_to_oom ............................... 12000
g0108:   mem_efficient_ln ................................ True
g0108:   memory_centric_tiled_linear ..................... False
g0108:   merge_file ...................................... None
g0108:   micro_batch_size ................................ 1
g0108:   min_loss_scale .................................. 1.0
g0108:   min_lr .......................................... 1e-05
g0108:   mlp_type ........................................ standard
g0108:   mmap_warmup ..................................... False
g0108:   moe_eval_capacity_factor ........................ 1.0
g0108:   moe_expert_parallel_size ........................ 1
g0108:   moe_loss_coeff .................................. 0.1
g0108:   moe_min_capacity ................................ 4
g0108:   moe_token_dropping .............................. True
g0108:   moe_train_capacity_factor ....................... 1.0
g0108:   mos ............................................. False
g0108:   no_load_lr_state ................................ False
g0108:   no_load_optim ................................... None
g0108:   no_load_rng ..................................... None
g0108:   no_persist_layer_norm ........................... False
g0108:   no_pipeline_parallel ............................ False
g0108:   no_save_optim ................................... None
g0108:   no_save_rng ..................................... None
g0108:   normalization ................................... rmsnorm
g0108:   num_attention_heads ............................. 16
g0108:   num_attention_heads_teacher ..................... None
g0108:   num_channels .................................... 3
g0108:   num_classes ..................................... 1000
g0108:   num_experts ..................................... [1]
g0108:   num_experts_switch .............................. None
g0108:   num_experts_teacher ............................. [1]
g0108:   num_key_value_heads ............................. 4
g0108:   num_layers ...................................... 22
g0108:   num_layers_per_virtual_pipeline_stage ........... None
g0108:   num_layers_teacher .............................. None
g0108:   num_workers ..................................... 0
g0108:   onnx_safe ....................................... None
g0108:   openai_gelu ..................................... False
g0108:   optimizer ....................................... adam
g0108:   output_bert_embeddings .......................... False
g0108:   overlap_p2p_comm ................................ False
g0108:   override_opt_param_scheduler .................... True
g0108:   params_dtype .................................... torch.float32
g0108:   partition_activations ........................... False
g0108:   patch_dim ....................................... 16
g0108:   perform_initialization .......................... True
g0108:   pipeline_model_parallel_size .................... 8
g0108:   pipeline_model_parallel_split_rank .............. None
g0108:   profile_backward ................................ False
g0108:   query_in_block_prob ............................. 0.1
g0108:   rampup_batch_size ............................... None
g0108:   random_ltd ...................................... False
g0108:   rank ............................................ 0
g0108:   recompute_granularity ........................... None
g0108:   recompute_method ................................ None
g0108:   recompute_num_layers ............................ 1
g0108:   remote_device ................................... none
g0108:   repeated_dataloader ............................. False
g0108:   reset_attention_mask ............................ False
g0108:   reset_iteration ................................. False
g0108:   reset_position_ids .............................. False
g0108:   retriever_report_topk_accuracies ................ []
g0108:   retriever_score_scaling ......................... False
g0108:   retriever_seq_length ............................ 256
g0108:   retro_add_retriever ............................. False
g0108:   retro_cyclic_train_iters ........................ None
g0108:   retro_encoder_attention_dropout ................. 0.1
g0108:   retro_encoder_hidden_dropout .................... 0.1
g0108:   retro_encoder_layers ............................ 2
g0108:   retro_num_neighbors ............................. 2
g0108:   retro_num_retrieved_chunks ...................... 2
g0108:   retro_return_doc_ids ............................ False
g0108:   retro_workdir ................................... None
g0108:   return_data_index ............................... False
g0108:   rotary_percent .................................. 1.0
g0108:   sample_rate ..................................... 1.0
g0108:   save ............................................ /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase
g0108:   save_interval ................................... 1000
g0108:   scatter_gather_tensors_in_pipeline .............. True
g0108:   scattered_embeddings ............................ False
g0108:   seed ............................................ 1234
g0108:   seq_length ...................................... 2048
g0108:   sequence_parallel ............................... False
g0108:   sgd_momentum .................................... 0.9
g0108:   short_seq_prob .................................. 0.1
g0108:   skip_train ...................................... False
g0108:   split ........................................... 949,50,1
g0108:   split_transformers .............................. False
g0108:   squared_relu .................................... False
g0108:   standalone_embedding_stage ...................... False
g0108:   start_weight_decay .............................. 0.1
g0108:   swiglu .......................................... True
g0108:   swin_backbone_type .............................. tiny
g0108:   synchronize_each_layer .......................... False
g0108:   tensor_model_parallel_size ...................... 1
g0108:   tensorboard_dir ................................. /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/tensorboard/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase_0.latin_wikipedia_poly_000000_1234_True
g0108:   tensorboard_log_interval ........................ 1
g0108:   tensorboard_queue_size .......................... 1
g0108:   test_data_path .................................. None
g0108:   tf32 ............................................ False
g0108:   tile_factor ..................................... 1
g0108:   timing_log_level ................................ 0
g0108:   timing_log_option ............................... minmax
g0108:   titles_data_path ................................ None
g0108:   tokenizer_model ................................. /groups/gcf51099/crypto_llm/tokenizers/tokenizer_wikipedia_latin_poly_000000_1234_True.model
g0108:   tokenizer_type .................................. SentencePieceTokenizer
g0108:   topk ............................................ 1
g0108:   train_data_exact_num_epochs ..................... 1
g0108:   train_data_path ................................. None
g0108:   train_desc_path ................................. None
g0108:   train_doc_idx_path .............................. None
g0108:   train_idx_path .................................. None
g0108:   train_iters ..................................... None
g0108:   train_sample_idx_path ........................... None
g0108:   train_samples ................................... 6656000
g0108:   train_shuffle_idx_path .......................... None
g0108:   train_tokens .................................... 13631488000
g0108:   transformer_impl ................................ local
g0108:   transformer_pipeline_model_parallel_size ........ 8
g0108:   universal_checkpoint ............................ False
g0108:   untie_embeddings_and_output_weights ............. True
g0108:   use_checkpoint_args ............................. False
g0108:   use_checkpoint_opt_param_scheduler .............. False
g0108:   use_contiguous_buffers_in_local_ddp ............. True
g0108:   use_cpu_initialization .......................... None
g0108:   use_dataset_only ................................ False
g0108:   use_distributed_optimizer ....................... False
g0108:   use_flash_attn .................................. False
g0108:   use_flash_attn_triton ........................... False
g0108:   use_flash_attn_v1 ............................... False
g0108:   use_flash_attn_v2 ............................... False
g0108:   use_one_sent_docs ............................... False
g0108:   use_pin_memory .................................. False
g0108:   use_ring_exchange_p2p ........................... False
g0108:   use_rotary_position_embeddings .................. True
g0108:   use_tutel ....................................... False
g0108:   use_wandb ....................................... True
g0108:   valid_data_path ................................. None
g0108:   variable_seq_lengths ............................ False
g0108:   virtual_pipeline_model_parallel_size ............ None
g0108:   vision_backbone_type ............................ vit
g0108:   vision_pretraining .............................. False
g0108:   vision_pretraining_type ......................... classify
g0108:   vocab_extra_ids ................................. 0
g0108:   vocab_file ...................................... None
g0108:   vocab_size ...................................... None
g0108:   wandb_entity .................................... yohei-kobashi
g0108:   wandb_group ..................................... pretrain_gpt_1.1B_0.latin_wikipedia_poly_000000_1234_True
g0108:   wandb_project ................................... encrypted_data_LLM
g0108:   wandb_tag ....................................... other_gpu
g0108:   weight_decay .................................... 0.1
g0108:   weight_decay_incr_style ......................... constant
g0108:   world_size ...................................... 32
g0108:   zero_allgather_bucket_size ...................... 0.0
g0108:   zero_contigious_gradients ....................... False
g0108:   zero_reduce_bucket_size ......................... 0.0
g0108:   zero_reduce_scatter ............................. False
g0108:   zero_stage ...................................... 0
g0108: -------------------- end of arguments ---------------------
g0108: setting number of micro-batches to constant 32
g0108: > building SentencePieceTokenizer tokenizer ...
g0108: [2024-08-12 02:42:46,501] [INFO] [comm.py:637:init_distributed] cdb=None
g0108: [2024-08-12 02:42:46,501] [INFO] [comm.py:637:init_distributed] cdb=None
g0108:  > padded vocab (size: 32003) with 125 dummy tokens (new size: 32128)
g0108: > initializing torch distributed ...
g0108: [2024-08-12 02:42:46,503] [INFO] [comm.py:637:init_distributed] cdb=None
g0108: [2024-08-12 02:42:46,503] [INFO] [comm.py:637:init_distributed] cdb=None
g0108: [2024-08-12 02:42:46,503] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
g0108: [W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [2024-08-12 02:42:47,687] [INFO] [launch.py:138:main] 2 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0120: [2024-08-12 02:42:47,687] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0120: [2024-08-12 02:42:47,687] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=2
g0120: [2024-08-12 02:42:47,688] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0120: [2024-08-12 02:42:47,688] [INFO] [launch.py:163:main] dist_world_size=32
g0120: [2024-08-12 02:42:47,688] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0127: [2024-08-12 02:42:47,689] [INFO] [launch.py:138:main] 7 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0127: [2024-08-12 02:42:47,689] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0127: [2024-08-12 02:42:47,689] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=7
g0127: [2024-08-12 02:42:47,689] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0127: [2024-08-12 02:42:47,690] [INFO] [launch.py:163:main] dist_world_size=32
g0127: [2024-08-12 02:42:47,690] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0125: [2024-08-12 02:42:47,734] [INFO] [launch.py:138:main] 5 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0125: [2024-08-12 02:42:47,734] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0125: [2024-08-12 02:42:47,734] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=5
g0125: [2024-08-12 02:42:47,734] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0125: [2024-08-12 02:42:47,734] [INFO] [launch.py:163:main] dist_world_size=32
g0125: [2024-08-12 02:42:47,734] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0123: [2024-08-12 02:42:47,761] [INFO] [launch.py:138:main] 4 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0123: [2024-08-12 02:42:47,761] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0123: [2024-08-12 02:42:47,761] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=4
g0123: [2024-08-12 02:42:47,761] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0123: [2024-08-12 02:42:47,761] [INFO] [launch.py:163:main] dist_world_size=32
g0123: [2024-08-12 02:42:47,761] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0126: [2024-08-12 02:42:47,857] [INFO] [launch.py:138:main] 6 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0126: [2024-08-12 02:42:47,857] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0126: [2024-08-12 02:42:47,857] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=6
g0126: [2024-08-12 02:42:47,857] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0126: [2024-08-12 02:42:47,857] [INFO] [launch.py:163:main] dist_world_size=32
g0126: [2024-08-12 02:42:47,857] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0121: [2024-08-12 02:42:48,309] [INFO] [launch.py:138:main] 3 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0121: [2024-08-12 02:42:48,309] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0121: [2024-08-12 02:42:48,309] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=3
g0121: [2024-08-12 02:42:48,309] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0121: [2024-08-12 02:42:48,309] [INFO] [launch.py:163:main] dist_world_size=32
g0121: [2024-08-12 02:42:48,309] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0113: [2024-08-12 02:42:49,199] [INFO] [launch.py:138:main] 1 HPCX_NCCL_RDMA_SHARP_PLUGIN_DIR=/apps/rocky8/hpcx/2.12/nccl_rdma_sharp_plugin
g0113: [2024-08-12 02:42:49,199] [INFO] [launch.py:145:main] WORLD INFO DICT: {'g0108': [0, 1, 2, 3], 'g0113': [0, 1, 2, 3], 'g0120': [0, 1, 2, 3], 'g0121': [0, 1, 2, 3], 'g0123': [0, 1, 2, 3], 'g0125': [0, 1, 2, 3], 'g0126': [0, 1, 2, 3], 'g0127': [0, 1, 2, 3]}
g0113: [2024-08-12 02:42:49,199] [INFO] [launch.py:151:main] nnodes=8, num_local_procs=4, node_rank=1
g0113: [2024-08-12 02:42:49,199] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'g0108': [0, 1, 2, 3], 'g0113': [4, 5, 6, 7], 'g0120': [8, 9, 10, 11], 'g0121': [12, 13, 14, 15], 'g0123': [16, 17, 18, 19], 'g0125': [20, 21, 22, 23], 'g0126': [24, 25, 26, 27], 'g0127': [28, 29, 30, 31]})
g0113: [2024-08-12 02:42:49,199] [INFO] [launch.py:163:main] dist_world_size=32
g0113: [2024-08-12 02:42:49,199] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
g0127: [2024-08-12 02:42:50,834] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0127: [2024-08-12 02:42:50,841] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0125: [2024-08-12 02:42:50,858] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0125: [2024-08-12 02:42:50,858] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0125: [2024-08-12 02:42:50,859] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0120: [2024-08-12 02:42:50,860] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0120: [2024-08-12 02:42:50,860] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0120: [2024-08-12 02:42:50,860] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0125: [2024-08-12 02:42:50,865] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0127: [2024-08-12 02:42:50,886] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0126: [2024-08-12 02:42:50,927] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0126: [2024-08-12 02:42:50,930] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0127: [2024-08-12 02:42:50,944] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0123: [2024-08-12 02:42:50,945] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0123: [2024-08-12 02:42:50,946] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0123: [2024-08-12 02:42:50,955] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0126: [2024-08-12 02:42:50,956] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0120: [2024-08-12 02:42:50,990] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0123: [2024-08-12 02:42:51,026] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0126: [2024-08-12 02:42:51,128] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0121: [2024-08-12 02:42:51,404] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0121: [2024-08-12 02:42:51,404] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0121: [2024-08-12 02:42:51,460] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0121: [2024-08-12 02:42:51,539] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0113: [2024-08-12 02:42:52,394] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0113: [2024-08-12 02:42:52,395] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0113: [2024-08-12 02:42:52,395] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0113: [2024-08-12 02:42:52,478] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
g0127: --------------------------------------------------
g0127: DeepSpeed C++/CUDA extension op report
g0127: --------------------------------------------------
g0127: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0127:       runtime if needed. Op compatibility means that your system
g0127:       meet the required dependencies to JIT install the op.
g0127: --------------------------------------------------
g0127: JIT compiled ops requires ninja
g0127: --------------------------------------------------
g0127: DeepSpeed C++/CUDA extension op report
g0127: --------------------------------------------------
g0127: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0127:       runtime if needed. Op compatibility means that your system
g0127:       meet the required dependencies to JIT install the op.
g0127: --------------------------------------------------
g0127: JIT compiled ops requires ninja
g0127: --------------------------------------------------
g0127: DeepSpeed C++/CUDA extension op report
g0127: --------------------------------------------------
g0127: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0127:       runtime if needed. Op compatibility means that your system
g0127:       meet the required dependencies to JIT install the op.
g0127: --------------------------------------------------
g0127: JIT compiled ops requires ninja
g0127: --------------------------------------------------
g0127: DeepSpeed C++/CUDA extension op report
g0127: --------------------------------------------------
g0127: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0127:       runtime if needed. Op compatibility means that your system
g0127:       meet the required dependencies to JIT install the op.
g0127: --------------------------------------------------
g0127: JIT compiled ops requires ninja
g0127: ninjaninja  ninja....................................   [92m[OKAY][0m[92m[OKAY][0m..................
g0127: 
g0127:  [92m[OKAY][0m----------------------------------------------------------------------------------------------------
g0127: 
g0127: 
g0127: --------------------------------------------------op nameop name
g0127:   ................op name................   installed................installed  ..installed   ..compatible.. 
g0127:  compatiblecompatible--------------------------------------------------
g0127: 
g0127: 
g0127: ----------------------------------------------------------------------------------------------------
g0127: 
g0127: ninja .................. [92m[OKAY][0m
g0127: --------------------------------------------------
g0127: op name ................ installed .. compatible
g0127: --------------------------------------------------
g0126: --------------------------------------------------
g0126: DeepSpeed C++/CUDA extension op report
g0126: --------------------------------------------------
g0126: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0126:       runtime if needed. Op compatibility means that your system
g0126:       meet the required dependencies to JIT install the op.
g0126: --------------------------------------------------
g0126: JIT compiled ops requires ninja
g0126: --------------------------------------------------
g0126: DeepSpeed C++/CUDA extension op report
g0126: --------------------------------------------------
g0126: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0126:       runtime if needed. Op compatibility means that your system
g0126:       meet the required dependencies to JIT install the op.
g0126: --------------------------------------------------
g0126: JIT compiled ops requires ninja
g0126: --------------------------------------------------
g0126: DeepSpeed C++/CUDA extension op report
g0126: --------------------------------------------------
g0126: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0126:       runtime if needed. Op compatibility means that your system
g0126:       meet the required dependencies to JIT install the op.
g0126: --------------------------------------------------
g0126: JIT compiled ops requires ninja
g0126: --------------------------------------------------
g0126: DeepSpeed C++/CUDA extension op report
g0126: --------------------------------------------------
g0126: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0126:       runtime if needed. Op compatibility means that your system
g0126:       meet the required dependencies to JIT install the op.
g0126: --------------------------------------------------
g0126: JIT compiled ops requires ninja
g0126: ninjaninjaninja ninja ..................  .................. ..................[92m[OKAY][0m ..................
g0126:  [92m[OKAY][0m [92m[OKAY][0m
g0126: --------------------------------------------------[92m[OKAY][0m
g0126: 
g0126: --------------------------------------------------
g0126: op name
g0126:  ----------------------------------------------------------------------------------------------------................op name
g0126:   
g0126: installed................op name  op name installed.. ................  ................ .. compatibleinstalled installed
g0126:  compatible ..--------------------------------------------------
g0126:  
g0126: ..--------------------------------------------------compatible
g0126:  
g0126: compatible--------------------------------------------------
g0126: 
g0126: --------------------------------------------------
g0125: --------------------------------------------------
g0125: DeepSpeed C++/CUDA extension op report
g0125: --------------------------------------------------
g0125: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0125:       runtime if needed. Op compatibility means that your system
g0125:       meet the required dependencies to JIT install the op.
g0125: --------------------------------------------------
g0125: JIT compiled ops requires ninja
g0125: --------------------------------------------------
g0125: DeepSpeed C++/CUDA extension op report
g0125: --------------------------------------------------
g0125: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0125:       runtime if needed. Op compatibility means that your system
g0125:       meet the required dependencies to JIT install the op.
g0125: --------------------------------------------------
g0125: JIT compiled ops requires ninja
g0125: --------------------------------------------------
g0125: DeepSpeed C++/CUDA extension op report
g0125: --------------------------------------------------
g0125: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0125:       runtime if needed. Op compatibility means that your system
g0125:       meet the required dependencies to JIT install the op.
g0125: --------------------------------------------------
g0125: JIT compiled ops requires ninja
g0125: --------------------------------------------------
g0125: DeepSpeed C++/CUDA extension op report
g0125: --------------------------------------------------
g0125: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0125:       runtime if needed. Op compatibility means that your system
g0125:       meet the required dependencies to JIT install the op.
g0125: --------------------------------------------------
g0125: JIT compiled ops requires ninja
g0125: ninjaninjaninja ninja  ......................................................    ..................[92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m 
g0125: 
g0125: 
g0125: [92m[OKAY][0m
g0125: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0125: 
g0125: 
g0125: --------------------------------------------------
g0125: op nameop nameop name   op name................................................    ................installedinstalledinstalled    installed......    ..compatible compatiblecompatible
g0125: compatible
g0125: 
g0125: 
g0125: --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
g0125: 
g0125: 
g0125: 
g0120: ----------------------------------------------------------------------------------------------------
g0120: 
g0120: DeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op report
g0120: 
g0120: ----------------------------------------------------------------------------------------------------
g0120: 
g0120: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0120:       runtime if needed. Op compatibility means that your system
g0120:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0120:       runtime if needed. Op compatibility means that your system
g0120:       meet the required dependencies to JIT install the op.
g0120: 
g0120: ------------------------------------------------------------------------------------------------------------------------------------------------------
g0120: 
g0120: JIT compiled ops requires ninjaJIT compiled ops requires ninja
g0120: 
g0120: 
g0120: DeepSpeed C++/CUDA extension op report
g0120: --------------------------------------------------
g0120: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0120:       runtime if needed. Op compatibility means that your system
g0120:       meet the required dependencies to JIT install the op.
g0120: --------------------------------------------------
g0120: JIT compiled ops requires ninja
g0120: --------------------------------------------------
g0120: DeepSpeed C++/CUDA extension op report
g0120: --------------------------------------------------
g0120: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0120:       runtime if needed. Op compatibility means that your system
g0120:       meet the required dependencies to JIT install the op.
g0120: --------------------------------------------------
g0120: JIT compiled ops requires ninja
g0120: ninjaninjaninjaninja    ...................................................... ..................  [92m[OKAY][0m [92m[OKAY][0m[92m[OKAY][0m
g0120: [92m[OKAY][0m
g0120: 
g0120: 
g0120: ----------------------------------------------------------------------------------------------------
g0120: ----------------------------------------------------------------------------------------------------
g0120: 
g0120: 
g0120: op nameop name op nameop name ................  ................ ................................ installed  installed installedinstalled ..  .. .... compatible  compatible
g0120: compatiblecompatible
g0120: 
g0120: --------------------------------------------------
g0120: --------------------------------------------------
g0120: --------------------------------------------------
g0120: --------------------------------------------------
g0120: 
g0126: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0126: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0126: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0126: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0126: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0126: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0126: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0126: fused_adam ............. [92m[YES][0masync_io ......  ...............[92m[OKAY][0m 
g0126: [92m[YES][0m ......cpu_adam [92m[OKAY][0m 
g0126: ............... [92m[YES][0m ...... [92m[OKAY][0m
g0126: fused_adam cpu_adagrad.............  ............[92m[YES][0m  [92m[YES][0masync_io......  ...... [92m[OKAY][0m ...............[92m[OKAY][0m
g0126:  
g0126: [92m[YES][0m cpu_lion......cpu_adam   [92m[OKAY][0m..............................
g0126:   [92m[YES][0m[92m[YES][0m  ............fused_adam   [92m[OKAY][0m[92m[OKAY][0m.............
g0126: 
g0126:  [92m[YES][0mcpu_adagrad  ..................  [92m[OKAY][0m[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[YES][0m
g0126:  
g0126: ......evoformer_attn cpu_adam[92m[OKAY][0m  
g0126: ........................  cpu_lion[92m[YES][0m  [93m[NO][0m.....................   .......[92m[YES][0m[92m[OKAY][0m  
g0126: [93m[NO][0m......
g0126:  fused_lamb cpu_adagrad.............[92m[OKAY][0m  ............
g0126: [92m[YES][0m  ......[92m[YES][0m  [92m[OKAY][0m......
g0126: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0126: [92m[OKAY][0m
g0126: evoformer_attn .........cpu_lion fused_lion [93m[NO][0m...............  [92m[YES][0m ...... ....... ............. [92m[OKAY][0m [93m[NO][0m
g0126: [92m[YES][0m
g0126:  ...... fused_lamb[92m[OKAY][0m 
g0126: .............[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0126: [92m[YES][0m evoformer_attn......  .........[92m[OKAY][0m 
g0126: [93m[NO][0m ....... [93m[NO][0m
g0126: fused_lionfused_lamb  ..........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0126: 
g0126: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0126: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0126: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0126: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0126: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0126: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0126: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0126: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0126: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0126: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0126: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0mragged_device_ops
g0126:  ...... [92m[YES][0m ...... [92m[OKAY][0m
g0126: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0126: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0126: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0126: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0126: ragged_ops ............. [92m[YES][0m ragged_ops......  [92m[OKAY][0m
g0126: ............. [92m[YES][0mrandom_ltd  ...................  [92m[YES][0m[92m[OKAY][0m ......
g0126:  [92m[OKAY][0m
g0126: random_ltd ............. [92m[YES][0m [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0......
g0126:  [92m[OKAY][0m
g0126: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0126: sparse_attn ............ [93m[NO][0m [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0.......
g0126:  [93m[NO][0m
g0126: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0126: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0126: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0126: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0126: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0126: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0126: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0126: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0126: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0126: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0126: spatial_inferencespatial_inference  ............  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0126: 
g0126: transformertransformer ............  ............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0126: [92m[OKAY][0m
g0126: stochastic_transformer .stochastic_transformer  [92m[YES][0m.  ......[92m[YES][0m  [92m[OKAY][0m......
g0126:  [92m[OKAY][0m
g0126: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0126: --------------------------------------------------
g0126: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0126: --------------------------------------------------
g0126: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0126: --------------------------------------------------
g0126: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0126: --------------------------------------------------
g0126: DeepSpeed general environment info:
g0126: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0126: torch version .................... 2.0.1+cu118
g0126: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0126: deepspeed info ................... 0.12.4, unknown, unknown
g0126: torch cuda version ............... 11.8
g0126: torch hip version ................ None
g0126: nvcc version ..................... 11.8
g0126: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0126: shared memory (/dev/shm) size .... 188.13 GB
g0126: DeepSpeed general environment info:
g0126: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0126: torch version .................... 2.0.1+cu118
g0126: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0126: deepspeed info ................... 0.12.4, unknown, unknown
g0126: torch cuda version ............... 11.8
g0126: torch hip version ................ None
g0126: nvcc version ..................... 11.8
g0126: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0126: shared memory (/dev/shm) size .... 188.13 GB
g0126: DeepSpeed general environment info:
g0126: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0126: torch version .................... 2.0.1+cu118
g0126: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0126: deepspeed info ................... 0.12.4, unknown, unknown
g0126: torch cuda version ............... 11.8
g0126: torch hip version ................ None
g0126: nvcc version ..................... 11.8
g0126: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0126: shared memory (/dev/shm) size .... 188.13 GB
g0126: DeepSpeed general environment info:
g0126: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0126: torch version .................... 2.0.1+cu118
g0126: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0126: deepspeed info ................... 0.12.4, unknown, unknown
g0126: torch cuda version ............... 11.8
g0126: torch hip version ................ None
g0126: nvcc version ..................... 11.8
g0126: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0126: shared memory (/dev/shm) size .... 188.13 GB
g0123: --------------------------------------------------
g0123: --------------------------------------------------DeepSpeed C++/CUDA extension op report
g0123: 
g0123: --------------------------------------------------DeepSpeed C++/CUDA extension op report
g0123: 
g0123: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0123:       runtime if needed. Op compatibility means that your system
g0123:       meet the required dependencies to JIT install the op.--------------------------------------------------
g0123: 
g0123: --------------------------------------------------NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0123:       runtime if needed. Op compatibility means that your system
g0123:       meet the required dependencies to JIT install the op.
g0123: 
g0123: JIT compiled ops requires ninja
g0123: --------------------------------------------------
g0123: JIT compiled ops requires ninja
g0123: --------------------------------------------------
g0123: DeepSpeed C++/CUDA extension op report
g0123: --------------------------------------------------
g0123: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0123:       runtime if needed. Op compatibility means that your system
g0123:       meet the required dependencies to JIT install the op.
g0123: --------------------------------------------------
g0123: JIT compiled ops requires ninja
g0125: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0125: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0125: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0125: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0125: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0125: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0125: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0125: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0125: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: ninjaninja  ....................................ninja  [92m[OKAY][0m [92m[OKAY][0m
g0123: ..................
g0123:  --------------------------------------------------[92m[OKAY][0m
g0123: --------------------------------------------------
g0123: 
g0123: op name--------------------------------------------------op name 
g0123:  ................................ op name installed installed ................ ..  ..installedcompatible  
g0123: compatible..
g0123: -------------------------------------------------- --------------------------------------------------
g0123: compatible
g0123: 
g0123: --------------------------------------------------
g0123: --------------------------------------------------
g0123: DeepSpeed C++/CUDA extension op report
g0123: --------------------------------------------------
g0123: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0123:       runtime if needed. Op compatibility means that your system
g0123:       meet the required dependencies to JIT install the op.
g0123: --------------------------------------------------
g0123: JIT compiled ops requires ninja
g0123: ninja .................. [92m[OKAY][0m
g0123: --------------------------------------------------
g0123: op name ................ installed .. compatible
g0123: --------------------------------------------------
g0120: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0120: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0120: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0120: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0120: async_ioevoformer_attn  ........................  [92m[YES][0m[93m[NO][0m  .............  [92m[OKAY][0m[93m[NO][0m
g0120: 
g0120: fused_lamb ............. [92m[YES][0mfused_adam  ...................  [92m[OKAY][0m[92m[YES][0m
g0120:  ...... [92m[OKAY][0m
g0120: cpu_adam ...............fused_lion  [92m[YES][0m.............  ......[92m[YES][0m  [92m[OKAY][0m......
g0120:  [92m[OKAY][0m
g0120: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0120: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0120: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0120: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0120: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0120: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: async_iocpu_lion ...............  ...............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0120: [92m[OKAY][0m
g0120: fused_adam [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH.............
g0120:  [92m[YES][0mevoformer_attn  ...............  [92m[OKAY][0m[93m[NO][0m
g0120:  ....... [93m[NO][0mcpu_adam
g0120:  ............... [92m[YES][0mfused_lamb  ...................  [92m[OKAY][0m[92m[YES][0m
g0120:  ...... [92m[OKAY][0mcpu_adagrad
g0120:  ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: fused_lion cpu_lion.............  ...............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0120: [92m[OKAY][0m
g0120: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0120: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0120: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0126: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0126: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0126: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0126: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0125: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0125: inference_core_ops ..... [92m[YES][0m ......inference_core_ops [92m[OKAY][0m 
g0125: ..... [92m[YES][0m ...... [92m[OKAY][0m
g0125: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0125: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0120: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0120: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0120: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0125: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0125: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0125: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0125: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0125: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0125: sparse_attn ............ [93m[NO][0m .......[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0 
g0125: [93m[NO][0m
g0125: ragged_ops ............. [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible[92m[YES][0m
g0125:  ...... sparse_attn[92m[OKAY][0m 
g0125: ............ [93m[NO][0m random_ltd.......  .............[93m[NO][0m 
g0125: [92m[YES][0m ...... [92m[OKAY][0m
g0125: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0125: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0125: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0120: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0125: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0125: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0125: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0125: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0125: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0120: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0125: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0125: --------------------------------------------------
g0125: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0125: --------------------------------------------------
g0125: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0125: --------------------------------------------------
g0125: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0125: --------------------------------------------------
g0120: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0120: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0120: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0120: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0120: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0120: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0120: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0120: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0120: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0120: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0120: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0120: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0125: DeepSpeed general environment info:
g0125: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0125: torch version .................... 2.0.1+cu118
g0125: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0125: deepspeed info ................... 0.12.4, unknown, unknown
g0125: torch cuda version ............... 11.8
g0125: torch hip version ................ None
g0125: nvcc version ..................... 11.8
g0125: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0125: shared memory (/dev/shm) size .... 188.13 GB
g0125: DeepSpeed general environment info:
g0125: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0125: torch version .................... 2.0.1+cu118
g0125: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0125: deepspeed info ................... 0.12.4, unknown, unknown
g0125: torch cuda version ............... 11.8
g0125: torch hip version ................ None
g0125: nvcc version ..................... 11.8
g0125: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0125: shared memory (/dev/shm) size .... 188.13 GB
g0125: DeepSpeed general environment info:
g0125: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0125: torch version .................... 2.0.1+cu118
g0125: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0125: deepspeed info ................... 0.12.4, unknown, unknown
g0125: torch cuda version ............... 11.8
g0125: torch hip version ................ None
g0125: nvcc version ..................... 11.8
g0125: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0125: shared memory (/dev/shm) size .... 188.13 GB
g0125: DeepSpeed general environment info:
g0125: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0125: torch version .................... 2.0.1+cu118
g0125: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0125: deepspeed info ................... 0.12.4, unknown, unknown
g0125: torch cuda version ............... 11.8
g0125: torch hip version ................ None
g0125: nvcc version ..................... 11.8
g0125: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0125: shared memory (/dev/shm) size .... 188.13 GB
g0120: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0120: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0120: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0120: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0120: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0120: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0120: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0120: --------------------------------------------------
g0120: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0120: --------------------------------------------------
g0120: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0120: --------------------------------------------------
g0120: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0120: --------------------------------------------------
g0120: DeepSpeed general environment info:
g0120: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0120: torch version .................... 2.0.1+cu118
g0120: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0120: deepspeed info ................... 0.12.4, unknown, unknown
g0120: torch cuda version ............... 11.8
g0120: torch hip version ................ None
g0120: nvcc version ..................... 11.8
g0120: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0120: shared memory (/dev/shm) size .... 188.13 GB
g0120: DeepSpeed general environment info:
g0120: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0120: torch version .................... 2.0.1+cu118
g0120: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0120: deepspeed info ................... 0.12.4, unknown, unknown
g0120: torch cuda version ............... 11.8
g0120: torch hip version ................ None
g0120: nvcc version ..................... 11.8
g0120: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0120: shared memory (/dev/shm) size .... 188.13 GB
g0120: DeepSpeed general environment info:
g0120: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0120: torch version .................... 2.0.1+cu118
g0120: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0120: deepspeed info ................... 0.12.4, unknown, unknown
g0120: torch cuda version ............... 11.8
g0120: torch hip version ................ None
g0120: nvcc version ..................... 11.8
g0120: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0120: shared memory (/dev/shm) size .... 188.13 GB
g0120: DeepSpeed general environment info:
g0120: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0120: torch version .................... 2.0.1+cu118
g0120: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0120: deepspeed info ................... 0.12.4, unknown, unknown
g0120: torch cuda version ............... 11.8
g0120: torch hip version ................ None
g0120: nvcc version ..................... 11.8
g0120: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0120: shared memory (/dev/shm) size .... 188.13 GB
g0125: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0125: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0125: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0125: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0127: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0127: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0127: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0123: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0123: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0123: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0123: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_lion ............. [92m[YES][0m ...... async_io[92m[OKAY][0m
g0123:  ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0123: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0123: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0123: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0123: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0127: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0127: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0127: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: async_iocpu_lion  ..............................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0127: 
g0127: fused_adam .............[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH 
g0127: [92m[YES][0m evoformer_attn......  .........[92m[OKAY][0m 
g0127: [93m[NO][0m ....... cpu_adam[93m[NO][0m 
g0127: ............... [92m[YES][0mfused_lamb  ...................  [92m[OKAY][0m[92m[YES][0m
g0127:  ...... cpu_adagrad[92m[OKAY][0m 
g0127: ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: fused_lioncpu_lion  ............................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0127: 
g0127: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0127: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0127: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0120: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0120: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0120: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0120: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0123: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0123: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0123: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0123: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0123: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: cutlass_ops ............ [92m[YES][0m ...... cutlass_ops[92m[OKAY][0m
g0123:  ............ [92m[YES][0m quantizer......  ..............[92m[OKAY][0m 
g0123: [92m[YES][0m ...... quantizer[92m[OKAY][0m 
g0123: .............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: inference_core_opsinference_core_ops .....  .....[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0127: [92m[OKAY][0m
g0127: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0127: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0123: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0127: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0123: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0123: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0123: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0123: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0123: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0123: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0123: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0123: sparse_attn [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible............
g0123:  [93m[NO][0m sparse_attn.......  ............[93m[NO][0m 
g0123: [93m[NO][0m ....... [93m[NO][0m
g0123: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0123: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0127: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0127: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0127: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0127: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0123: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0123: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: stochastic_transformer spatial_inference.  ......[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0123: [92m[OKAY][0m
g0123: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0123: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0123: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0123: --------------------------------------------------
g0127: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0127: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0127: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0127: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0127: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0127: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0123: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0123: --------------------------------------------------
g0123: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0123: --------------------------------------------------
g0123: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0123: --------------------------------------------------
g0127: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0127: ragged_ops[93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible 
g0127: ............. sparse_attn[92m[YES][0m  ..................  [93m[NO][0m[92m[OKAY][0m 
g0127: ....... random_ltd[93m[NO][0m 
g0127: ............. [92m[YES][0m ...... [92m[OKAY][0m
g0127: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0127: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0127: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0123: DeepSpeed general environment info:
g0123: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0123: torch version .................... 2.0.1+cu118
g0123: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0123: deepspeed info ................... 0.12.4, unknown, unknown
g0123: torch cuda version ............... 11.8
g0123: torch hip version ................ None
g0123: nvcc version ..................... 11.8
g0123: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0123: shared memory (/dev/shm) size .... 188.13 GB
g0127: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0127: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0123: DeepSpeed general environment info:
g0123: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0123: torch version .................... 2.0.1+cu118
g0123: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0123: deepspeed info ................... 0.12.4, unknown, unknown
g0123: torch cuda version ............... 11.8
g0123: torch hip version ................ None
g0123: nvcc version ..................... 11.8
g0123: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0123: shared memory (/dev/shm) size .... 188.13 GB
g0123: DeepSpeed general environment info:
g0123: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0123: torch version .................... 2.0.1+cu118
g0123: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0123: deepspeed info ................... 0.12.4, unknown, unknown
g0123: torch cuda version ............... 11.8
g0123: torch hip version ................ None
g0123: nvcc version ..................... 11.8
g0123: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0123: shared memory (/dev/shm) size .... 188.13 GB
g0123: DeepSpeed general environment info:
g0123: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0123: torch version .................... 2.0.1+cu118
g0123: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0123: deepspeed info ................... 0.12.4, unknown, unknown
g0123: torch cuda version ............... 11.8
g0123: torch hip version ................ None
g0123: nvcc version ..................... 11.8
g0123: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0123: shared memory (/dev/shm) size .... 188.13 GB
g0127: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0127: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0127: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0127: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0127: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0127: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0127: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0127: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0127: --------------------------------------------------
g0127: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0127: --------------------------------------------------
g0127: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0127: --------------------------------------------------
g0127: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0127: --------------------------------------------------
g0127: DeepSpeed general environment info:
g0127: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0127: torch version .................... 2.0.1+cu118
g0127: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0127: deepspeed info ................... 0.12.4, unknown, unknown
g0127: torch cuda version ............... 11.8
g0127: torch hip version ................ None
g0127: nvcc version ..................... 11.8
g0127: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0127: shared memory (/dev/shm) size .... 188.13 GB
g0127: DeepSpeed general environment info:
g0127: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0127: torch version .................... 2.0.1+cu118
g0127: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0127: deepspeed info ................... 0.12.4, unknown, unknown
g0127: torch cuda version ............... 11.8
g0127: torch hip version ................ None
g0127: nvcc version ..................... 11.8
g0127: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0127: shared memory (/dev/shm) size .... 188.13 GB
g0127: DeepSpeed general environment info:
g0127: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0127: torch version .................... 2.0.1+cu118
g0127: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0127: deepspeed info ................... 0.12.4, unknown, unknown
g0127: torch cuda version ............... 11.8
g0127: torch hip version ................ None
g0127: nvcc version ..................... 11.8
g0127: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0127: shared memory (/dev/shm) size .... 188.13 GB
g0127: DeepSpeed general environment info:
g0127: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0127: torch version .................... 2.0.1+cu118
g0127: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0127: deepspeed info ................... 0.12.4, unknown, unknown
g0127: torch cuda version ............... 11.8
g0127: torch hip version ................ None
g0127: nvcc version ..................... 11.8
g0127: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0127: shared memory (/dev/shm) size .... 188.13 GB
g0123: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0123: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0123: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0123: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0126: [2024-08-12 02:42:55,452] [INFO] [comm.py:637:init_distributed] cdb=None
g0126: [2024-08-12 02:42:55,452] [INFO] [comm.py:637:init_distributed] cdb=None
g0126: [2024-08-12 02:42:55,452] [INFO] [comm.py:637:init_distributed] cdb=None
g0126: [2024-08-12 02:42:55,452] [INFO] [comm.py:637:init_distributed] cdb=None
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0126: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [2024-08-12 02:42:55,465] [INFO] [comm.py:637:init_distributed] cdb=None
g0125: [2024-08-12 02:42:55,465] [INFO] [comm.py:637:init_distributed] cdb=None
g0125: [2024-08-12 02:42:55,465] [INFO] [comm.py:637:init_distributed] cdb=None
g0125: [2024-08-12 02:42:55,465] [INFO] [comm.py:637:init_distributed] cdb=None
g0127: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0127: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0127: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0127: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0125: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [2024-08-12 02:42:55,474] [INFO] [comm.py:637:init_distributed] cdb=None
g0120: [2024-08-12 02:42:55,474] [INFO] [comm.py:637:init_distributed] cdb=None
g0120: [2024-08-12 02:42:55,475] [INFO] [comm.py:637:init_distributed] cdb=None
g0120: [2024-08-12 02:42:55,476] [INFO] [comm.py:637:init_distributed] cdb=None
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0120: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [2024-08-12 02:42:55,545] [INFO] [comm.py:637:init_distributed] cdb=None
g0123: [2024-08-12 02:42:55,545] [INFO] [comm.py:637:init_distributed] cdb=None
g0123: [2024-08-12 02:42:55,548] [INFO] [comm.py:637:init_distributed] cdb=None
g0123: [2024-08-12 02:42:55,552] [INFO] [comm.py:637:init_distributed] cdb=None
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0123: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: [2024-08-12 02:42:55,565] [INFO] [comm.py:637:init_distributed] cdb=None
g0127: [2024-08-12 02:42:55,565] [INFO] [comm.py:637:init_distributed] cdb=None
g0127: [2024-08-12 02:42:55,566] [INFO] [comm.py:637:init_distributed] cdb=None
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: ----------------------------------------------------------------------------------------------------
g0121: 
g0121: DeepSpeed C++/CUDA extension op reportDeepSpeed C++/CUDA extension op report
g0121: 
g0121: ----------------------------------------------------------------------------------------------------
g0121: 
g0121: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0121:       runtime if needed. Op compatibility means that your system
g0121:       meet the required dependencies to JIT install the op.NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0121:       runtime if needed. Op compatibility means that your system
g0121:       meet the required dependencies to JIT install the op.
g0121: 
g0121: ----------------------------------------------------------------------------------------------------
g0121: 
g0121: JIT compiled ops requires ninjaJIT compiled ops requires ninja
g0121: 
g0121: --------------------------------------------------
g0121: DeepSpeed C++/CUDA extension op report
g0121: --------------------------------------------------
g0121: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0121:       runtime if needed. Op compatibility means that your system
g0121:       meet the required dependencies to JIT install the op.
g0121: --------------------------------------------------
g0121: JIT compiled ops requires ninja
g0121: ninjaninjaninja  .................. .................. .................. [92m[OKAY][0m [92m[OKAY][0m
g0121: [92m[OKAY][0m
g0121: 
g0121: ----------------------------------------------------------------------------------------------------
g0121: --------------------------------------------------
g0121: op name
g0121: op name  ................op name................  installed ................ installed  ..installed..   compatible..compatible
g0121:  
g0121: --------------------------------------------------compatible--------------------------------------------------
g0121: 
g0121: 
g0121: --------------------------------------------------
g0121: --------------------------------------------------
g0121: DeepSpeed C++/CUDA extension op report
g0121: --------------------------------------------------
g0121: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0121:       runtime if needed. Op compatibility means that your system
g0121:       meet the required dependencies to JIT install the op.
g0121: --------------------------------------------------
g0121: JIT compiled ops requires ninja
g0121: ninja .................. [92m[OKAY][0m
g0121: --------------------------------------------------
g0121: op name ................ installed .. compatible
g0121: --------------------------------------------------
g0121: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0121: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0121: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0121: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0121: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0121: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0121: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0121: async_io ............... fused_adam[92m[YES][0m  ...................  [92m[YES][0m[92m[OKAY][0m ......
g0121:  async_io[92m[OKAY][0m
g0121:  ............... [92m[YES][0mfused_adamcpu_adam   ..................................   [92m[OKAY][0m[92m[YES][0m[92m[YES][0m  
g0121: ............  [92m[OKAY][0m[92m[OKAY][0m
g0121: 
g0121: cpu_adagradfused_adamcpu_adam   ........................................   [92m[YES][0m[92m[YES][0m[92m[YES][0m   ..................   [92m[OKAY][0m[92m[OKAY][0m[92m[OKAY][0m
g0121: 
g0121: 
g0121: cpu_lioncpu_adam cpu_adagrad ............... ............... ............ [92m[YES][0m [92m[YES][0m [92m[YES][0m ............   [92m[OKAY][0m[92m[OKAY][0m......
g0121: 
g0121:  [92m[OKAY][0m
g0121: cpu_lioncpu_adagrad  ...........................[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH  
g0121: [92m[YES][0m[92m[YES][0m  evoformer_attn............   .........[92m[OKAY][0m[92m[OKAY][0m 
g0121: 
g0121: [93m[NO][0m ....... cpu_lion[93m[NO][0m 
g0121: ............... [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[92m[YES][0mfused_lamb
g0121:   ................... evoformer_attn [92m[OKAY][0m[92m[YES][0m 
g0121:  ...............  [93m[NO][0m[92m[OKAY][0m 
g0121: ....... [93m[NO][0m
g0121: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATHfused_lamb
g0121:  .............fused_lion evoformer_attn [92m[YES][0m ............. ......... ...... [92m[YES][0m [93m[NO][0m [92m[OKAY][0m ......
g0121: .......  [92m[OKAY][0m[93m[NO][0m
g0121: 
g0121: fused_lamb fused_lion.............  .............[92m[YES][0m  [92m[YES][0m......  ......[92m[OKAY][0m 
g0121: [92m[OKAY][0m
g0121: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: inference_core_opsinference_core_ops  ..........  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0121: inference_core_ops
g0121:  ..... [92m[YES][0m ...... [92m[OKAY][0m
g0121: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0121: cutlass_opscutlass_ops  ........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0121: 
g0121: quantizercutlass_opsquantizer  .............. ............ .............. [92m[YES][0m [92m[YES][0m [92m[YES][0m ...... ...... ...... [92m[OKAY][0m [92m[OKAY][0m
g0121: [92m[OKAY][0m
g0121: 
g0121: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0121: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0121: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0121: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0121: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0121: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0121: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0121: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0121: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0121: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0121: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0121: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0121: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0121: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0121: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0121: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0121: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0121: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0121: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0121: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0121: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0121: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0121: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0121: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0121: --------------------------------------------------
g0121: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0121: --------------------------------------------------
g0121: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0121: --------------------------------------------------
g0121: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0121: --------------------------------------------------
g0121: DeepSpeed general environment info:
g0121: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0121: torch version .................... 2.0.1+cu118
g0121: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0121: deepspeed info ................... 0.12.4, unknown, unknown
g0121: torch cuda version ............... 11.8
g0121: torch hip version ................ None
g0121: nvcc version ..................... 11.8
g0121: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0121: shared memory (/dev/shm) size .... 188.13 GB
g0121: DeepSpeed general environment info:
g0121: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0121: torch version .................... 2.0.1+cu118
g0121: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0121: deepspeed info ................... 0.12.4, unknown, unknown
g0121: torch cuda version ............... 11.8
g0121: torch hip version ................ None
g0121: nvcc version ..................... 11.8
g0121: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0121: shared memory (/dev/shm) size .... 188.13 GB
g0121: DeepSpeed general environment info:
g0121: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0121: torch version .................... 2.0.1+cu118
g0121: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0121: deepspeed info ................... 0.12.4, unknown, unknown
g0121: torch cuda version ............... 11.8
g0121: torch hip version ................ None
g0121: nvcc version ..................... 11.8
g0121: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0121: shared memory (/dev/shm) size .... 188.13 GB
g0121: DeepSpeed general environment info:
g0121: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0121: torch version .................... 2.0.1+cu118
g0121: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0121: deepspeed info ................... 0.12.4, unknown, unknown
g0121: torch cuda version ............... 11.8
g0121: torch hip version ................ None
g0121: nvcc version ..................... 11.8
g0121: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0121: shared memory (/dev/shm) size .... 188.13 GB
g0121: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0121: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0121: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0121: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0121: [2024-08-12 02:42:55,904] [INFO] [comm.py:637:init_distributed] cdb=None
g0121: [2024-08-12 02:42:55,905] [INFO] [comm.py:637:init_distributed] cdb=None
g0121: [2024-08-12 02:42:55,907] [INFO] [comm.py:637:init_distributed] cdb=None
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: [2024-08-12 02:42:55,912] [INFO] [comm.py:637:init_distributed] cdb=None
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0121: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: > setting tensorboard ...
g0127: [2024-08-12 02:42:55,973] [INFO] [comm.py:637:init_distributed] cdb=None
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0127: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: --------------------------------------------------
g0113: DeepSpeed C++/CUDA extension op report
g0113: --------------------------------------------------
g0113: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0113:       runtime if needed. Op compatibility means that your system
g0113:       meet the required dependencies to JIT install the op.
g0113: --------------------------------------------------
g0113: JIT compiled ops requires ninja
g0113: --------------------------------------------------
g0113: DeepSpeed C++/CUDA extension op report
g0113: --------------------------------------------------
g0113: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0113:       runtime if needed. Op compatibility means that your system
g0113:       meet the required dependencies to JIT install the op.
g0113: --------------------------------------------------
g0113: JIT compiled ops requires ninja
g0113: --------------------------------------------------
g0113: DeepSpeed C++/CUDA extension op report
g0113: --------------------------------------------------
g0113: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0113:       runtime if needed. Op compatibility means that your system
g0113:       meet the required dependencies to JIT install the op.
g0113: --------------------------------------------------
g0113: JIT compiled ops requires ninja
g0113: --------------------------------------------------
g0113: DeepSpeed C++/CUDA extension op report
g0113: --------------------------------------------------
g0113: NOTE: Ops not installed will be just-in-time (JIT) compiled at
g0113:       runtime if needed. Op compatibility means that your system
g0113:       meet the required dependencies to JIT install the op.
g0113: --------------------------------------------------
g0113: JIT compiled ops requires ninja
g0113: ninjaninjaninja  ninja....................................    ..................[92m[OKAY][0m..................[92m[OKAY][0m 
g0113: 
g0113:  [92m[OKAY][0m[92m[OKAY][0m----------------------------------------------------------------------------------------------------
g0113: 
g0113: 
g0113: 
g0113: --------------------------------------------------op nameop name--------------------------------------------------
g0113:   
g0113: ................op name ................ installed .. compatible
g0113: ................--------------------------------------------------op name
g0113:    installedinstalled................   ....installed   compatiblecompatible..
g0113: 
g0113:  compatible----------------------------------------------------------------------------------------------------
g0113: 
g0113: 
g0113: --------------------------------------------------
g0113: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0113: fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
g0113: cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
g0113: cpu_lion ............... [92m[YES][0m ...... [92m[OKAY][0m
g0113: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0113: evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
g0113: fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: fused_lion ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
g0113: fused_adam ............. [92m[YES][0m ......async_io [92m[OKAY][0m 
g0113: ............... cpu_adam[92m[YES][0m async_io...............   ......[92m[YES][0m...............   ......[92m[YES][0m[92m[OKAY][0m  [92m[OKAY][0m
g0113: ......
g0113:  [92m[OKAY][0mcpu_adagrad
g0113:  ............ fused_adam[92m[YES][0m  ...................fused_adam   [92m[YES][0m[92m[OKAY][0m............. 
g0113:  ......[92m[YES][0m  [92m[OKAY][0mcpu_lion......
g0113:   ...............[92m[OKAY][0m 
g0113: [92m[YES][0mcpu_adam  .....................cpu_adam   [92m[OKAY][0m[92m[YES][0m...............
g0113:   ......[92m[YES][0m  [92m[OKAY][0m...... 
g0113: [92m[OKAY][0m
g0113: cpu_adagrad cpu_adagrad............ [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH ............
g0113: [92m[YES][0m  [92m[YES][0mevoformer_attn......   ............... [92m[OKAY][0m [92m[OKAY][0m
g0113: [93m[NO][0m
g0113:  .......cpu_lion cpu_lion [93m[NO][0m ...............
g0113: ...............  [92m[YES][0m[92m[YES][0mfused_lamb   ............ ............. [92m[OKAY][0m [92m[OKAY][0m
g0113: [92m[YES][0m
g0113:  ...... [92m[OKAY][0m
g0113: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
g0113: 
g0113: evoformer_attnevoformer_attn  ..................fused_lion   [93m[NO][0m[93m[NO][0m.............   ..............[92m[YES][0m   [93m[NO][0m[93m[NO][0m......
g0113: 
g0113:  [92m[OKAY][0m
g0113: fused_lambfused_lamb  ..........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0113: 
g0113: fused_lionfused_lion  ..........................  [92m[YES][0m[92m[YES][0m  ............  [92m[OKAY][0m[92m[OKAY][0m
g0113: 
g0113: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0113: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0113: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0113: inference_core_ops ..... [92m[YES][0m ...... [92m[OKAY][0m
g0113: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0113: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: cutlass_ops ............ [92m[YES][0m ...... cutlass_ops[92m[OKAY][0m 
g0113: ............ [92m[YES][0m quantizer......  ..............[92m[OKAY][0m
g0113:  [92m[YES][0m ......quantizer  ..............[92m[OKAY][0m 
g0113: [92m[YES][0m ...... [92m[OKAY][0m
g0113: cutlass_ops ............ [92m[YES][0m ...... [92m[OKAY][0m
g0113: quantizer .............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: ragged_device_ops ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: ragged_ops ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0113: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0113: sparse_attn ............ [93m[NO][0mragged_ops .......  .............[93m[NO][0m 
g0113: [92m[YES][0m ...... [92m[OKAY][0m
g0113: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0113: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatibleragged_ops
g0113:  .............sparse_attn  [92m[YES][0m............  ......[93m[NO][0m  [92m[OKAY][0m.......
g0113:  [93m[NO][0m
g0113: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0113: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0113: sparse_attn ............ [93m[NO][0mragged_ops  ....................  [93m[NO][0m[92m[YES][0m
g0113:  ...... [92m[OKAY][0m
g0113: random_ltd ............. [92m[YES][0m ...... [92m[OKAY][0m
g0113: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
g0113: [93m [WARNING] [0m using untested triton version (2.0.0), only 1.0.0 is known to be compatible
g0113: sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
g0113: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0113: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0113: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0113: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0113: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0113: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0113: spatial_inference ...... [92m[YES][0m ...... [92m[OKAY][0m
g0113: transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
g0113: stochastic_transformer . [92m[YES][0m ...... [92m[OKAY][0m
g0113: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0113: --------------------------------------------------
g0113: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0113: --------------------------------------------------
g0113: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0113: --------------------------------------------------
g0113: transformer_inference .. [92m[YES][0m ...... [92m[OKAY][0m
g0113: --------------------------------------------------
g0113: DeepSpeed general environment info:
g0113: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0113: torch version .................... 2.0.1+cu118
g0113: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0113: deepspeed info ................... 0.12.4, unknown, unknown
g0113: torch cuda version ............... 11.8
g0113: torch hip version ................ None
g0113: nvcc version ..................... 11.8
g0113: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0113: shared memory (/dev/shm) size .... 188.13 GB
g0113: DeepSpeed general environment info:
g0113: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0113: torch version .................... 2.0.1+cu118
g0113: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0113: deepspeed info ................... 0.12.4, unknown, unknown
g0113: torch cuda version ............... 11.8
g0113: torch hip version ................ None
g0113: nvcc version ..................... 11.8
g0113: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0113: shared memory (/dev/shm) size .... 188.13 GB
g0113: DeepSpeed general environment info:
g0113: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0113: torch version .................... 2.0.1+cu118
g0113: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0113: deepspeed info ................... 0.12.4, unknown, unknown
g0113: torch cuda version ............... 11.8
g0113: torch hip version ................ None
g0113: nvcc version ..................... 11.8
g0113: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0113: shared memory (/dev/shm) size .... 188.13 GB
g0113: DeepSpeed general environment info:
g0113: torch install path ............... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/torch']
g0113: torch version .................... 2.0.1+cu118
g0113: deepspeed install path ........... ['/home/acf16449gb/crypto_llm/train/.venv_train/lib/python3.11/site-packages/deepspeed']
g0113: deepspeed info ................... 0.12.4, unknown, unknown
g0113: torch cuda version ............... 11.8
g0113: torch hip version ................ None
g0113: nvcc version ..................... 11.8
g0113: deepspeed wheel compiled w. ...... torch 2.0, cuda 11.8
g0113: shared memory (/dev/shm) size .... 188.13 GB
g0113: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0113: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0113: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0113: **** Git info for Megatron: git_hash=26f6f9f git_branch=main ****
g0113: [2024-08-12 02:42:57,059] [INFO] [comm.py:637:init_distributed] cdb=None
g0113: [2024-08-12 02:42:57,059] [INFO] [comm.py:637:init_distributed] cdb=None
g0113: [2024-08-12 02:42:57,060] [INFO] [comm.py:637:init_distributed] cdb=None
g0113: [2024-08-12 02:42:57,062] [INFO] [comm.py:637:init_distributed] cdb=None
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0113: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: [W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [g0108-eth0]:29500 (errno: 97 - Address family not supported by protocol).
g0108: > initialized tensor model parallel with size 1
g0108: > initialized pipeline model parallel with size 8
g0108: > setting random seeds to 1234 ...
g0108: > initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
g0108: > compiling dataset index builder ...
g0108: make: Entering directory '/home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/data'
g0108: make: Nothing to be done for 'default'.
g0108: make: Leaving directory '/home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/data'
g0108: >>> done with dataset index builder. Compilation time: 0.081 seconds
g0108: WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
g0108: > compiling and loading fused kernels ...
g0108: Detected CUDA files, patching ldflags
g0108: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0108: Building extension module scaled_upper_triang_masked_softmax_cuda...
g0108: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0108: ninja: no work to do.
g0108: Loading extension module scaled_upper_triang_masked_softmax_cuda...
g0108: Detected CUDA files, patching ldflags
g0108: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0108: Building extension module scaled_masked_softmax_cuda...
g0108: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0108: ninja: no work to do.
g0108: Loading extension module scaled_masked_softmax_cuda...
g0108: Detected CUDA files, patching ldflags
g0108: Emitting ninja build file /home/acf16449gb/ucllm_nedo_prod/train/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
g0108: Building extension module scaled_softmax_cuda...
g0108: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
g0108: ninja: no work to do.
g0108: Loading extension module scaled_softmax_cuda...
g0108: >>> done with compiling and loading fused kernels. Compilation time: 7.313 seconds
g0108: time to initialize megatron (seconds): 22.504
g0108: [after megatron is initialized] datetime: 2024-08-12 02:43:07 
g0120: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0123: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0126: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0125: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0108: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0127: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0121: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0113: wandb: Currently logged in as: yohei-kobashi. Use `wandb login --relogin` to force relogin
g0108: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0108: wandb:  $ pip install wandb --upgrade
g0108: wandb: Tracking run with wandb version 0.17.5
g0108: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-0udlkkbm
g0108: wandb: Run `wandb offline` to turn off syncing.
g0108: wandb: Syncing run g0108.abci.local
g0108: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0108: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/0udlkkbm
g0127: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0127: wandb:  $ pip install wandb --upgrade
g0127: wandb: Tracking run with wandb version 0.17.5
g0127: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-p8aqrm1p
g0127: wandb: Run `wandb offline` to turn off syncing.
g0127: wandb: Syncing run g0127.abci.local
g0127: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0127: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/p8aqrm1p
g0121: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0121: wandb:  $ pip install wandb --upgrade
g0121: wandb: Tracking run with wandb version 0.17.5
g0121: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-smcgp7ju
g0121: wandb: Run `wandb offline` to turn off syncing.
g0121: wandb: Syncing run g0121.abci.local
g0121: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0121: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/smcgp7ju
g0123: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0123: wandb:  $ pip install wandb --upgrade
g0123: wandb: Tracking run with wandb version 0.17.5
g0123: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-rcdxbd15
g0123: wandb: Run `wandb offline` to turn off syncing.
g0123: wandb: Syncing run g0123.abci.local
g0123: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0123: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/rcdxbd15
g0120: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0120: wandb:  $ pip install wandb --upgrade
g0120: wandb: Tracking run with wandb version 0.17.5
g0120: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-stfeyvzp
g0120: wandb: Run `wandb offline` to turn off syncing.
g0126: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0126: wandb:  $ pip install wandb --upgrade
g0126: wandb: Tracking run with wandb version 0.17.5
g0126: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-84pt6kny
g0126: wandb: Run `wandb offline` to turn off syncing.
g0125: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0125: wandb:  $ pip install wandb --upgrade
g0125: wandb: Tracking run with wandb version 0.17.5
g0125: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-j5f6c923
g0125: wandb: Run `wandb offline` to turn off syncing.
g0120: wandb: Syncing run g0120.abci.local
g0120: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0120: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/stfeyvzp
g0113: wandb: wandb version 0.17.6 is available!  To upgrade, please run:
g0113: wandb:  $ pip install wandb --upgrade
g0113: wandb: Tracking run with wandb version 0.17.5
g0113: wandb: Run data is saved locally in /home/acf16449gb/crypto_llm/train/scripts/step2_pretrain_model/wandb/run-20240812_024308-tcqzqxo8
g0113: wandb: Run `wandb offline` to turn off syncing.
g0125: wandb: Syncing run g0125.abci.local
g0125: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0125: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/j5f6c923
g0126: wandb: Syncing run g0126.abci.local
g0126: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0126: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/84pt6kny
g0113: wandb: Syncing run g0113.abci.local
g0113: wandb: ⭐️ View project at https://wandb.ai/yohei-kobashi/encrypted_data_LLM
g0113: wandb: 🚀 View run at https://wandb.ai/yohei-kobashi/encrypted_data_LLM/runs/tcqzqxo8
g0108: building GPT model ...
g0108: [2024-08-12 02:43:09,708] [INFO] [utils.py:795:see_memory_usage] Before Building Model
g0108: [2024-08-12 02:43:09,709] [INFO] [utils.py:796:see_memory_usage] MA 0.0 GB         Max_MA 0.73 GB         CA 0.0 GB         Max_CA 1 GB 
g0108: [2024-08-12 02:43:09,709] [INFO] [utils.py:803:see_memory_usage] CPU Virtual Memory:  used = 53.53 GB, percent = 14.2%
g0108: SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
g0108: Using topology: {ProcessCoord(pipe=0, data=0, model=0): 0, ProcessCoord(pipe=0, data=1, model=0): 1, ProcessCoord(pipe=0, data=2, model=0): 2, ProcessCoord(pipe=0, data=3, model=0): 3, ProcessCoord(pipe=1, data=0, model=0): 4, ProcessCoord(pipe=1, data=1, model=0): 5, ProcessCoord(pipe=1, data=2, model=0): 6, ProcessCoord(pipe=1, data=3, model=0): 7, ProcessCoord(pipe=2, data=0, model=0): 8, ProcessCoord(pipe=2, data=1, model=0): 9, ProcessCoord(pipe=2, data=2, model=0): 10, ProcessCoord(pipe=2, data=3, model=0): 11, ProcessCoord(pipe=3, data=0, model=0): 12, ProcessCoord(pipe=3, data=1, model=0): 13, ProcessCoord(pipe=3, data=2, model=0): 14, ProcessCoord(pipe=3, data=3, model=0): 15, ProcessCoord(pipe=4, data=0, model=0): 16, ProcessCoord(pipe=4, data=1, model=0): 17, ProcessCoord(pipe=4, data=2, model=0): 18, ProcessCoord(pipe=4, data=3, model=0): 19, ProcessCoord(pipe=5, data=0, model=0): 20, ProcessCoord(pipe=5, data=1, model=0): 21, ProcessCoord(pipe=5, data=2, model=0): 22, ProcessCoord(pipe=5, data=3, model=0): 23, ProcessCoord(pipe=6, data=0, model=0): 24, ProcessCoord(pipe=6, data=1, model=0): 25, ProcessCoord(pipe=6, data=2, model=0): 26, ProcessCoord(pipe=6, data=3, model=0): 27, ProcessCoord(pipe=7, data=0, model=0): 28, ProcessCoord(pipe=7, data=1, model=0): 29, ProcessCoord(pipe=7, data=2, model=0): 30, ProcessCoord(pipe=7, data=3, model=0): 31}
g0108: [2024-08-12 02:43:10,221] [INFO] [module.py:375:_partition_layers] Partitioning pipeline stages with method type:transformer
g0108: stage=0 layers=5
g0108:      0: _to_float16
g0108:      1: EmbeddingPipe
g0108:      2: ParallelTransformerLayerPipe
g0108:      3: ParallelTransformerLayerPipe
g0108:      4: ParallelTransformerLayerPipe
g0108: stage=1 layers=3
g0108:      5: ParallelTransformerLayerPipe
g0108:      6: ParallelTransformerLayerPipe
g0108:      7: ParallelTransformerLayerPipe
g0108: stage=2 layers=3
g0108:      8: ParallelTransformerLayerPipe
g0108:      9: ParallelTransformerLayerPipe
g0108:     10: ParallelTransformerLayerPipe
g0108: stage=3 layers=3
g0108:     11: ParallelTransformerLayerPipe
g0108:     12: ParallelTransformerLayerPipe
g0108:     13: ParallelTransformerLayerPipe
g0108: stage=4 layers=3
g0108:     14: ParallelTransformerLayerPipe
g0108:     15: ParallelTransformerLayerPipe
g0108:     16: ParallelTransformerLayerPipe
g0108: stage=5 layers=3
g0108:     17: ParallelTransformerLayerPipe
g0108:     18: ParallelTransformerLayerPipe
g0108:     19: ParallelTransformerLayerPipe
g0108: stage=6 layers=3
g0108:     20: ParallelTransformerLayerPipe
g0108:     21: ParallelTransformerLayerPipe
g0108:     22: ParallelTransformerLayerPipe
g0108: stage=7 layers=3
g0108:     23: ParallelTransformerLayerPipe
g0108:     24: MixedFusedRMSNorm
g0108:     25: LMHeadPipe
g0108:   loss: CrossEntropy
g0120:  > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 135278592
g0127:  > number of parameters on (tensor, pipeline) model parallel rank (0, 7): 110893056
g0113:  > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 135278592
g0125:  > number of parameters on (tensor, pipeline) model parallel rank (0, 5): 135278592
g0123:  > number of parameters on (tensor, pipeline) model parallel rank (0, 4): 135278592
g0121:  > number of parameters on (tensor, pipeline) model parallel rank (0, 3): 135278592
g0126:  > number of parameters on (tensor, pipeline) model parallel rank (0, 6): 135278592
g0120: [2024-08-12 02:43:10,845] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0120: [2024-08-12 02:43:10,845] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0120: [2024-08-12 02:43:10,845] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0120: [2024-08-12 02:43:10,845] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0113: [2024-08-12 02:43:10,850] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0113: [2024-08-12 02:43:10,850] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0113: [2024-08-12 02:43:10,850] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0113: [2024-08-12 02:43:10,850] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0127: [2024-08-12 02:43:10,862] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0127: [2024-08-12 02:43:10,863] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0127: [2024-08-12 02:43:10,863] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0127: [2024-08-12 02:43:10,863] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0123: [2024-08-12 02:43:10,867] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0123: [2024-08-12 02:43:10,867] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0123: [2024-08-12 02:43:10,867] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0123: [2024-08-12 02:43:10,867] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0108: [2024-08-12 02:43:10,870] [INFO] [utils.py:795:see_memory_usage] After Building Model
g0108: [2024-08-12 02:43:10,871] [INFO] [utils.py:796:see_memory_usage] MA 0.75 GB         Max_MA 0.78 GB         CA 0.78 GB         Max_CA 1 GB 
g0108: [2024-08-12 02:43:10,871] [INFO] [utils.py:803:see_memory_usage] CPU Virtual Memory:  used = 53.59 GB, percent = 14.2%
g0108:  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 201076736
g0108: setting training iterations to 52000
g0108: > learning rate decay style: cosine
g0108: DeepSpeed is enabled.
g0108: [2024-08-12 02:43:10,873] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.4, git-hash=unknown, git-branch=unknown
g0126: [2024-08-12 02:43:10,888] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0126: [2024-08-12 02:43:10,888] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0126: [2024-08-12 02:43:10,888] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0126: [2024-08-12 02:43:10,888] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0121: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0121: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0121: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0125: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0125: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0125: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0125: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0121: [2024-08-12 02:43:10,891] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0108: [2024-08-12 02:43:11,084] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
g0108: [2024-08-12 02:43:11,085] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
g0108: [2024-08-12 02:43:11,086] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
g0108: [2024-08-12 02:43:11,086] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
g0108: [2024-08-12 02:43:11,086] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
g0108: [2024-08-12 02:43:11,112] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
g0108: [2024-08-12 02:43:11,112] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
g0108: [2024-08-12 02:43:11,112] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0108: [2024-08-12 02:43:11,113] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <megatron.optimizer_param_scheduler.OptimizerParamScheduler object at 0x7f4894e86510>
g0108: [2024-08-12 02:43:11,113] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0108: [2024-08-12 02:43:11,113] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0108: [2024-08-12 02:43:11,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
g0108: [2024-08-12 02:43:11,113] [INFO] [config.py:979:print] DeepSpeedEngine configuration:
g0108: [2024-08-12 02:43:11,114] [INFO] [config.py:983:print]   activation_checkpointing_config  {
g0108:     "partition_activations": false, 
g0108:     "contiguous_memory_optimization": false, 
g0108:     "cpu_checkpointing": false, 
g0108:     "number_checkpoints": null, 
g0108:     "synchronize_checkpoint_boundary": false, 
g0108:     "profile": false
g0108: }
g0108: [2024-08-12 02:43:11,114] [INFO] [config.py:983:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
g0108: [2024-08-12 02:43:11,114] [INFO] [config.py:983:print]   amp_enabled .................. False
g0108: [2024-08-12 02:43:11,114] [INFO] [config.py:983:print]   amp_params ................... False
g0108: [2024-08-12 02:43:11,114] [INFO] [config.py:983:print]   autotuning_config ............ {
g0108:     "enabled": false, 
g0108:     "start_step": null, 
g0108:     "end_step": null, 
g0108:     "metric_path": null, 
g0108:     "arg_mappings": null, 
g0108:     "metric": "throughput", 
g0108:     "model_info": null, 
g0108:     "results_dir": "autotuning_results", 
g0108:     "exps_dir": "autotuning_exps", 
g0108:     "overwrite": true, 
g0108:     "fast": true, 
g0108:     "start_profile_step": 3, 
g0108:     "end_profile_step": 5, 
g0108:     "tuner_type": "gridsearch", 
g0108:     "tuner_early_stopping": 5, 
g0108:     "tuner_num_trials": 50, 
g0108:     "model_info_path": null, 
g0108:     "mp_size": 1, 
g0108:     "max_train_batch_size": null, 
g0108:     "min_train_batch_size": 1, 
g0108:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
g0108:     "min_train_micro_batch_size_per_gpu": 1, 
g0108:     "num_tuning_micro_batch_sizes": 3
g0108: }
g0108: [2024-08-12 02:43:11,114] [INFO] [config.py:983:print]   bfloat16_enabled ............. False
g0108: [2024-08-12 02:43:11,115] [INFO] [config.py:983:print]   checkpoint_parallel_write_pipeline  False
g0108: [2024-08-12 02:43:11,115] [INFO] [config.py:983:print]   checkpoint_tag_validation_enabled  True
g0108: [2024-08-12 02:43:11,115] [INFO] [config.py:983:print]   checkpoint_tag_validation_fail  False
g0108: [2024-08-12 02:43:11,115] [INFO] [config.py:983:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4894dea6d0>
g0108: [2024-08-12 02:43:11,115] [INFO] [config.py:983:print]   communication_data_type ...... None
g0108: [2024-08-12 02:43:11,115] [INFO] [config.py:983:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
g0108: [2024-08-12 02:43:11,115] [INFO] [config.py:983:print]   curriculum_enabled_legacy .... False
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   curriculum_params_legacy ..... False
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   data_efficiency_enabled ...... False
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   dataloader_drop_last ......... False
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   disable_allgather ............ False
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   dump_state ................... False
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 500, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   eigenvalue_enabled ........... False
g0108: [2024-08-12 02:43:11,116] [INFO] [config.py:983:print]   eigenvalue_gas_boundary_resolution  1
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   eigenvalue_layer_name ........ bert.encoder.layer
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   eigenvalue_layer_num ......... 0
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   eigenvalue_max_iter .......... 100
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   eigenvalue_stability ......... 1e-06
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   eigenvalue_tol ............... 0.01
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   eigenvalue_verbose ........... False
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   elasticity_enabled ........... False
g0108: [2024-08-12 02:43:11,117] [INFO] [config.py:983:print]   flops_profiler_config ........ {
g0108:     "enabled": false, 
g0108:     "recompute_fwd_factor": 0.0, 
g0108:     "profile_step": 1, 
g0108:     "module_depth": -1, 
g0108:     "top_modules": 1, 
g0108:     "detailed": true, 
g0108:     "output_file": null
g0108: }
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   fp16_auto_cast ............... False
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   fp16_enabled ................. True
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   fp16_master_weights_and_gradients  False
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   global_rank .................. 0
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   grad_accum_dtype ............. None
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   gradient_accumulation_steps .. 32
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   gradient_clipping ............ 1.0
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   gradient_predivide_factor .... 1.0
g0108: [2024-08-12 02:43:11,118] [INFO] [config.py:983:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   initial_dynamic_scale ........ 2048
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   load_universal_checkpoint .... False
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   loss_scale ................... 0
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   memory_breakdown ............. False
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   mics_hierarchial_params_gather  False
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   mics_shard_size .............. -1
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
g0108: [2024-08-12 02:43:11,119] [INFO] [config.py:983:print]   nebula_config ................ {
g0108:     "enabled": false, 
g0108:     "persistent_storage_path": null, 
g0108:     "persistent_time_interval": 100, 
g0108:     "num_of_version_in_retention": 2, 
g0108:     "enable_nebula_load": true, 
g0108:     "load_path": null
g0108: }
g0108: [2024-08-12 02:43:11,120] [INFO] [config.py:983:print]   optimizer_legacy_fusion ...... False
g0108: [2024-08-12 02:43:11,120] [INFO] [config.py:983:print]   optimizer_name ............... None
g0108: [2024-08-12 02:43:11,120] [INFO] [config.py:983:print]   optimizer_params ............. None
g0108: [2024-08-12 02:43:11,120] [INFO] [config.py:983:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
g0108: [2024-08-12 02:43:11,120] [INFO] [config.py:983:print]   pld_enabled .................. False
g0108: [2024-08-12 02:43:11,120] [INFO] [config.py:983:print]   pld_params ................... False
g0108: [2024-08-12 02:43:11,120] [INFO] [config.py:983:print]   prescale_gradients ........... True
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   scheduler_name ............... None
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   scheduler_params ............. None
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   seq_parallel_communication_data_type  torch.float32
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   sparse_attention ............. None
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   sparse_gradients_enabled ..... False
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   steps_per_print .............. 10
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   train_batch_size ............. 128
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   train_micro_batch_size_per_gpu  1
g0108: [2024-08-12 02:43:11,121] [INFO] [config.py:983:print]   use_data_before_expert_parallel_  False
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   use_node_local_storage ....... False
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   wall_clock_breakdown ......... False
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   weight_quantization_config ... None
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   world_size ................... 4
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   zero_allow_untested_optimizer  False
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   zero_enabled ................. False
g0108: [2024-08-12 02:43:11,122] [INFO] [config.py:983:print]   zero_force_ds_cpu_optimizer .. True
g0108: [2024-08-12 02:43:11,123] [INFO] [config.py:983:print]   zero_optimization_stage ...... 0
g0108: [2024-08-12 02:43:11,123] [INFO] [config.py:969:print_user_config]   json = {
g0108:     "train_batch_size": 128, 
g0108:     "train_micro_batch_size_per_gpu": 1, 
g0108:     "steps_per_print": 10, 
g0108:     "zero_optimization": {
g0108:         "stage": 0
g0108:     }, 
g0108:     "gradient_clipping": 1.0, 
g0108:     "prescale_gradients": true, 
g0108:     "fp16": {
g0108:         "enabled": true, 
g0108:         "loss_scale": 0, 
g0108:         "loss_scale_window": 500, 
g0108:         "hysteresis": 2, 
g0108:         "min_loss_scale": 1, 
g0108:         "initial_scale_power": 11
g0108:     }, 
g0108:     "wall_clock_breakdown": false
g0108: }
g0108: [2024-08-12 02:43:11,123] [INFO] [engine.py:99:__init__] CONFIG: micro_batches=32 micro_batch_size=1
g0108: [2024-08-12 02:43:11,123] [INFO] [engine.py:139:__init__] is_pipe_partitioned= False is_grad_partitioned= False
g0108: [2024-08-12 02:43:11,836] [INFO] [engine.py:158:__init__] RANK=0 STAGE=0 LAYERS=5 [0, 5) STAGE_PARAMS=201076736 (201.077M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0123: [2024-08-12 02:43:11,836] [INFO] [engine.py:158:__init__] RANK=16 STAGE=4 LAYERS=3 [14, 17) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0120: [2024-08-12 02:43:11,836] [INFO] [engine.py:158:__init__] RANK=8 STAGE=2 LAYERS=3 [8, 11) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0126: [2024-08-12 02:43:11,837] [INFO] [engine.py:158:__init__] RANK=24 STAGE=6 LAYERS=3 [20, 23) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0113: [2024-08-12 02:43:11,837] [INFO] [engine.py:158:__init__] RANK=4 STAGE=1 LAYERS=3 [5, 8) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0127: [2024-08-12 02:43:11,837] [INFO] [engine.py:158:__init__] RANK=28 STAGE=7 LAYERS=3 [23, 26) STAGE_PARAMS=110893056 (110.893M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0125: [2024-08-12 02:43:11,837] [INFO] [engine.py:158:__init__] RANK=20 STAGE=5 LAYERS=3 [17, 20) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0121: [2024-08-12 02:43:11,837] [INFO] [engine.py:158:__init__] RANK=12 STAGE=3 LAYERS=3 [11, 14) STAGE_PARAMS=135278592 (135.279M) TOTAL_PARAMS=1123641344 (1123.641M) UNIQUE_PARAMS=1123641344 (1123.641M)
g0120: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0127: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0120: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0125: [2024-08-12 02:43:12,538] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0127: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0120: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0125: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0120: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0123: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0123: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0127: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0108: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0125: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0108: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0108: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0108: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0113: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0113: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0127: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0121: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0113: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0123: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0121: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0126: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0126: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0126: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0126: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0121: [2024-08-12 02:43:12,539] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0123: [2024-08-12 02:43:12,540] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0121: [2024-08-12 02:43:12,540] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0113: [2024-08-12 02:43:12,546] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0125: [2024-08-12 02:43:12,555] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0113: [2024-08-12 02:43:15,564] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0113: [2024-08-12 02:43:15,564] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0113: [2024-08-12 02:43:15,565] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0113: [2024-08-12 02:43:15,565] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0126: [2024-08-12 02:43:15,571] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0126: [2024-08-12 02:43:15,571] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0113: [2024-08-12 02:43:15,572] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0113: [2024-08-12 02:43:15,573] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0113: [2024-08-12 02:43:15,573] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0113: [2024-08-12 02:43:15,574] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt...
g0126: [2024-08-12 02:43:15,574] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0126: [2024-08-12 02:43:15,575] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0126: [2024-08-12 02:43:15,579] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0126: [2024-08-12 02:43:15,579] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0126: [2024-08-12 02:43:15,581] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0126: [2024-08-12 02:43:15,582] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt...
g0125: [2024-08-12 02:43:15,686] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0125: [2024-08-12 02:43:15,687] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0125: [2024-08-12 02:43:15,687] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0125: [2024-08-12 02:43:15,688] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0125: [2024-08-12 02:43:15,695] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0125: [2024-08-12 02:43:15,695] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0125: [2024-08-12 02:43:15,695] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0125: [2024-08-12 02:43:15,697] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt...
g0123: [2024-08-12 02:43:15,738] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0123: [2024-08-12 02:43:15,739] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0123: [2024-08-12 02:43:15,739] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0123: [2024-08-12 02:43:15,739] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0121: [2024-08-12 02:43:15,741] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0123: [2024-08-12 02:43:15,747] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0123: [2024-08-12 02:43:15,747] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0123: [2024-08-12 02:43:15,747] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0123: [2024-08-12 02:43:15,747] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt...
g0121: [2024-08-12 02:43:15,748] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0121: [2024-08-12 02:43:15,755] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0121: [2024-08-12 02:43:15,756] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0121: [2024-08-12 02:43:15,770] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0121: [2024-08-12 02:43:15,770] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0121: [2024-08-12 02:43:15,770] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0121: [2024-08-12 02:43:15,770] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt...
g0120: [2024-08-12 02:43:15,788] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0120: [2024-08-12 02:43:15,788] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0120: [2024-08-12 02:43:15,788] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0120: [2024-08-12 02:43:15,788] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0120: [2024-08-12 02:43:15,796] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0120: [2024-08-12 02:43:15,796] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0120: [2024-08-12 02:43:15,796] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0120: [2024-08-12 02:43:15,796] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt...
g0108: [2024-08-12 02:43:15,878] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:15,878] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:15,878] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:15,878] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:15,885] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0108: [2024-08-12 02:43:15,886] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0108: [2024-08-12 02:43:15,886] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0108: [2024-08-12 02:43:15,886] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt...
g0127: [2024-08-12 02:43:16,482] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0127: [2024-08-12 02:43:16,482] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0127: [2024-08-12 02:43:16,483] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0127: [2024-08-12 02:43:16,483] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0127: [2024-08-12 02:43:16,490] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0127: [2024-08-12 02:43:16,490] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0127: [2024-08-12 02:43:16,491] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0127: [2024-08-12 02:43:16,491] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt...
g0125: [2024-08-12 02:43:17,380] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0125: [2024-08-12 02:43:17,380] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0125: [2024-08-12 02:43:17,380] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0125: [2024-08-12 02:43:17,381] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_05_model_states.pt.
g0125: [2024-08-12 02:43:17,381] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,381] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,381] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,382] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,399] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0113: [2024-08-12 02:43:17,399] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0113: [2024-08-12 02:43:17,400] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,400] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0113: [2024-08-12 02:43:17,400] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,400] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_01_model_states.pt.
g0113: [2024-08-12 02:43:17,401] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,401] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,429] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0120: [2024-08-12 02:43:17,429] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0120: [2024-08-12 02:43:17,430] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,430] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,430] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0120: [2024-08-12 02:43:17,430] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_02_model_states.pt.
g0120: [2024-08-12 02:43:17,431] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,432] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,639] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,640] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,640] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,640] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,640] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,640] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,641] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,641] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,674] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,674] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,677] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,678] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_17-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,692] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,696] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,696] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,700] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,702] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,702] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,703] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,703] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,703] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,703] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,703] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,704] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,737] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,737] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,740] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,740] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_05-model_00-model_states.pt.
g0113: [2024-08-12 02:43:17,752] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,759] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,761] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0113: [2024-08-12 02:43:17,761] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,803] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,803] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,803] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,803] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,804] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,804] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,804] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,804] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt...
g0126: [2024-08-12 02:43:17,814] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0126: [2024-08-12 02:43:17,814] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0126: [2024-08-12 02:43:17,815] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0126: [2024-08-12 02:43:17,815] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0126: [2024-08-12 02:43:17,815] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0126: [2024-08-12 02:43:17,816] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_06_model_states.pt.
g0126: [2024-08-12 02:43:17,816] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0126: [2024-08-12 02:43:17,817] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,837] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,842] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,842] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,842] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_08-model_00-model_states.pt.
g0120: [2024-08-12 02:43:17,859] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,863] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,863] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0120: [2024-08-12 02:43:17,864] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,944] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,944] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,944] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,944] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,944] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,944] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,944] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,945] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,977] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,977] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,979] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,979] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_18-model_00-model_states.pt.
g0125: [2024-08-12 02:43:17,991] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0125: [2024-08-12 02:43:17,999] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0125: [2024-08-12 02:43:18,000] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0125: [2024-08-12 02:43:18,000] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,075] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,075] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,075] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,075] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,075] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,075] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,075] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,076] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,091] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,091] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,091] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,091] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,092] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,092] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,092] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,092] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,107] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,107] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,110] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,110] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_06-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,121] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,123] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,123] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,123] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,123] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_09-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,128] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,131] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,131] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,144] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,144] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,144] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,144] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,155] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0121: [2024-08-12 02:43:18,156] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0121: [2024-08-12 02:43:18,156] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0121: [2024-08-12 02:43:18,156] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_03_model_states.pt.
g0121: [2024-08-12 02:43:18,156] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,156] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,157] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,158] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,231] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,231] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,232] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,232] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,232] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,232] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,233] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,233] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt...
g0125: [2024-08-12 02:43:18,242] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,242] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,242] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,243] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,243] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0125: [2024-08-12 02:43:18,243] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0125: [2024-08-12 02:43:18,243] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0125: [2024-08-12 02:43:18,243] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,265] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,266] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,268] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,270] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_20-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,276] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,276] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,277] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0125: [2024-08-12 02:43:18,277] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_19-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,284] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,286] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,287] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,287] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,376] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0123: [2024-08-12 02:43:18,376] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0123: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0123: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_04_model_states.pt.
g0121: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,377] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,378] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,415] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,415] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,416] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,416] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_11-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,431] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,437] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,437] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,438] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0127: [2024-08-12 02:43:18,447] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0127: [2024-08-12 02:43:18,447] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0127: [2024-08-12 02:43:18,448] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0127: [2024-08-12 02:43:18,448] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_07_model_states.pt.
g0127: [2024-08-12 02:43:18,448] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0127: [2024-08-12 02:43:18,448] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0127: [2024-08-12 02:43:18,449] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0127: [2024-08-12 02:43:18,449] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,453] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,453] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,455] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,455] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,455] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,456] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,456] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,456] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,477] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,478] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,478] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,478] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,478] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,478] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,478] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0113: [2024-08-12 02:43:18,479] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt...
g0120: [2024-08-12 02:43:18,487] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,491] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,491] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0120: [2024-08-12 02:43:18,491] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_10-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,510] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,510] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,513] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0113: [2024-08-12 02:43:18,513] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_07-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,561] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:18,561] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:18,562] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:18,562] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/mp_rank_00_model_states.pt.
g0108: [2024-08-12 02:43:18,562] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,562] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,563] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,564] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,589] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,589] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,589] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,589] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,589] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,590] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,590] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,590] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,621] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,621] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,623] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,623] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_21-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,624] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,624] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,624] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,625] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,625] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,625] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,625] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,626] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,637] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,638] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,642] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,643] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,661] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,661] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,662] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0123: [2024-08-12 02:43:18,663] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_14-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,676] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,676] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,677] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,677] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,677] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,677] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,677] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,677] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,677] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,683] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,683] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0123: [2024-08-12 02:43:18,684] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,709] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,709] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,712] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,712] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_12-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,727] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,729] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,730] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,734] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,736] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,736] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,737] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,737] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,737] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,737] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,737] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,737] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,782] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,782] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,786] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,786] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_01-model_00-model_states.pt.
g0108: [2024-08-12 02:43:18,812] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,813] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,815] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0108: [2024-08-12 02:43:18,815] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,856] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,857] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,858] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,859] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,859] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,860] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,860] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,860] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt...
g0126: [2024-08-12 02:43:18,888] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,888] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,893] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0126: [2024-08-12 02:43:18,894] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_22-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,940] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,940] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,941] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,941] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,941] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,941] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,941] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,941] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt...
g0121: [2024-08-12 02:43:18,975] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,975] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,976] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0121: [2024-08-12 02:43:18,976] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_13-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,209] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,209] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,209] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,209] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,210] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,210] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,210] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,210] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,242] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,242] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,244] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,244] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_02-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,263] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,264] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,265] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,266] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,495] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,495] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,495] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,495] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,495] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,496] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,496] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,496] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,526] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,526] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,528] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,528] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_03-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,547] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,547] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,549] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,549] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,791] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,791] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,791] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,792] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,792] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,792] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,792] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,792] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt...
g0108: [2024-08-12 02:43:19,823] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,823] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,825] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0108: [2024-08-12 02:43:19,826] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_04-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,230] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,230] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,230] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,230] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,230] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,230] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,230] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,231] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,261] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,261] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,263] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,264] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_15-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,275] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,283] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,285] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,285] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,335] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,335] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,336] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,336] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,336] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,336] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,337] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,337] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,619] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,619] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,619] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,620] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,620] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,620] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,620] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,620] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt...
g0123: [2024-08-12 02:43:20,652] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,652] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,654] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0123: [2024-08-12 02:43:20,654] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_16-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,826] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,826] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,826] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,827] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_23-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,841] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,848] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,848] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,848] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,858] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,858] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,858] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,858] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,858] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,858] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,859] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,859] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,859] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,859] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,859] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,859] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_24-model_00-model_states.pt.
g0127: [2024-08-12 02:43:20,860] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,860] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,860] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:20,861] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:21,074] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0127: [2024-08-12 02:43:21,074] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0127: [2024-08-12 02:43:21,075] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0127: [2024-08-12 02:43:21,075] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0127: [2024-08-12 02:43:21,075] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:21,075] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:21,075] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:21,076] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt...
g0127: [2024-08-12 02:43:21,123] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0127: [2024-08-12 02:43:21,123] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0127: [2024-08-12 02:43:21,129] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0127: [2024-08-12 02:43:21,129] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase/global_step42000/layer_25-model_00-model_states.pt.
g0108:  > overriding learning rate value to 0.0002
g0108:  > overriding minimum learning rate value to 1e-05
g0108:  > overriding warmup iterations value to 0
g0108:  > overriding warmup tokens value to 3000000000
g0108:  > overriding total number of iterations value to 6656000
g0108:  > overriding decay tokens value to 300000000000
g0108:  > overriding learning rate decay style value to cosine
g0108:  > overriding start weight decay value to 0.1
g0108:  > overriding end weight decay value to 0.1
g0108:  > overriding total number of weight decay iterations value to 6656000
g0108:  > overriding weight decay incr style value to constant
g0108:  checkpoint version 3.0
g0108:   successfully loaded checkpoint from /groups/gcf51099/crypto_llm/models/0.latin_wikipedia_poly_000000_1234_True/checkpoint/gpt_1.1B_tok300B_lr2.0e-4_min1.0e-5_w3000M_d300B_cosine_gbs128_mbs1_g32_pp8_seed1234_rebase at iteration 42000
g0127: (min, max) time across ranks (ms):
g0127:     load-checkpoint ................................: (9405.49, 9409.38)
g0108: [after model, optimizer, and learning rate scheduler are built] datetime: 2024-08-12 02:43:21 
g0108: > building train, validation, and test datasets ...
g0108:  > datasets target sizes (minimum size):
g0108:     train:      6656000
g0108:     validation: 678400
g0108:     test:       12800
g0108: > building train, validation, and test datasets for GPT ...
g0108: Single data path provided for train, valid & test
g0108:  > building dataset index ...
g0108:     reading sizes...
g0108:     reading pointers...
g0108:     reading document index...
g0108:     creating numpy buffer of mmap...
g0108:     creating memory view of numpy buffer...
g0108:  > finished creating indexed dataset in 0.038350 seconds
g0108:     number of documents: 2237032
g0108:  > dataset split:
g0108:     train:
g0108:      document indices in [0, 2122943) total of 2122943 documents
g0108:     validation:
g0108:      document indices in [2122943, 2234795) total of 111852 documents
g0108:     test:
g0108:      document indices in [2234795, 2237032) total of 2237 documents
g0108:  > WARNING: could not find index map files, building the indices on rank 0 ...
g0108:  > only one epoch required, setting separate_last_epoch to False
g0108:  > elasped time to build and save doc-idx mapping (seconds): 0.082704
g0108:     using:
g0108:      number of documents:       2122943
g0108:      number of epochs:          1
g0108:      sequence length:           2048
g0108:      total number of samples:   10749554
g0108:  > elasped time to build and save sample-idx mapping (seconds): 0.317709
g0108:  > building shuffle index with split [0, 10749554) and [10749554, 10749554) ...
g0108:  > elasped time to build and save shuffle-idx mapping (seconds): 0.371965
g0108:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/4ca8a15b7ed2215f2c21277420db9d1a_doc_idx.npy
g0108:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/4ca8a15b7ed2215f2c21277420db9d1a_sample_idx.npy
g0108:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/4ca8a15b7ed2215f2c21277420db9d1a_shuffle_idx.npy
g0108:     loaded indexed file in 0.011 seconds
g0108:     total number of samples: 10749555
g0108:     total number of epochs: 1
g0108:  > WARNING: could not find index map files, building the indices on rank 0 ...
g0108:  > last epoch number of samples (114685) is smaller than 80% of number of samples per epoch (563715), setting separate_last_epoch to True
g0108:  > elasped time to build and save doc-idx mapping (seconds): 0.009048
g0108:     using:
g0108:      number of documents:       111852
g0108:      number of epochs:          2
g0108:      sequence length:           2048
g0108:      total number of samples:   1127430
g0108:  > elasped time to build and save sample-idx mapping (seconds): 0.020921
g0108:  > building shuffle index with split [0, 563715) and [563715, 1127430) ...
g0108:  > elasped time to build and save shuffle-idx mapping (seconds): 0.031939
g0108:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2476414ed7b35c2c042db8799c7e4abd_doc_idx.npy
g0108:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2476414ed7b35c2c042db8799c7e4abd_sample_idx.npy
g0108:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/2476414ed7b35c2c042db8799c7e4abd_shuffle_idx.npy
g0108:     loaded indexed file in 0.009 seconds
g0108:     total number of samples: 1127431
g0108:     total number of epochs: 2
g0108:  > loading doc-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/6749304f1e1aa62f2f0d4bf70e8db4aa_doc_idx.npy
g0108:  > loading sample-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/6749304f1e1aa62f2f0d4bf70e8db4aa_sample_idx.npy
g0108:  > loading shuffle-idx mapping from /groups/gcf51099/crypto_llm/data/index-cache/6749304f1e1aa62f2f0d4bf70e8db4aa_shuffle_idx.npy
g0108:     loaded indexed file in 0.038 seconds
g0108:     total number of samples: 14468
g0108:     total number of epochs: 2
g0108: > finished creating GPT datasets ...
g0108: [after dataloaders are built] datetime: 2024-08-12 02:43:25 
g0108: done with setup ...
g0108: training ...
g0127: (min, max) time across ranks (ms):
g0127:     model-and-optimizer-setup ......................: (12399.96, 12419.16)
g0127:     train/valid/test-data-iterators-setup ..........: (3439.13, 3448.44)
g0108: [before the start of training step] datetime: 2024-08-12 02:43:25 
g0108: [2024-08-12 02:44:17,263] [INFO] [logging.py:96:log_dist] [Rank 0] step=42010, skipped=71, lr=[0.00019965900617800823, 0.00019965900617800823], mom=[(0.9, 0.95), (0.9, 0.95)]
g0108: steps: 42010 loss: 1.2145 iter time (s): 5.118 samples/sec: 25.011
g0127:  iteration    42010/   52000 | consumed samples:      5377280 | consumed tokens:  11012669440 | elapsed time per iteration (ms): 5160.4 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 1.065865E+00 | loss scale: 32.0 | grad norm: 0.264 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 24.804 | tokens per gpu per second (tgs): 1587.475 | TFLOPs: 12.77 |
g0113: [Rank 4] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 8703.76220703125 | reserved: 9010.0 | max reserved: 9010.0
g0127: [Rank 28] (after 42010 iterations) memory (MB) | allocated: 1924.90087890625 | max allocated: 2985.41162109375 | reserved: 3720.0 | max reserved: 3720.0
g0126: [Rank 24] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 4273.52783203125 | reserved: 5182.0 | max reserved: 5182.0
g0121: [Rank 12] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 6931.66845703125 | reserved: 7222.0 | max reserved: 7222.0
g0108: [Rank 0] (after 42010 iterations) memory (MB) | allocated: 2877.66943359375 | max allocated: 10557.68408203125 | reserved: 10902.0 | max reserved: 10902.0
g0120: [Rank 8] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 7817.71533203125 | reserved: 8116.0 | max reserved: 8116.0
g0123: [Rank 16] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 6045.62158203125 | reserved: 6456.0 | max reserved: 6456.0
g0125: [Rank 20] (after 42010 iterations) memory (MB) | allocated: 1971.41943359375 | max allocated: 5159.57470703125 | reserved: 5434.0 | max reserved: 5434.0
g0108: [2024-08-12 02:44:59,456] [INFO] [logging.py:96:log_dist] [Rank 0] step=42020, skipped=71, lr=[0.00019965878314753572, 0.00019965878314753572], mom=[(0.9, 0.95), (0.9, 0.95)]
g0108: steps: 42020 loss: 0.9147 iter time (s): 4.049 samples/sec: 31.616
g0127:  iteration    42020/   52000 | consumed samples:      5378560 | consumed tokens:  11015290880 | elapsed time per iteration (ms): 4219.3 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 1.013267E+00 | loss scale: 32.0 | grad norm: 0.305 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 30.337 | tokens per gpu per second (tgs): 1941.549 | TFLOPs: 15.62 |
g0108: [2024-08-12 02:45:40,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=42030, skipped=71, lr=[0.00019965856004428058, 0.00019965856004428058], mom=[(0.9, 0.95), (0.9, 0.95)]
g0108: steps: 42030 loss: 1.0217 iter time (s): 4.042 samples/sec: 31.666
g0127:  iteration    42030/   52000 | consumed samples:      5379840 | consumed tokens:  11017912320 | elapsed time per iteration (ms): 4074.5 | learning rate: 1.997E-04 | global batch size:   128 | lm loss: 1.002557E+00 | loss scale: 32.0 | grad norm: 0.297 | num zeros: 0.0 | actual seqlen:  2048 | number of skipped iterations:   0 | number of nan iterations:   0 | samples per second: 31.415 | tokens per gpu per second (tgs): 2010.571 | TFLOPs: 16.18 |
